### Techniques that build on prior knowledge and indirectly related data are necessary for many rare disease applications {.page_break_before}

#### Knowledge graphs
Rare diseases lack large, normalized datasets, limiting our ability to study key attributes of these diseases.
A potentially powerful strategy for evaluating genotype-phenotype relationships or repurposing drugs when large datasets are scarce is to use knowledge graphs.
Knowledge graphs integrate related-but-different data types, creating a rich data source.
Examples of public biomedical knowledge graphs and frameworks that could be useful in rare disease include the Monarch Graph Database[@doi:10.1093/nar/gkw1128], hetionet[@doi:10.7554/eLife.26726], PheKnowLator[@doi:10.1101/2020.04.30.071407], and the Global Network of Biomedical Relationships[@doi:10.1093/bioinformatics/bty114].
These graphs connect information like genetic, functional, chemical, clinical, and ontological data to enable the exploration of relationships of data with disease phenotypes through manual review[@doi:10.1093/database/baaa015] or computational methods[@doi:10.1101/727925; @doi:10.1186/s12911-019-0938-1].

In the academic rare disease space, there a few pioneering examples of ML-based mining of knowledge graphs to repurpose drugs[@doi:10.1101/727925] and classify rare diseases[@doi:10.1186/s12911-019-0938-1].
These studies make it clear that there are challenges in using machine learning based on knowledge graphs in rare disease.
For example, these projects rely on a gold standard dataset to validate the performance of the models; often, there are not robust gold standard datasets available for individual rare diseases.
They also evaluate rare diseases in an unbiased manner, rather than interrogating a specific disease of interest.
Consequently, it is not yet clear how effective these approaches, and knowledge graphs in general, are in studying a specific disease of interest; more work needs to be done to identify methods that can provide actionable insights for a specific rare disease application. <!-- TODO: Is this a point to note that may need to be combined with statistical techniques described earlier? -->

Beyond the aforementioned studies, there are not many examples of studies in the public domain that leverage knowledge graphs to characterize rare diseases.
Private entities (e.g. healx, Boehringer Ingelheim), however, are performing an undisclosed amount of work to create proprietary rare disease knowledge graphs for ML-based drug discovery applications.
The existence of private companies pursuing this idea, as well as the availability of public biomedical knowledge graphs, suggests that this may be a fruitful untapped area of rare disease research in the public arena.
More work needs to be done to assess 1) which graphs and graph features capture the salient information about rare diseases, 2) the utility of ML methods to obtain actionable insights about rare diseases and 3) which problems - like drug discovery, identification of novel rare diseases, or assessment of genotype-phenotype relationships - can be interrogated using ML of knowledge graphs.

<!-- TODO: Is this header level right? I can't tell if this is supposed to be a subsection or its own section. The strategies discussed here might either be considered bringing both statistical + prior knowledge & data together or another part of using prior knowledge + data. I think I favor the former, though it would require putting a brief transfer and multi-task blurb in the prior/related data section. -->

#### Transfer, multitask, and few-shot learning

To realize the potential of machine learning for biological discovery in rare diseases, we often cannot study an individual rare disease alone as samples are limited.
Instead, we can build on prior knowledge and large volumes of data that do not directly assay our disease of interest, but are similar enough to be valuable for discovery.
We can leverage shared features, whether they are normal developmental processes that are aberrant in disease or an imaging anomaly present in rare and common diseases, for advancing our understanding.
Methods that leverage shared features include transfer learning, multitask learning, and few-shot learning approaches.

Transfer learning is an approach where a model trained for one task or domain (source domain) is applied to another, typically related task or domain (target domain).
Transfer learning can be supervised (one or both of the source and target domains have labels), or unsupervised (both domains are unlabeled).
Though there are multiple types of transfer learning, in a later section we will focus on feature-representation-transfer [@doi:10.1109/TKDE.2009.191].
Feature-representation-transfer approaches learn representations from the source domain and apply them to a target domain [@doi:10.1109/TKDE.2009.191].
<!-- TODO: Add a motivating example that's not DeepProfile or MultiPLIER and ties into the first section that I propose to be about dimensionality reduction, etc. :D -->

Where transfer learning can be supervised or unsupervised, the related approaches multitask and few-shot learning are forms of supervised learning that generally rely on deep neural networks.
Multitask learning is an approach where classifiers are learned for _related tasks_ at the same time using a shared representation [@doi:10.1023/A:1007379606734], where task refers to an individual prediction being made.
Few-shot learning is the generalization of a model trained on related tasks to a new task with limited labeled data (e.g., the detection of a patient with a rare disease from a low number of examples of that rare disease).

<!-- TODO: Shorten considerably -->

Multitask neural networks that predict multiple tasks simultaneously are generally thought to improve performance over models that make predictions for a single task by learning a shared representation and effectively being exposed to more training data than the single task case [@doi:10.1023/A:1007379606734; @arxiv:1606.08793].
Kearnes, Goldman, and Pande set out to examine the effects of dataset size and task relatedness on multitask learning performance improvements ("multitask effect") in drug discoveryâ€“an area that also suffers from insufficient data [@arxiv:1606.08793].
The authors found that the multitask performance gains were highly dataset-specific: smaller datasets tended to benefit most from multitask learning and the addition of more training data did not guarantee improved performance for multitask models.
In predicting phenotypes from EHR data, Ding et al. demonstrated that multitask neural networks outperformed single-task networks for predicting complex rare phenotypes but not common phenotypes [@arxiv:1808.03331].
Liu et al. developed a method to train long short-term memory networks, a type of recurrent neural network, to predict mortality in rare diseases using EHR data as input [@arxiv:2004.05318v2].
Their method, Ada-SiT (Adaptation to Similar Tasks), was specifically designed for many tasks with insufficient data and allowed for task similarity to be measured during training.

In contrast, one-shot or few-shot learning relies on using prior knowledge to generalize to new prediction tasks where there are a low number of examples [@arxiv:1904.05046v3], where a distance metric is learned from input data and used to compare new examples for prediction [@doi:10.1021/acscentsci.6b00367].
Altae-Tran et al. developed a method for predicting small molecule activity that learned a meaningful distance metric over the properties of various compounds [@doi:10.1021/acscentsci.6b00367].
However, the authors' results suggested underperformance of one-shot learning methods relative to baseline random forest models when structural similarity could not be exploited and did not show support for generalization of models trained on very different contexts from the target task.
Quellec et al. presented a few-shot learning approach for detecting rare pathologies in fundus photographs [@arxiv:1907.09449v3].
The authors trained a convolutional neural network (CNN) to predict common pathologies, which tended to cluster similar conditions in feature space.
The learned feature space was then used to train a probabilistic model for each rare pathology.
This approach outperformed multitask learning, which suggests few-shot learning provides an advantage in contexts where predicting common conditions simultaneously results in a loss of performance [@arxiv:1907.09449v3].  

Multitask and few-shot learning are comprised of a variety of approaches and architectures that are beyond this scope of this work (see [@arxiv:1706.05098; @arxiv:1707.08114v2] and [@arxiv:1904.05046v3] for an overview).
As with transfer learning, the utility of these approaches to rare disease research is an open question and is likely to be highly dependent on dataset availability and research goals.
