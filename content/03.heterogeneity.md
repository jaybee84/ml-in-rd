### Managing disparities in data generation is required for robust analysis

Rare disease data often suffers from artifacts introduced by non-biological phenomena such as batch or assay platform. 
The consequences of these artifacts are amplified when there are few samples and heterogeneous phenotypes.
Furthermore, datasets are often combined from multiple small studies where biological characteristics are confounded by technical variables. 
Collaboration with domain experts may result in unexpected insight into potential sources of variation. 
The authors experienced this when studying neurofibromatosis type 1 (NF1). 
The NF1 datasets were comprised of samples obtained with different surgical techniques, resulting in differences that were a consequence of sample collection method rather than differences in biology.
Consequently, careful assessment of and accounting for confounding factors is critical to identifying meaningful features within a dataset. 

Assessment of confounding factors and heterogeneity is perhaps most easily performed using unsupervised learning approaches. 
K-means clustering or hierarchical clustering can be used to characterize the structure present in genomic or imaging data. [@doi:10.1186/1471-2105-9-497;@doi:10.1109/JBHI.2013.2276766] 
Similarly, dimensionality reduction methods can be used to visualize heterogeneity and confounders, including multidimensional scaling, principal components analysis, t-distributed stochastic neighbor embedding (t-SNE), and uniform manifold approximation and projection (UMAP), among others. [@doi:10.1007/978-3-540-33037-0_14; @doi:10.1098/rsta.2015.0202; @https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf; @arXiv:1802.03426]
Dimensionality reduction techniques are not restricted to 'omic' data - they can also be used in rare disease applications to characterize the structure and heterogeneity of imaging data [@doi:10.1016/j.media.2020.101660], mass cytometry data [@doi:10.1038/ncomms14825], and others.
All of these methods can be used to identify batch effects and other structure in the data, though some (like t-SNE and UMAP) require parameters that can affect the output [@doi:10.23915/distill.00002;@arXiv:1802.03426]. 
Therefore, obtaining a clear interpretation from these methods requires understanding the underlying approach and parameters.  
Another important consideration is discussed by Way, et. al. [@doi:10.1186/s13059-020-02021-3]: a single dimensionality reduction method alone may not be sufficient to reveal all of the technical or biological heterogeneity; testing multiple methods may result in a more comprehensive portrait of the data.

Once the nature of the non-biological heterogeneity has been established, different techniques can be used to correct the differences. 
Common approaches include reprocessing the raw data using a single analysis pipeline if the data are obtained from different sources, application of batch correction methods [@doi:10.1093/biostatistics/kxj037; @doi:10.1093/nar/gku864], and normalization of raw values[@doi:10.1186/gb-2010-11-3-r25].
It is also important to be realistic when working with rare disease data. 
For various reasons including ethical constraints, funding, and limited biospecimens, experimental design and the resulting data will often be less-than-ideal. 
In these cases, it may be prudent to take a step back, re-evaluate the data, and identify methods that can operate within the constraints of the data, rather than expecting the data to conform to your method of choice.