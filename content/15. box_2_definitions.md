## Definitions {.page_break_before}

### Knowledge Graph

A knowledge graph is a network representation of human knowledge about a domain, abstracted into nodes and edges. 
Any entity of interest (for example a gene, a disease, a protein, or a cell-line) can be represented as a node in a knowledge graph.
All nodes can be linked through edges that represent known relationships between the nodes. 
Edges can be directed, indicating that the order of the nodes is important for encoding the relationship, or undirected.
For example, a gene (node) can be linked to a protein (node) using a directed edge that represents the relationship that the protein is generated through the transcription and translation of the gene. 
Knowledge graphs serve to integrate data that exist in distributed sources, encode human readable knowledge in machine readable format, and evolve in a flexible manner to integrate new knowledge as it becomes available.

### Machine Learning

Machine learning is a scientific discipline at the intersection of computer science and statistics, which combines computational and statistical methods to identify patterns in sample data.[@https://link.springer.com/book/10.1007/978-0-387-21606-5, @doi:10.1038/s41580-021-00407-0]
In this discipline, one intends to use data as input and apply or fit predictive models to recognize patterns in the data or identify informative groups among the data using objective computational methods.

### Rare Disease

According to the Orphan Drug Act[@https://www.fda.gov/media/99546/download] of United States of America, diseases or conditions that impact less than 200,000 people in the U.S are considered to be rare diseases. 
The European Union defines a disease as rare when it affects less than 1 in 2,000 people.

### Regularization
Regularization is an approach to reduce overfitting of models to training data, where a penalty or constraint is added to a model trained on a training dataset to avoid making large prediction errors on the evaluation dataset.

### Transfer Learning

Transfer learning is an approach where a model trained for one task or domain (source domain) is applied to another, typically related task or domain (target domain), for example a model pre-trained natural images from the ImageNet dataset can potentially be used to classify medical images.[@doi:10.1109/TMI.2016.2528162]
Transfer learning can be supervised (one or both of the source and target domains have labels), or unsupervised (both domains are unlabeled).

### Variational Autoencoder

Variational Autoencoders or VAEs are unsupervised neural networks that use hidden layers to learn or encode representations from available data while mapping the input data to the output data. 
VAEs are distinct from other autoencoders since the distribution of the encodings are regularized such that they are close to a normal distribution, which may contribute to learning more biologically relevant signals [@doi:10.1186/s13059-020-02021-3].