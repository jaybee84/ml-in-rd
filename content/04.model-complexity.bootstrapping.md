## Bootstrapping {.page_break_before}

Bootstrap or resampling computation is a powerful statistical technique that can be used for estimating population values from datasets of limited sample size [@doi:10.1080/01621459.1997.10474007].
The technique utilizes random sampling of data points from a dataset of limited sample size with replacement to approximate a larger population and estimate various population statistics (e.g. mean).
Subsequent iterations of resampling generates a distribution of the statistical value (mean) which minimizes the error of the estimate.
Bootstrap based techniques (e.g. bootstrap aggregating or bagging) are used in conjunction with various learning methods to find the most informative models given a specific dataset [@doi:10.1023/A:1010933404324, @doi:10.1198/0003130043277, @doi:10.1016/S0925-2312(01)00650-6, @doi:10.1016/j.neucom.2004.11.017, @doi:10.1002/sim.4780111607].

While most datasets in practice are of finite sample size and can benefit from bootstrapping, rare disease datasets with limited number of samples necessitate the use of bootstrap to form an informative dataset in addition to model selection [@doi:10.3390/genes11020226].
In this study, bootstrapping the training sample without replacement simulated formation of different incomplete datasets that helped expose the learning models to the incompleteness of the data.
Such additional bootstrapping of the training data helped create confidence intervals for the predictions and the important predictors originating from unstable ensemble models run on the incomplete training data.