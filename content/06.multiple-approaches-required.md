#### Multiple approaches are required 

We have described multiple approaches for maximizing the success of machine learning applications in rare disease research throughout. 
In practice, it is rarely sufficient to use one of these techniques in isolation. 
In this section, we will discuss two recent works – one supervised and one unsupervised – in the rare disease domain that draw on multiple concepts covered here. Feature-representation-transfer (and therefore representation learning and prior data) and regularization underlie both approaches. 

As discussed in the transfer learning section, feature-representation-transfer is an approach wherein a model learns a representation of some collection of data and those features are applied or transferred to a target domain.
This can be a powerful tool for rare diseases if the model used requires more samples than available samples that assay the disease of interest, but we have a collection of data that is related.
Whether our research goal is biological discovery or prediction, we want the representation that a model learns to be _useful_.
In addition to reducing model complexity as discussed earlier, regularization can aid in useful representations by putting some constraints on what is learned by a model.

In a method termed DeepProfile, Dincer et al. leveraged publicly available acute myeloid leukemia (AML) gene expression data to improve the prediction of _in vitro_ drug responses [@doi:10.1101/278739].
The authors trained a variational autoencoder (an unsupervised neural network that learns a series of representations from data), or VAE, on AML data that had been collected over time without the desired phenotypic information (drug response).
VAEs are distinct from other autoencoders in that the distribution of the encodings are regularized such that they are close to a normal distribution, which can help avoid overfitting and learn a representation that is more than just an identity mapping [TODO: CITATIONS / Take another pass at this sentence].
Dincer et al. used the learned attributes to encode a low-dimensional representation of held-out AML data with phenotype labels of interest, and used this representation as input to a classifier that predicted _in vitro_ drug response, which outperformed using the original features.
The study by Dincer and colleagues highlights another challenge: samples collected as part of multiple studies may not be associated with the deep phenotypic information that would maximize their scientific value, but this does not preclude the use of these samples in learning representations.

In an unsupervised case, Taroni et al. trained Pathway-Level Information ExtractoR (PLIER) [@doi:10.1038/s41592-019-0456-1] on a large generic collection of human transcriptomic data (recount2 [@doi:10.1038/nbt.3838]) and used the latent variables learned by the model to describe transcriptomic data from the unseen rare diseases antineutrophil cytoplasmic antibody (ANCA)-associated vasculitis (AAV) and medulloblastoma in an approach termed MultiPLIER [@doi:10.1016/j.cels.2019.04.003]. 
(Here "unseen" refers to the fact that these diseases were not in the training set.) 
PLIER is a matrix factorization approach that takes prior knowledge in the form of gene sets or pathways and gene expression data as input. 
PLIER includes constraints (regularization) such that some latent variables learned by the model will align with input gene sets and ideally latent variables will only be associated with a low number of related gene sets [@doi:10.1038/s41592-019-0456-1], which make it suitable for biological discovery or description of rare disease data.
MultiPLIER allows us to use one model to describe multiple datasets instead of reconciling output from multiple models, which is highly beneficial when identifying commonalities among disease manifestations or affected tissues is a research goal. 

Taken together, DeepProfile [@doi:10.1101/278739] and MultiPLIER [@doi:10.1016/j.cels.2019.04.003] suggest a combination of the techniques discussed throughout can be capitalized on for rare disease research.
We may have few samples from our disease of interest with the required phenotypic labels, but we can leverage existing collections of data and knowledge if we select the models with the _right attributes_.
The utility of DeepProfile and MultiPLIER stem from the fact that biological processes can be shared between biological contexts and that the methods underlying the approaches can effectively learn about those processes. 
In the natural images field, researchers have demonstrated that the transferability of features depends on relatedness of tasks [@arxiv:1411.1792]. 
The limits of transfer learning for and the concept of relatedness in high-dimensional biomedical data assaying rare diseases are open research questions. 
In the authors' opinion, selecting an appropriate model for a given task and evaluations that are well-aligned with a research goal are crucial for applying these approaches in rare diseases.
