### Learning representations from rare disease data

Dimensionality reduction methods can help ‘compress’ information from a large number of features into a smaller number of features in an unsupervised manner [@doi:10.1007/978-3-540-33037-0; @doi:10.1098/rsta.2015.0202, @https://www.jmlr.org/papers/v9/vandermaaten08a.html; @https://arxiv.org/abs/1802.03426] (Figure {@fig:1}C).
An example of a method that is commonly used for dimensionality reduction is principal components analysis (PCA).
PCA identifies new features (or "dimensions"), termed principal components (PCs), that are combinations of original features.
The PCs are calculated in a way that maximizes the amount of information ("variance") they contain and ensures that each PC is uncorrelated with the other PCs [@doi:10.1098/rsta.2015.0202].
In practice, researchers often use the first few PCs to reduce the dimensionality without removing what may be important or informative variability in the data, though PCs are obtained without regard for labels (e.g., disease vs. control or dataset of origin).
Beyond reducing the number of features in various types of data [@doi:10.1016/j.media.2020.101660; @doi:10.1038/ncomms14825], dimensionality reduction can also be used to visualize structure or artifacts in the data (e.g., [@doi:10.1038/s41467-019-13056-x]), to define sample subgroups (e.g., [@doi:10.1038/s41467-020-15351-4], or for feature selection and extraction during application of specific machine learning models [@doi:10.1007/978-3-030-03243-2_299-1] (Figure {@fig:1}D). 

Methods like PCA, multidimensional scaling (MDS), t-distributed stochastic neighbor embedding (t-SNE), and uniform manifold approximation and projection (UMAP) can help researchers successfully identify useful patterns in the original data, though t-SNE and UMAP may require adjusting the hyperparameters – values used to set up a model that can be specified by a user, rather than learned from the data – that may effect the output [@https://arxiv.org/abs/1802.03426; @doi:10.23915/distill.00002].
Testing multiple dimensionality reduction methods, rather than a single method, may be necessary to obtain a more comprehensive portrait of the data [@doi:10.1186/s13059-020-02021-3]. 
Nguyen and Holmes discuss additional important considerations for using dimensionality reduction methods such as selection criteria and interpretation of results [@doi:10.1371/journal.pcbi.1006907].
Beyond dimensionality reduction, other unsupervised learning approaches such as k-means clustering or hierarchical clustering have been used to characterize the structure present in genomic or imaging data [@doi:10.1186/1471-2105-9-497; @doi:10.1109/jbhi.2013.2276766].

Representation learning approaches, of which dimensionality reduction methods are a subset, learns low-dimensional representations (composite features) from the raw data. 
For example, representation learning through matrix factorization can extract features from transcriptomics datasets that are made of combinations of gene expression values found in the training data [@doi:10.1038/s41467-020-14666-6], and use them to interpret test data [@doi:10.1093/bioinformatics/btq503; @doi:10.1186/s13059-020-02021-3].
To ensure that the learned representations are generalizable to other data, the features learned by the model can be constrained through methods like regularization [@doi:10.1371/journal.pgen.1004754, @doi:10.1002/sim.6782]. 
Representation learning generally requires many samples when applied to complex biological systems and therefore may appear to aggravate the curse of dimensionality. 
However, it can be a powerful tool to learn low-dimensional patterns from large datasets and then find those patterns in smaller, related datasets. 
In later sections, we will discuss this method of leveraging large datasets to reduce dimensionality in smaller datasets, also known as feature-representation-transfer learning. 

![Representation learning can extract useful features from high dimensional data. a) The data (e.g., transcriptomic data) are highly dimensional, having thousands of features (displayed as Fa-Fz). Samples come from two separate classes (purple and green row annotation).  b) In the original feature space, Fa and Fb do not separate the two classes (purple and green) well. c) A representation learning approach learns new features (e.g., New Feature 1, a combination of Fa, Fb .... Fz, and New Feature 2, a different combination of Fa, Fb .... Fz). New Feature 2 distinguishes class, whereas New Feature 1 may capture some other variable such as batch (not represented). New features from the model can be used to interrogate the biology of the input samples, develop classification models, or use other analytical techniques that would have been more difficult with the original dataset dimensions.](content/images/figures/pdfs/figure2-representation-learning.png){#fig:2}
