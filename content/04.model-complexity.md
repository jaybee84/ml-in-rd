### Manage model complexity without sacrificing the value of machine learning

Machine learning is a great tool to capture complex patterns that underlie a dataset.
But for fruitful translation of patterns extracted using machine learning into testable hypotheses, there are a few pre-requisites: the predicted features need to be a) stable i.e. the same features should surface from the data if the model is run multiple times, b) interpretable, and c) should not include technical artifacts leading to misinterpretation of data.
Fulfilling these pre-requisites become even more important in case of rare disease dataset where there is high label-uncertainty (i.e. where the label given to a data point may not be correct due to imperfect understanding of the disease).
In this section we highlight few techniques which can help fulfill the above mentioned pre-requisites.

#### Bootstrapping

A technique to bolster stability in the model predictions is bootstrapping.
Bootstrapping is a powerful statistical technique where resampling the data with replacements can help estimate population values from datasets of limited sample size [@doi:10.1080/01621459.1997.10474007].
Such resampling with replacement is used in various learning methods to find the most informative models (e.g. bootstrap aggregating or _bagging_ used in random forests [@doi:10.1023/A:1010933404324; @doi:10.1198/0003130043277], bootstrap in neural networks [@doi:10/c8xpqz], or regression models [@doi:10.1016/j.neucom.2004.11.017; @doi:10.1002/sim.4780111607]).
A variation where resampling of a rare disease dataset was done _without replacement_, generated confidence intervals for the model predictions as they were exposed to incomplete datasets (mimicking the real life case where most rare disease datasets are incomplete) [@doi:10.3390/genes11020226].

#### Regularization

Another common strategy for handling the paucity of data in rare disease is to aggregate data from multiple studies or time points to produce a more comprehensive dataset.
Given a dataset with strong preexisting study-specific technical differences between groups of samples, ML methods may model dataset-specific features instead of true biology, leading to high prediction accuracy for training data but poor performance in new test data (an "overfit" model) [@doi:10.1073/pnas.1900654116].
Minimization of overfitting can be accomplished by cross-validation (to reduce variance in predictions) and regularization (to reduce low bias in models).
Regularization makes models less reliant on training data by adding a small penalty (determined by cross-validation), and can minimize overfitting while improving feature selection.

ML models can be regularized using 3 main methods, each with strengths and weaknesses.
Ridge regression aims to minimize the magnitude of the features, but cannot remove unimportant features and thus may not be ideal for reducing the feature space.
Another method, LASSO regression, works well for selecting few important features since it can minimize the magnitude of some features more than the others[@doi:10.1038/nmeth.4014].
Elastic-net regression is a combination of LASSO and ridge regression [@doi:10.1111/j.1467-9868.2005.00503.x], and helps to select the most useful features, especially in presence of large number of correlated features.

While regression based regularization has not been used extensively in rare disease, examples in rare variant discovery and immune cell signature discovery provide insights into their possible application in rare disease.
In rare variant discovery, ridge regression has been utilized to combine rare variants into a single score to increase the signal of rare variants [@doi:10.1371/journal.pone.0044173], while LASSO was implemented along with group penalties to identify rare variants/low frequency predictors [@doi:10.1038/nrg2867; @doi:10.1093/bioinformatics/btq448].
Hybrid applications of LASSO have also been tested in rare variant discovery, including boosting the signal of rare variants by capturing combinations of variants [@doi:10.1016/j.ajhg.2008.06.024; @doi:10.1186/1753-6561-5-S9-S113], integration with a probabilistic logistic Bayesian approach [@doi:10.4137/CIN.S17290], combining feature selection methods with a generalized pooling strategy [@doi:10.1371/journal.pone.0041694], and incorporating prior knowledge into the regularization step to select driver genes in a pathway of interest [@doi:10.1080/10618600.2012.681250].

In immune cell signature discovery, elastic-net regression has been used to reduce the feature space and was found to outperform other regression approaches [@doi:10.1016/j.compbiomed.2015.10.008; @doi:10.1186/1471-2105-14-198; @doi:10.1111/j.1467-9868.2005.00503.x].
A variation of elastic-net, where a two-step regularized logistic regression was used to pre-select an optimal number of genes before implementing elastic-net regularization for gene selection, identified immune cell signatures in an RNA-seq dataset where the number of cells sampled were far fewer than number of genes profiled [@doi:10.1186/s12859-019-2994-z].
Thus, regularization methods like LASSO or elastic-net have been methods of choice where the profiled feature space is substantially larger than the number of samples; these methods should be explored while working with rare disease datasets.

#### Ensemble learning

Rare disease datasets not only present limited data points but, due to inadequate understanding of the diseases, the labels associated with the data points also carry high levels of uncertainty.
Training ML models using data points with high label-uncertainty (i.e. a silver standard dataset) can lead to unstable predictions.
In such cases, combining various machine learning methods together (_ensemble learning_) can increase accuracy and stability of the predictions.
For example, ensemble learning methods like random forests use bagging of independent decision trees that use similar parameters but different paths to form a consensus about the important predictive features hidden in the dataset [@doi:10.1186/1472-6947-13-134; @doi:10.1023/A:1010933404324; @doi:10.1214/aos/1031689014; @doi:10.1177/2045894019890549; @doi:10/btzfh6].
In silver standard datasets, the limited success of the bagging approach has led to the use of ensemble learning or _cascade learning_, where multiple methods leveraging distinct underlying assumptions are used in tandem and augmented with algorithms like AdaBoost (_boosting_), to capture stable patterns existing in the silver standard data and reduce uncertainty [@doi:10.1109/CVPR.2001.990537; @doi:10.1007/978-3-540-75175-5_16; @doi:10.1109/ICPR.2004.1334680].
A variation of cascade learning implemented to identify rare disease patients from electronic health records from the general population utilized independent steps for feature extraction (using word2vec [@arXiv:1301.3781v3]), preliminary prediction (ensemble of decision trees with penalization for excessive tree-depth), and prediction refinement (using similarity of data points to resolve sample labels) [@pmid:30815073].
Combining these three methods resulted in better performance than other methods when implemented on the silver standard dataset in isolation.

#### One-class-at-a-time classification

In rare diseases like neurofibromatosis, the presence of more than one phenotype (or class) further decreases the number of data-points per class and introduces additional label-uncertainty due to related phenotypes.
In datasets with multiple classes, most ensemble or cascade classifiers follow a _one-classifier-at-a-time_ approach where algorithms at each level predict all classes involved.
But instances where the need for high prediction accuracy for one class outweighs other classes, further modification of the cascade learning efforts is required.
An example of such modification was implemented for triaging psychiatric patients where the identification of one class of psychiatric patients ("severe") far outweighed the need for optimized overall classification accuracy [@pmid:30380082].
Due to the requirements of the problem, a _one-class-at-a-time_ cascade learning approach was adopted, where at each stage a binary classifier was used to predict a specific class against all others.
The final model implemented all models together each identifying one class sequentially and the union of the predictions of all the different models as the final prediction.
The cascade classifiers using the one-class-at-a-time approach were found to perform better than multi-class ensemble classifiers in most cases.
