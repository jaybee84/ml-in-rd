### Constructing machine learning-ready rare disease datasets

High-throughput 'omic' data methods generate high-dimensional data or data with many features, regardless of the underlying disease or condition being assayed.
A typical rare disease dataset is comprised of a small number of samples [@doi:10.1186/s13023-020-01424-6].
A lack of samples gives rise to the “curse of dimensionality” (i.e., few samples but many features), which can contribute to the poor performance of models [@doi:10.1038/nrc2294] [TODO: reference new figure as appropriate #186].
More features often means increased missing observations (_sparsity_), more dissimilarity between samples (_variance_), and increased redundancy between individual features or combinations of features (_collinearity_) [@doi:10.1038/s41592-018-0019-x], all of which contribute to a challenging prediction problem.

If a small sample size compromises an ML model's performance, then two approaches can be taken to improve the outcome: 1) increase the number of samples to reduce sparsity, variance, and collinearity, 2) improve the quality of samples to account for sparsity, variance, and collinearity
In the first approach, appropriate training, testing, and validation sets could be constructed by combining multiple small individual rare disease cohorts [TODO: Link to experimental design box #185].
In fact, this is often required for the study of rare diseases in the authors' experience.
In doing so, special attention should be directed towards harmonization since data collection can differ from cohort to cohort.
Without careful selection of aggregation methods, one may introduce technical variability into the aggregated dataset which can negatively impact the ML model's ability to learn or detect meaningful signal.
Steps such as reprocessing the data using a single pipeline, using batch correction methods [@doi:10.1093/biostatistics/kxj037; @doi:10.1093/nar/gku864], and normalizing raw values [@doi:10.1186/gb-2010-11-3-r25] may be necessary to mitigate unwanted technical variability.

In the second approach,  small but meaningfully generated datasets can greatly enhance the performance of ML models in the context of rare disease.
Specifically, improving labeling of data is critical in accounting for sparsity and variance in the data. 
In our experience, collaboration with domain experts has proved to be critical in gaining insight into potential sources of variation in the datasets.
An anecdotal example from the authors' personal experience: conversations with a rare disease clinician revealed that samples in a particular tumor dataset were collected using vastly different surgical techniques (laser ablation and excision vs standard excision). 
This information that was not readily available to non-experts, but was obvious to the clinician. 
Addition of this kind of important metadata or labels to the samples can greatly help ML models become more effective in extracting biologically relevant patterns.
Such instances underline the fact that continuous collaboration with domain experts and the sharing of well-annotated data is needed to generate robust datasets in the future.
Ideally, structure in the composite datasets under study will be aligned with variables of interest, such as phenotype labels if available; if instead samples from the same cohort tend to group together regardless of phenotype, revisiting the construction of the dataset is warranted.
In the next section, we will discuss approaches that can aid in identifying and visualizing structure in datasets.
