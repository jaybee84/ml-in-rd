## Constructing machine learning-ready rare disease datasets

High-throughput ‘omic’ assays generate thousands of measurements in the case of transcriptomic sequencing to billions of measurements in the case of whole genome sequencing, resulting in high-dimensional datasets, regardless of the underlying disease or condition being assayed. 
A typical rare disease dataset consists of a small number of samples[@doi:10.1186/s13023-020-01424-6] leading to the “curse of dimensionality” (i.e., few samples but many features), which can lead to spurious results or models that do not generalize to new datasets [@doi:10.1038/nrc2294].
More features often mean increased missing observations (_sparsity_), more dissimilarity between samples (_variance_), and increased redundancy between individual features or combinations of features (_multicollinearity_) [@doi:10.1038/s41592-018-0019-x], all of which contribute to a challenges in ML implementation.

One of the important factors in machine learning is performance (e.g. the accuracy of a supervised model in identifying patterns relevant for the biological question of interest, or the reliability of an unsupervised model in identifying hypothetical biological patterns that are supported by post-hoc validation and research). 
When small sample sizes compromise an ML model’s performance, then two approaches can be taken to manage sparsity, variance, and multicollinearity: 1) increase the number of samples, 2) improve the quality of samples. 
In the first approach, appropriate training, evaluation, and held-out validation sets could be constructed by combining multiple rare disease cohorts (Figure [@fig:1]a, Box 1). 
When combining datasets, special attention should be directed towards data harmonization since data collection methods can differ from cohort to cohort. 
Without careful selection of aggregation methods, one may introduce variability into the combined dataset that can negatively impact the ML model’s ability to learn or detect meaningful signals. 
Steps such as reprocessing the data using a single pipeline, using batch correction methods [@doi:10.1093/biostatistics/kxj037; @doi:10.1093/nar/gku864], and normalizing raw values appropriately without affecting the underlying variance in the data [@doi:10.1186/gb-2010-11-3-r25, @doi:10.1371/journal.pcbi.1003531, @doi:10.1186/s13059-014-0550-8] may be necessary to mitigate unwanted variability. (Figure [@fig:1]a)
Data harmonization may also entail the standardization of sample labels, for example, using biomedical ontologies to normalize how samples are annotated across multiple datasets.

Another way to improve the quality of a dataset is to improve the accuracy of metadata (both the description of technical variables and biologically relevant phenotypes) for each sample in the dataset. 
This may increase the effectiveness of ML models in extracting biologically relevant patterns from small datasets. 
The recognized need for improved labeling of, for instance, genomic data is highlighted by the recent introduction of the Phenopackets standard for sharing clinical phenotype data [@url:https://www.ga4gh.org/news/phenopackets-standardizing-and-exchanging-patient-phenotypic-data/; @url:https://phenopacket-schema.readthedocs.io/en/2.0.0/basics.html].
Collaboration with domain experts to boost the value of research datasets through careful annotation, and subsequent sharing of well-annotated datasets, is required to foster effective use of datasets in the future.

How does one know if a composite dataset has undergone proper harmonization and annotation? 
Ideally, the structure of the composite dataset reflects differences in variables of interest, such as phenotype labels. 
If the samples from the same cohort tend to group together regardless of phenotype, this suggests that the datasets used to generate the composite dataset need to be corrected to overcome differences in how the data were generated or collected. 
In the next section, we will discuss approaches that can aid in identifying and visualizing structure in datasets to determine whether composite rare disease datasets are appropriate for use in ML.

