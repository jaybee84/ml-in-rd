### Techniques that build on prior knowledge and indirectly related data are necessary for many rare disease applications {.page_break_before}

#### Wisdom of the crowd: rare disease applications of ensemble methods
Implementing machine learning on data with low sample size and high label uncertainty can lead to unstable predictions. 
In such cases various machine learning methods together (also called _ensemble learning_) can help increase accuracy and stability of the predictions.
Ensemble learning can use multiple similar approaches stitched together to reach a consensus, or can be a collection of different approaches that perform better compared to any single algorithm.
For example, ensemble learning methods like random forests use bootstrap aggregation (or _bagging_) of independent decision trees that use similar parameters but different paths to form a consensus about the important predictive features hidden in the dataset [@doi:10.1186/1472-6947-13-134, @doi:10.1023/A:1010933404324, @doi:10.1214/aos/1031689014, @doi:10.1177/2045894019890549, @doi:10/btzfh6].
However, successful application of consensus based ensemble learning requires "gold standard" data where the diagnosis or label of a data point in the training dataset has very little uncertainty (or "label-noise") associated with it [@doi:10.1093/jamia/ocw028]. 
In most cases of rare disease, due to the inherent nature of being less defined, the symptoms as well as any underlying biology comes with a reasonable amount label-noise leading to a _silver standard_ dataset[@doi:10.1109/TNNLS.2013.2292894, @doi:10.1093/jamia/ocw028].
In such datasets, ensemble learning or _cascade learning_ is used where multiple methods leveraging distinct underlying assumptions are used in tandem and augmented with algorithms like AdaBoost (_boosting_) to capture stable patterns existing in the silver standard data and reduce uncertainty [@doi:10.1109/CVPR.2001.990537, @doi:10.1007/978-3-540-75175-5_16, @doi:10.1109/ICPR.2004.1334680].
A variation of cascade learning implemented to identify rare disease patients from electronic health records from the general population utilized independent steps for feature extraction (using word2vec [@arXiv:1301.3781v3]), preliminary prediction (ensemble of decision trees with penalization for excessive tree-depth), and prediction refinement (using similarity of data points to resolve sample labels) [@pmid:30815073].
This cascade learner benefited from the independence of the feature extraction step and the prediction refinement step from the preliminary classification of the labeled dataset to find stable patterns and perform better than other ensemble methods when implemented on this silver standard dataset.

In datasets with multiple classes, most cascade classifiers follow a _one-classifier-at-a-time_ approach where algorithms at each level predict all classes involved.
But instances where the need for high prediction accuracy for one class outweighs other classes, further modification of the cascade learning efforts is required.
An example of such modification was implemented for triaging psychiatric patients where the identification of one class of psychiatric patients ("severe") far outweighed the need for optimized overall classification accuracy [@pmid:30380082].
Due to the requirements of the problem, a _one-class-at-a-time_ cascade learning approach was adopted, where at each stage a binary classifier was used to predict a specific class against all others.
The final model implemented all models together each identifying one class sequentially and the union of the predictions of all the different models as the final prediction.
The cascade classifiers using the one-class-at-a-time approach were found to perform better than multi-class ensemble classifiers in most cases.

Thus ensemble learning can be helpful in producing stable predictions from rare disease data, but the choice of using _bagging_, _boosting_, independent algorithmic steps, or _one-class-at-a-time_ approach depends on the nature of the prediction question.
The limited success of the _bagging_ approach in rare disease has encouraged various methodological modifications as discussed above.
