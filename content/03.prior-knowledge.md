### Techniques that build on prior knowledge and indirectly related data are necessary for many rare disease applications

>This section will highlight promising approaches for analyzing rare disease data to extract biological insights. 
>We will discuss techniques like transfer learning, representation learning, cascade learning, integrative analysis, and knowledge-graph creation and use that leverage other knowledge and data sources to construct testable hypotheses from rare diseases datasets with limited sample sizes 1–8.

#### Representation learning

Representation learning, also called feature learning, is the process of learning features from raw data, where a feature is an individual variable or property.
An algorithm or approach will construct features as part of training and, in the case of supervised feature learning, use those features to predict labels on input data. 
Using an example from transcriptomics, an unsupervised method such as matrix factorization can be used to extract a low-dimensional representation of the gene-level data, learning features that are a combination of input genes' expression levels [@doi:10.1093/bioinformatics/btq503; @doi:10.1186/s13059-020-02021-3].
Low-dimensional representations trained on a collection of transcriptomic data can then be used as input to supervised machine learning methods [@doi:10.1186/s12859-020-3427-8]. 
Supervised neural networks used in medical imaging studies [@doi:10.1016/j.procs.2016.07.014] (reviewed in [@doi:10.1016/j.zemedi.2018.11.002] and [@doi:10.1098/rsif.2017.0387]), which are trained to predict labels or classes, are also an example of representation learning.

Whether or not a learned representation or set of features is _useful_ depends on the task at hand.
In a supervised setting, it may be sufficient for a feature to distinguish between classes, but if we hope to use a feature for biological discovery, we may prioritize intepretability.
For example, learned features in the medical imaging domain may be a series of edges that constitute a blood vessel formation that discriminates between disease states or the learned features may not align with characteristics recognized as important by domain experts at all.
From transcriptomics data, learned features could be coordinated sets of genes involved in a biological process that are descriptive in some way, but do not distinguish cases from controls.

In the rare disease domain, Dincer et al. leveraged publicly available acute myeloid leukemia (AML) gene expression data to improve the prediction of _in vitro_ drug responses [@doi:10.1101/278739]. 
The authors trained a variational autoencoder (VAE) on AML data that had been collected over time without the phenotypic information they were interested in–in this case, drug response. 
A VAE is an unsupervised neural network that learns a series of representations or encodings from data, where each learned attribute will have a probability distribution associated with it rather than a single value.
The authors used the learned attributes to encode a low-dimensional representation of held-out AML data with phenotype labels of interest, and used this low-dimensional representation as input to a classifier that predicted _in vitro_ drug response.

Representation learning tends to be data-intensive–many samples are required.
Though there were over 6500 publicly available AML samples from many different studies used as part of the training set in Dincer et al. [@doi:10.1101/278739], we expect that in other rare diseases considerably fewer samples will be available for training or, in the case of systemic diseases, studies may be from different tissues.
The study by Dincer and colleagues highlights another challenge: even if enough samples have been collected over time to support representation learning, these samples may not be associated with the deep phenotypic information that would maximize their scientific value.
In the next section, we will introduce methods or approaches that may be more broadly useful in rare diseases; representation learning underlies many of them.

#### Transfer learning

We focus on a series of approaches that are centered on the following concept: to realize the potential of machine learning for biological discovery in rare diseases, we often can not study an individual rare disease alone as samples are limited.
We may instead build on prior knowledge and large volumes of data that do not directly assay our disease of interest, but are closely-enough related to be valuable for discovery.
We can leverage shared features, whether they are biological patterns that are a normal part of development aberrant in a particular disease context or an imaging anomaly present in both rare and common diseases, for advancing our understanding.
We discuss transfer learning or domain adaptation, multitask learning, and few-shot learning approaches below.

* Transfer learning example - mention how representation learning or feature construction can be related/part of this approach
* Multitask learning example
* Few-shot learning example

