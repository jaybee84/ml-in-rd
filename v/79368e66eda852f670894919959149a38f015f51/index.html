<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Jineta Banerjee" />
  <meta name="author" content="Jaclyn N Taroni" />
  <meta name="author" content="Robert J Allaway" />
  <meta name="author" content="Deepashree Venkatesh Prasad" />
  <meta name="author" content="Justin Guinney" />
  <meta name="author" content="Casey Greene" />
  <meta name="dcterms.date" content="2022-11-11" />
  <meta name="keywords" content="rare disease, machine learning, transfer learning" />
  <title>Machine learning in rare disease</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Machine learning in rare disease" />
  <meta name="citation_title" content="Machine learning in rare disease" />
  <meta property="og:title" content="Machine learning in rare disease" />
  <meta property="twitter:title" content="Machine learning in rare disease" />
  <meta name="dc.date" content="2022-11-11" />
  <meta name="citation_publication_date" content="2022-11-11" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="Jineta Banerjee" />
  <meta name="citation_author_institution" content="Sage Bionetworks" />
  <meta name="citation_author_orcid" content="0000-0002-1775-3645" />
  <meta name="citation_author" content="Jaclyn N Taroni" />
  <meta name="citation_author_institution" content="Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation" />
  <meta name="citation_author_orcid" content="0000-0003-4734-4508" />
  <meta name="citation_author" content="Robert J Allaway" />
  <meta name="citation_author_institution" content="Sage Bionetworks" />
  <meta name="citation_author_orcid" content="0000-0003-3573-3565" />
  <meta name="twitter:creator" content="@allawayr" />
  <meta name="citation_author" content="Deepashree Venkatesh Prasad" />
  <meta name="citation_author_institution" content="Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation" />
  <meta name="citation_author_orcid" content="0000-0001-5756-4083" />
  <meta name="citation_author" content="Justin Guinney" />
  <meta name="citation_author_institution" content="Sage Bionetworks" />
  <meta name="citation_author_orcid" content="0000-0003-1477-1888" />
  <meta name="citation_author" content="Casey Greene" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania" />
  <meta name="citation_author_institution" content="Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation" />
  <meta name="citation_author_orcid" content="0000-0001-8713-9213" />
  <link rel="canonical" href="https://jaybee84.github.io/ml-in-rd/" />
  <meta property="og:url" content="https://jaybee84.github.io/ml-in-rd/" />
  <meta property="twitter:url" content="https://jaybee84.github.io/ml-in-rd/" />
  <meta name="citation_fulltext_html_url" content="https://jaybee84.github.io/ml-in-rd/" />
  <meta name="citation_pdf_url" content="https://jaybee84.github.io/ml-in-rd/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://jaybee84.github.io/ml-in-rd/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://jaybee84.github.io/ml-in-rd/v/79368e66eda852f670894919959149a38f015f51/" />
  <meta name="manubot_html_url_versioned" content="https://jaybee84.github.io/ml-in-rd/v/79368e66eda852f670894919959149a38f015f51/" />
  <meta name="manubot_pdf_url_versioned" content="https://jaybee84.github.io/ml-in-rd/v/79368e66eda852f670894919959149a38f015f51/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Machine learning in rare disease</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://jaybee84.github.io/ml-in-rd/v/79368e66eda852f670894919959149a38f015f51/">permalink</a>)
was automatically generated
from <a href="https://github.com/jaybee84/ml-in-rd/tree/79368e66eda852f670894919959149a38f015f51">jaybee84/ml-in-rd@79368e6</a>
on November 11, 2022.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Jineta Banerjee</strong>
<sup>☯</sup><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-1775-3645">0000-0002-1775-3645</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jaybee84">jaybee84</a><br>
<small>
Sage Bionetworks
· Funded by Neurofibromatosis Therapeutic Acceleration Program; Children’s Tumor Foundation
</small></p></li>
<li><p><strong>Jaclyn N Taroni</strong>
<sup>☯</sup><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-4734-4508">0000-0003-4734-4508</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jaclyn-taroni">jaclyn-taroni</a><br>
<small>
Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation
</small></p></li>
<li><p><strong>Robert J Allaway</strong>
<sup></sup><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-3573-3565">0000-0003-3573-3565</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/allaway">allaway</a>
· <img src="images/twitter.svg" class="inline_icon" alt="Twitter icon" />
<a href="https://twitter.com/allawayr">allawayr</a><br>
<small>
Sage Bionetworks
· Funded by Neurofibromatosis Therapeutic Acceleration Program; Children’s Tumor Foundation
</small></p></li>
<li><p><strong>Deepashree Venkatesh Prasad</strong>
<sup></sup><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-5756-4083">0000-0001-5756-4083</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/dvenprasad">dvenprasad</a><br>
<small>
Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation
</small></p></li>
<li><p><strong>Justin Guinney</strong>
<sup></sup><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-1477-1888">0000-0003-1477-1888</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/jguinney">jguinney</a><br>
<small>
Sage Bionetworks
· Funded by Neurofibromatosis Therapeutic Acceleration Program; Children’s Tumor Foundation
</small></p></li>
<li><p><strong>Casey Greene</strong>
<sup>✉</sup><br>
<img src="images/orcid.svg" class="inline_icon" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8713-9213">0000-0001-8713-9213</a>
· <img src="images/github.svg" class="inline_icon" alt="GitHub icon" />
<a href="https://github.com/cgreene">cgreene</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania; Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation
</small></p></li>
</ul>
<p><sup>☯</sup>: These authors contributed equally to this work.</p>
<p><sup>✉</sup>: Corresponding author; Please address your emails to <a href="mailto:casey.s.greene@cuanschutz.edu" class="email">casey.s.greene@cuanschutz.edu</a>.</p>
<h2 class="page_break_before" id="synopsis">Synopsis</h2>
<p>(Instructions: Describe the background, basic structure of the article, list material to be covered indicating depth of coverage, how they are logically arranged, include recent pubs in the area, 300-500 words)</p>
<p>The advent of high-throughput profiling methods such as genomics and other technologies has accelerated basic research and made deep molecular characterization of patient samples routine.
These approaches provide a rich portrait of genes, molecular pathways, and cell types involved in complex phenotypes.
Machine learning can be a useful tool to extract disease-relevant patterns from high dimensional datasets.
However, depending on the complexity of the biological question, machine learning often requires a large number of samples to identify recurrent and biologically meaningful patterns.
Rare diseases are inherently limited in clinical cases and thus have few samples to study.
Precision medicine also presents a similar challenge, where patients with common diseases are partitioned into small subsets of patients based on particular characteristics.
In this perspective, we outline the challenges and emerging solutions for using machine learning in the context of small sample sets, specifically that of rare diseases.
Advances in machine learning methods for rare disease are likely to be informative for applications beyond rare diseases in which sample sizes are small but datasets are complex (e.g., using genomics data for predictive modeling in precision medicine).
We propose that the methods community prioritizes the development of machine learning techniques for rare disease research.</p>
<h2 class="page_break_before" id="introduction">Introduction</h2>
<p>Rare disease researchers increasingly depend on machine learning to analyze complex datasets.
A systematic review of the application of ML in rare diseases using the European Union definition of rare disease (fewer than 5 patients per 10,000 people) uncovered 211 human data studies that used ML to study 74 different rare diseases over the last 10 years.<span class="citation" data-cites="12bOkHKJU">[<a href="#ref-12bOkHKJU" role="doc-biblioref">1</a>]</span>
Indeed, ML can be a powerful tool in biomedical research but it does not come without pitfalls, some of which are magnified in a rare disease context.<span class="citation" data-cites="1DlwO80sJ">[<a href="#ref-1DlwO80sJ" role="doc-biblioref">2</a>]</span>
In this perspective, we discuss considerations for using two types of ML – supervised and unsupervised learning – in the study of rare diseases, with a specific focus on high-dimensional molecular data.</p>
<p>ML algorithms are computational methods that can identify patterns in data, and can use information about these patterns to perform tasks (e.g., pick out important data points or predict unknown outcomes).
<em>Supervised learning</em> algorithms must be trained with data that has specific phenotypes or patient outcome labels.
Supervised methods can learn correlations of features (e.g., expression measurements of a large number of genes) with the outcome labels to predict the outcome in unseen or new data, such as predicting which patients will or will not respond to treatment.
Therefore, if the goal of a study is to classify patients with a rare disease into well-known molecular subtypes based on high-throughput molecular profiling, a supervised ML algorithm is appropriate to carry out this task.
Conversely, unsupervised learning algorithms can learn patterns or features from unlabeled training data.
In the absence of known molecular subtypes, unsupervised ML approaches can be applied to identify groups of samples that are similar and may have distinct patterns of pathway activation <span class="citation" data-cites="18Ysd1Qjh">[<a href="#ref-18Ysd1Qjh" role="doc-biblioref">3</a>]</span>.
Unsupervised approaches can also extract combinations of features (e.g., genes) that may describe a certain cell type or pathway.</p>
<p>While ML can be a useful tool, there are challenges in applying ML to rare disease datasets.
ML methods are generally most effective when using large datasets[TODO: add ref]; analyzing high dimensional biomedical data (i.e. data with typically &gt; 1000 features, e.g. 20,000 genes) from rare diseases datasets that typically contain 20 to 99 samples is challenging<span class="citation" data-cites="wwF0mDld 12bOkHKJU">[<a href="#ref-12bOkHKJU" role="doc-biblioref">1</a>,<a href="#ref-wwF0mDld" role="doc-biblioref">4</a>]</span>.
Small datasets lead to a lack of statistical power and magnify the susceptibility of ML methods to misinterpretation and unstable performance.
For example, with insufficient data, an unsupervised model will fail to identify patterns that are useful for biological discovery (i.e. “perform” poorly).
Similarly, supervised models require datasets where the phenotype labels have very little uncertainty (or “label-noise”) <span class="citation" data-cites="G5HC64pk">[<a href="#ref-G5HC64pk" role="doc-biblioref">5</a>]</span> – termed “gold standard” datasets.
Datasets with high label-noise decrease prediction accuracy and necessitate larger sample sizes during training <span class="citation" data-cites="16kfJJap4">[<a href="#ref-16kfJJap4" role="doc-biblioref">6</a>]</span>, and rare disease datasets often come with significant label-noise (e.g., silver standard datasets) due to limited understanding of the underlying biology or evolving clinical classifications.
Additionally, a supervised ML model is of limited utility if it can only accurately predict phenotype labels in the data it was trained on, also known as overfitting.
Instead, most researchers aspire to develop models that generalize or maintain performance when applied to new data that has not yet been “seen” by the model.</p>
<p>While we expect ML in rare disease research to continue to increase in popularity, specialized computational methods that can learn patterns from small datasets and can generalize to newly acquired data are required for rare disease applications <span class="citation" data-cites="Zoj0hKzb">[<a href="#ref-Zoj0hKzb" role="doc-biblioref">7</a>]</span>.
In this perspective, we first highlight approaches that address or better tolerate the limitations of rare disease data, and then discuss the future of ML applications in rare disease.</p>
<h2 id="constructing-machine-learning-ready-rare-disease-datasets">Constructing machine learning-ready rare disease datasets</h2>
<p>High-throughput ‘omic’ assays generate thousands of measurements in the case of transcriptomic sequencing to billions of measurements in the case of whole genome sequencing, resulting in high-dimensional datasets, regardless of the underlying disease or condition being assayed.
A typical rare disease dataset consists of a small number of samples<span class="citation" data-cites="12bOkHKJU">[<a href="#ref-12bOkHKJU" role="doc-biblioref">1</a>]</span> leading to the “curse of dimensionality” (i.e., few samples but many features), which can lead to spurious results or models that do not generalize to new datasets <span class="citation" data-cites="KOD2gdVS">[<a href="#ref-KOD2gdVS" role="doc-biblioref">8</a>]</span>.
More features often means increased missing observations (<em>sparsity</em>), more dissimilarity between samples (<em>variance</em>), and increased redundancy between individual features or combinations of features (<em>multicollinearity</em>) <span class="citation" data-cites="c6DKSPdm">[<a href="#ref-c6DKSPdm" role="doc-biblioref">9</a>]</span>, all of which contribute to a challenges in ML implementation.</p>
<p>One of the important factors in machine learning is performance (e.g. the accuracy of a supervised model in identifying patterns relevant for the biological question of interest, or the reliability of an unsupervised model in identifying hypothetical biological patterns that are supported by post-hoc validation and research).
When small sample sizes compromise an ML model’s performance, then two approaches can be taken to manage sparsity, variance, and multicollinearity: 1) increase the number of samples, 2) improve the quality of samples.
In the first approach, appropriate training, evaluation, and held-out validation sets could be constructed by combining multiple rare disease cohorts (Figure <a href="#fig:1">1</a>a, Box 1).
When combining datasets, special attention should be directed towards data harmonization since data collection methods can differ from cohort to cohort.
Without careful selection of aggregation methods, one may introduce variability into the combined dataset that can negatively impact the ML model’s ability to learn or detect meaningful signals.
Steps such as reprocessing the data using a single pipeline, using batch correction methods <span class="citation" data-cites="1HahRBkyb XJiH4M02">[<a href="#ref-1HahRBkyb" role="doc-biblioref">10</a>,<a href="#ref-XJiH4M02" role="doc-biblioref">11</a>]</span>, and normalizing raw values <span class="citation" data-cites="19neBSN5B">[<a href="#ref-19neBSN5B" role="doc-biblioref">12</a>]</span> may be necessary to mitigate unwanted variability. (Figure <a href="#fig:1">1</a>a)
Data harmonization may also entail the standardization of sample labels, for example, using biomedical ontologies to normalize how samples are annotated across multiple datasets.</p>
<p>Another way to improve the quality of a dataset is to improve the accuracy of metadata (both the description of technical variables and biologically relevant phenotypes) for each sample in the dataset.
This may increase the effectiveness of ML models in extracting biologically relevant patterns from small datasets.
The recognized need for improved labeling of, for instance, genomic data is highlighted by the recent introduction of the Phenopackets standard for sharing clinical phenotype data <span class="citation" data-cites="LE2agOLt g6a6KX9t">[<a href="#ref-LE2agOLt" role="doc-biblioref">13</a>,<a href="#ref-g6a6KX9t" role="doc-biblioref">14</a>]</span>.
Collaboration with domain experts to boost the value of research datasets through careful annotation, and subsequent sharing of well-annotated datasets, is required to foster effective use of datasets in the future.</p>
<p>How does one know if a composite dataset has undergone proper harmonization and annotation?
Ideally, the structure of the composite dataset reflects differences in variables of interest, such as phenotype labels.
If the samples from the same cohort tend to group together regardless of phenotype, this suggests that the datasets used to generate the composite dataset need to be corrected to overcome differences in how the data were generated or collected.
In the next section, we will discuss approaches that can aid in identifying and visualizing structure in datasets to determine whether composite rare disease datasets are appropriate for use in ML.</p>
<div id="fig:1" class="fignos">
<figure>
<img src="images/figures/pdfs/figure-1-combining-datasets-resized.png" alt="" /><figcaption><span>Figure 1:</span> Combining datasets to increase data for training machine learning models. a) Appropriate methods are required to combine smaller datasets into a larger composite dataset: The left panel shows multiple small rare disease datasets that need to be combined to form a dataset of higher sample size. The color of the samples suggest classes or groups present in the datasets. The shape represents the dataset of origin. The middle panel shows methods that may be used to combine the datasets while accounting for dataset-specific technical differences. The right panel shows Principal Component Analysis of the combined datasets to verify proper integration of samples in the larger dataset. b) Composite datasets can be used to make training, evaluation, and validation datasets for machine learning: Left panel shows the division of the composite dataset into training dataset and a held-out validation dataset (top). Shapes indicate the study of origin. The held-out validation set is a separate study that has not been seen by the model. The training set is further divided into training and evaluation datasets for k-fold cross-validation (in this example k=4), where each fold contains all samples from an individual studyThis approach is termed study-wise cross validation, and supports the goal of training models that generalize to unseen cohorts.The panel on the right shows the class distribution of the training, evaluation, and held-out validation datasets.</figcaption>
</figure>
</div>
<h2 id="box-1-understanding-experimental-design-of-ml-to-inform-requirements-for-data">Box 1: Understanding experimental design of ML to inform requirements for data</h2>
<h3 id="components-of-ml-experiments">Components of ML experiments</h3>
<p>Machine learning (ML) algorithms identify patterns that explain or fit a given dataset.
Every ML algorithm goes through <em>training</em>, where it identifies underlying patterns in a given dataset to create a “trained” algorithm (a model), and <em>testing</em>, where the model applies the identified patterns to unseen data points.
Typically, a ML algorithm is provided with: 1. a <em>training dataset</em> , 2. an <em>evaluation dataset</em> , 3. a <em>held-out validation dataset</em>.
These input data can be images, text, numbers, or other types of data which are typically encoded as a numerical representation of the input data.
A training dataset is used by the model to learn underlying patterns from the features present in the data of interest.
An evaluation dataset is a small and previously unused dataset which is used during the training phase to help the model iteratively update its parameters (i.e., <em>hyperparameter tuning</em> or <em>model tuning</em>).
In many cases, a large training set may be subdivided to form a smaller training dataset and the evaluation dataset, both of which are used to train the model.
In the testing phase, a completely new or unseen test dataset or held-out validation set is used to test whether the patterns learned by the model hold true in new data (i.e., they are <em>generalizable</em>).
While the evaluation dataset helps us refine a model’s fit to patterns in the training data, the held-out validation set helps us test the generalizability of the model.</p>
<p>If a model is generalizable, it is able to make accurate predictions on new data.
High generalizability of a model on previously unseen data suggests that the model has identified important patterns in the data that are not unique to the data used for training and tuning.
Generalizability can be affected if <em>data leakage</em> occurs during training of the model, i.e., if a model is exposed to the same or related data points in both the training set and the held-out test set.
Ensuring absence of any overlap or relatedness among data points or samples used in the training set and evaluation set is important to avoid data leakage during model training.
Specifically, in cases of rare genetic diseases where, for example, many samples can contain familial relationships or data from the same patient could be collected by multiple specialists at different clinical facilities, special care should be taken while crafting the training and testing sets to ensure that no data leakage occurs and the trained model has high generalizability.</p>
<h3 id="training-and-testing">Training and testing</h3>
<p>The implementation of a ML experiment begins with splitting a single dataset of interest such that a large proportion of the data (e.g., 70-90%) is used for training (generally subdivided into the training dataset and the evaluation dataset), and the remaining data is used for testing or validation (as the held-out validation dataset).
Ideally, a <em>held-out validation dataset</em> is an entirely new study or cohort, as researchers typically aim to build models that generalize to unseen, newly generated data.
In rare diseases where multiple datasets may be combined to make a large enough training dataset, special care should be taken to standardize the features and the patterns therein.
Although ML algorithms generally expect that datasets have uniform features, normalizing training and testing data together may introduce similarities between samples (causing inadvertent data leakage) that hamper the goal of training models that are highly generalizable.</p>
<p>The iterative training phase helps the model learn important patterns in the training dataset and then use the evaluation dataset to test for errors in prediction and update its learning parameters (hyperparameter tuning).
The method by which the evaluation dataset tests the performance of the trained model and helps update the hyperparameters is called cross-validation.
There are multiple approaches that can be deployed to maximally utilize the available data when generating training and evaluation datasets e.g., leave-p-out cross-validation, leave-one-out cross-validation, k-fold cross-validation, Monte-Carlo random subsampling cross-validation.<span class="citation" data-cites="sFnMb5kB">[<a href="#ref-sFnMb5kB" role="doc-biblioref">15</a>]</span>
In the case of k-fold cross-validation, a given dataset is shuffled randomly and split into <em>k</em> parts.
One of the k parts is reserved as the <em>evaluation dataset</em> and the rest are cumulatively used as the <em>training dataset</em>.
In the next iteration, a different part is used as the evaluation dataset, while the rest are used for training.
To avoid data leakage, and to promote generalization of models to new studies, researchers can use <em>study-wise cross-validation</em>, such that all samples from a study are in the same fold and no individual study is represented in both the training and evaluation datasets.
Once the model has iterated through all k parts of the training and evaluation datasets, it is ready to be tested on the held-out validation dataset.(Figure <a href="#fig:1">1</a>b)</p>
<p>The held-out validation dataset is exposed to the model only once to estimate the accuracy of the model.
High accuracy of a model during cross-validation but low accuracy on the held-out dataset is a sign that the model has become overfit to the training set and has low generalizability.
If this is encountered, researchers should revisit the construction of the dataset to make sure they meet the best practices outlined above.</p>
<h2 id="learning-representations-from-rare-disease-data">Learning representations from rare disease data</h2>
<p>Dimensionality reduction methods can help explore and visualize underlying structure in the data (e.g., <span class="citation" data-cites="AZCOtvbC">[<a href="#ref-AZCOtvbC" role="doc-biblioref">16</a>]</span>), to define sample subgroups (e.g., <span class="citation" data-cites="12XiicejZ">[<a href="#ref-12XiicejZ" role="doc-biblioref">17</a>]</span>, or for feature selection and extraction during application of specific machine learning models <span class="citation" data-cites="15yIhkDpY">[<a href="#ref-15yIhkDpY" role="doc-biblioref">18</a>]</span> (Figure [<a href="#fig:2">2</a>]c).
These methods ‘compress’ information from a large number of features into a smaller number of features in an unsupervised manner <span class="citation" data-cites="1HICCTHVj qRi1wkz4 BsfyICXU 1Ak4JFhvU gqTS2Uy7">[<a href="#ref-1HICCTHVj" role="doc-biblioref">19</a>,<a href="#ref-qRi1wkz4" role="doc-biblioref">20</a>,<a href="#ref-BsfyICXU" role="doc-biblioref">21</a>,<a href="#ref-1Ak4JFhvU" role="doc-biblioref">22</a>,<a href="#ref-gqTS2Uy7" role="doc-biblioref">23</a>]</span> (Figure <a href="#fig:2">2</a>).
An example of a method that is commonly used for dimensionality reduction is principal components analysis (PCA).
PCA identifies new features or dimensions, termed <em>principal components</em> (PCs), that are combinations of original features.
The PCs are calculated in a way that maximizes the amount of information (variance) they contain and ensures that each PC is uncorrelated with the other PCs. <span class="citation" data-cites="qRi1wkz4">[<a href="#ref-qRi1wkz4" role="doc-biblioref">20</a>]</span>
In practice, researchers often use the first few PCs to reduce the dimensionality without removing what may be important or informative variability in the data.
Other methods like multidimensional scaling (MDS), t-distributed stochastic neighbor embedding (t-SNE), and uniform manifold approximation and projection (UMAP) can also help identify useful patterns in the data, though t-SNE and UMAP require adjusting hyperparameters to get results that are not misleading or not reproducible. <span class="citation" data-cites="BsfyICXU Lby4PmSX">[<a href="#ref-BsfyICXU" role="doc-biblioref">21</a>,<a href="#ref-Lby4PmSX" role="doc-biblioref">25</a>]</span>
Testing multiple dimensionality reduction methods, rather than a single method, may be necessary to obtain a more comprehensive portrait of the data. <span class="citation" data-cites="NsW0qxZF">[<a href="#ref-NsW0qxZF" role="doc-biblioref">26</a>]</span>
Nguyen and Holmes discuss additional important considerations for using dimensionality reduction methods such as selection criteria and interpretation of results. <span class="citation" data-cites="Pyg7FNxd">[<a href="#ref-Pyg7FNxd" role="doc-biblioref">27</a>]</span>
Beyond dimensionality reduction, other unsupervised learning approaches such as k-means clustering or hierarchical clustering have been used to characterize the structure present in genomic or imaging data. <span class="citation" data-cites="11QYztxcm U2RMvmE5">[<a href="#ref-11QYztxcm" role="doc-biblioref">28</a>,<a href="#ref-U2RMvmE5" role="doc-biblioref">29</a>]</span></p>
<p>Representation learning approaches (which include dimensionality reduction) learn low-dimensional representations (composite features) from the raw data.
For example, representation learning through matrix factorization methods can extract features from transcriptomics datasets that are made of combinations of gene expression values. <span class="citation" data-cites="ChpTIk5j 1DrhKLdVp NsW0qxZF">[<a href="#ref-NsW0qxZF" role="doc-biblioref">26</a>,<a href="#ref-ChpTIk5j" role="doc-biblioref">30</a>,<a href="#ref-1DrhKLdVp" role="doc-biblioref">31</a>]</span></p>
<p>When applied to complex biological systems, representation learning generally requires many samples and therefore may appear to aggravate the curse of dimensionality.
However, it can be a powerful tool to learn low-dimensional patterns from large datasets and then find those patterns in smaller, related datasets.
In later sections, we will discuss this method of leveraging large datasets to reduce dimensionality in smaller datasets, also known as feature-representation-transfer learning.
Once the dimensions of the training dataset have been reduced, model training can proceed using the experimental design as outlined in Box 1.</p>
<div id="fig:2" class="fignos">
<figure>
<img src="content/images/figures/pdfs/figure2-representation-learning-resized.png" alt="" /><figcaption><span>Figure 2:</span> Representation learning can extract useful features from high dimensional data. a) The data (e.g., transcriptomic data) are highly dimensional, having thousands of features (displayed as Fa-Fz). Samples come from two separate classes (purple and green row annotation). b) In the original feature space, Fa and Fb do not separate the two classes (purple and green) well. c) A representation learning approach learns new features (e.g., New Feature 1, a combination of Fa, Fb …. Fz, and New Feature 2, a different combination of Fa, Fb …. Fz). New Feature 2 distinguishes class, whereas New Feature 1 may capture some other variable such as batch (not represented). New features from the model can be used to interrogate the biology of the input samples, develop classification models, or use other analytical techniques that would have been more difficult with the original dataset dimensions.</figcaption>
</figure>
</div>
<h2 id="reducing-misinterpretation-of-model-output-with-statistical-techniques">Reducing misinterpretation of model output with statistical techniques</h2>
<p>Machine learning methods generally work well on data that meet a few critical assumptions.
First, the dataset contains an equal number of samples for all categories (no “class imbalance”).
Second, the dataset is complete; all samples have measurements for all variables in the dataset (i.e., the dataset is not “sparse”, meaning that it is not missing data for some of the samples).
Third, there is no ambiguity about the labels for the samples in the dataset (i.e., no “label-noise”).</p>
<p>Rare disease datasets, however, violate many of these assumptions.
There is generally a high class imbalance due to small number of samples for specific classes (e.g., only a few patients with a particular rare disease in a health records dataset), the data are often sparse, and there may be abundant label-noise due to incomplete understanding of the disease.
All of these contribute to low signal to noise ratio in rare disease datasets.
Thus, applying ML to rare disease data without addressing the aforementioned shortcomings may lead to models that have low reproducibility or are hard to interpret.</p>
<p>Class imbalance in datasets can be addressed using decision tree-based ensemble learning methods (e.g., random forests). <span class="citation" data-cites="YuD6CEIZ">[<a href="#ref-YuD6CEIZ" role="doc-biblioref">32</a>]</span> (Figure[??]a)
Random forests use resampling (with replacement) based techniques to form a consensus about the important predictive features identified by the decision trees. <span class="citation" data-cites="16uxtBBBG 14J3u9pnR">[<a href="#ref-16uxtBBBG" role="doc-biblioref">33</a>,<a href="#ref-14J3u9pnR" role="doc-biblioref">34</a>]</span>
Additional approaches like combining random forests with resampling without replacement can generate confidence intervals for the model predictions by iteratively exposing the models to incomplete datasets, mimicking real world cases where most rare disease datasets are incomplete <span class="citation" data-cites="wv3oXzet">[<a href="#ref-wv3oXzet" role="doc-biblioref">35</a>]</span>.
Resampling approaches are most helpful in constructing confidence intervals for algorithms that generate the same outcome every time they are run (i.e., deterministic models).
For decision trees that choose features at random for selecting a path to the outcome (i.e., are non-deterministic), resampling approaches can be helpful in estimating the reproducibility of the model.</p>
<p>In situations where decision tree-based ensemble methods fail when they are applied to rare disease datasets, cascade learning is a viable alternative. <span class="citation" data-cites="HWIKCkVI">[<a href="#ref-HWIKCkVI" role="doc-biblioref">36</a>]</span>
In cascade learning, multiple methods leveraging distinct underlying assumptions are used in tandem to capture stable patterns existing in the dataset <span class="citation" data-cites="Q25GV92r ThoSnmu3 doi:10.1109/icpr.2004.1334680">[<span class="citeproc-not-found" data-reference-id="doi:10.1109/icpr.2004.1334680"><strong>???</strong></span>,<a href="#ref-Q25GV92r" role="doc-biblioref">37</a>,<a href="#ref-ThoSnmu3" role="doc-biblioref">38</a>]</span>.
For example, a cascade learning approach for identifying rare disease patients from electronic health record data incorporated independent steps for feature extraction (word2vec <span class="citation" data-cites="1GhHIDxuW">[<a href="#ref-1GhHIDxuW" role="doc-biblioref">39</a>]</span>), preliminary prediction with ensembled decision trees, and then prediction refinement using data similarity metrics. <span class="citation" data-cites="HWIKCkVI">[<a href="#ref-HWIKCkVI" role="doc-biblioref">36</a>]</span>
Combining these three methods resulted in better overall prediction when implemented on a silver standard dataset, as compared to a model that used ensemble-based prediction alone.
In addition to cascade learning, other approaches that can better represent rare classes using class re-balancing techniques like inverse sampling probability weighting <span class="citation" data-cites="orPSUYei">[<a href="#ref-orPSUYei" role="doc-biblioref">40</a>]</span>, inverse class frequency weighting <span class="citation" data-cites="fMU2mxEc">[<a href="#ref-fMU2mxEc" role="doc-biblioref">41</a>]</span>, oversampling of rare classes <span class="citation" data-cites="U1rmHW8N">[<a href="#ref-U1rmHW8N" role="doc-biblioref">42</a>]</span>, or undersampling of majority class <span class="citation" data-cites="19Gunahwx">[<a href="#ref-19Gunahwx" role="doc-biblioref">43</a>]</span> may also help mitigate limitations due to class imbalance.</p>
<p>The presence of label-noise and sparsity in the data can lead to overfitting of models to the training data, meaning that the models show high prediction accuracy on the training data but low prediction accuracy (and large prediction errors) on new evaluation data.
Overfit models tend to rely on patterns that are unique to the training data (for example, the clinical vocabulary or clinical coding practices at a specific hospital), and not generalizable to new data (e.g., data collected at different hospitals). <span class="citation" data-cites="wFHvLXy8 SDzZeG0c">[<a href="#ref-wFHvLXy8" role="doc-biblioref">44</a>,<a href="#ref-SDzZeG0c" role="doc-biblioref">45</a>]</span>
Regularization can help in these scenarios.
Regularization is an approach by which a penalty or constraint is added to a model to avoid making large prediction errors.
These procedures can not only protect ML models as well as learned representations from poor generalizability caused by overfitting, but also reduce model complexity by reducing the feature space available for training <span class="citation" data-cites="biC8xxbd">[<a href="#ref-biC8xxbd" role="doc-biblioref">46</a>]</span>. (Figure[??]a)
Some examples of ML methods with regularization include ridge regression, LASSO regression, and elastic net regression <span class="citation" data-cites="JZNkB8d7">[<a href="#ref-JZNkB8d7" role="doc-biblioref">48</a>]</span>, among others.
Regularization is often used in rare variant discovery and immune cell signature discovery studies; much like rare disease, these examples need to accommodate sparsity in data.
For example, LASSO has been used to capture combinations of rare and common variants associated with specific traits. <span class="citation" data-cites="fPp30wsy">[<a href="#ref-fPp30wsy" role="doc-biblioref">49</a>]</span>
In this example, applying LASSO regularization reduced the number of common variants included as features in the final analysis generating a simpler model while reducing error in the association of common and rare variants with a specific trait.
In the context of rare immune cell signature discovery, variations of elastic-net regression were found to outperform other regression approaches <span class="citation" data-cites="lXiw1iso JkWXgEgV">[<a href="#ref-lXiw1iso" role="doc-biblioref">50</a>,<a href="#ref-JkWXgEgV" role="doc-biblioref">51</a>]</span>.
Thus, regularization methods like LASSO or elastic-net are beneficial in ML with rare observations, and are worth exploring in the context of rare diseases.<span class="citation" data-cites="biC8xxbd">[<a href="#ref-biC8xxbd" role="doc-biblioref">46</a>]</span>
Other examples of regularization that have been successfully applied to rare disease ML include Kullback–Leibler (KL) divergence loss or dropout during neural network training.
In a study using a variational autoencoder (VAE) (see Box 2: Definitions) for dimensionality reduction in gene expression data from acute myeloid leukemia (AML) samples, the KL loss between the input data and its low dimensional representation provided the regularizing penalty for the model. <span class="citation" data-cites="17HK9o457 EOUjThUk">[<a href="#ref-17HK9o457" role="doc-biblioref">52</a>,<a href="#ref-EOUjThUk" role="doc-biblioref">53</a>]</span>
In a study using a convolutional neural network (CNN) to identify tubers in MRI images from tuberous sclerosis patients, overfitting was minimized using the dropout regularization method which removed randomly chosen network nodes in each iteration of the CNN model generating simpler models in each iteration.<span class="citation" data-cites="i5ynU2dS">[<a href="#ref-i5ynU2dS" role="doc-biblioref">54</a>]</span>
Thus, depending on the learning method that is used, regularization approaches should be incorporated into data analysis when working with rare disease datasets.</p>
<p><a href="images/figures/pdfs/figure-3-resized.png" id="fig:3">Strategies to reduce misinterpretation of machine learning model output in rare disease. a) Bootstrapping: Left panel shows a small rare disease dataset, which can be resampled with replacement using bootstrap to form a large resampled dataset (middle panel). Running the same ML model on multiple resampled datasets generates a distribution of values for the importance scores for each feature utilized by the ML model (right panel), b) Cascade Learning: A schematic showing the different steps in a cascade learning approach for identifying rare disease patients from electronic health record data<span class="citation" data-cites="HWIKCkVI">[<a href="#ref-HWIKCkVI" role="doc-biblioref">36</a>]</span>. The bar plot in the middle panel schematically represents patient classification accuracy after ensemble learning. The accuracy is high for non-rare diseases, but low for rare diseases. The bar plot on the right panel depicts classification accuracy after implementation of cascade learning. The accuracy is high for both non-rare and rare diseases. c) Regularization: A schematic showing the concept of regularization to selectively learn relevant features. The samples (green and blue circles) in the rare disease dataset on left panel can be represented as a combination of features. Each horizontal bar in the middle panel (training set) represents a feature-by-sample heatmap for one sample each. In the held-out validation dataset, for a sample of unknown class (open circle), some features recapitulate the pattern present in the training set, while others do not. The right panel depicts accuracy of predicting the class of the open circles with or without using regularization during implementation of the ML models on rare disease data. Without regularization the classification accuracy is low due to presence of only a subset of learned features (denoted by dashed rectangle in middle panel), but with regularization this subset of features is sufficient to gain high classification accuracy.</a>]</p>
<h3 class="page_break_before" id="build-upon-prior-knowledge-and-indirectly-related-data">Build upon prior knowledge and indirectly related data</h3>
<p>Rare diseases often lack large, normalized datasets, limiting our ability to study key attributes of these diseases.
One strategy to overcome this is to integrate and explore rare disease information alongside other knowledge by combining a variety of different data types.
By using several data modalities (such as curated pathways, genetic data, or other data types), it may be possible to gain a better understanding of rare diseases (e.g., identifying novel genotype-phenotype relationships or opportunities for drug repurposing).
Knowledge graphs (KGs) which integrate related-but-different data types, provide a rich multimodal data source (e.g., Monarch Graph Database <span class="citation" data-cites="5cHHEM6Q">[<a href="#ref-5cHHEM6Q" role="doc-biblioref">55</a>]</span>, hetionet <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">56</a>]</span>, PheKnowLator <span class="citation" data-cites="1H2nqqKV7">[<a href="#ref-1H2nqqKV7" role="doc-biblioref">57</a>]</span>, and the Global Network of Biomedical Relationships <span class="citation" data-cites="CSiMoOrI">[<a href="#ref-CSiMoOrI" role="doc-biblioref">58</a>]</span>, Orphanet <span class="citation" data-cites="wjHFUHNC">[<a href="#ref-wjHFUHNC" role="doc-biblioref">59</a>]</span>).
These graphs connect genetic, functional, chemical, clinical, and ontological data so that relationships of data with disease phenotypes can be explored through manual review <span class="citation" data-cites="1DCdPxaef">[<a href="#ref-1DCdPxaef" role="doc-biblioref">60</a>]</span> or computational methods <span class="citation" data-cites="5FkKpSQe gVNjawAX">[<a href="#ref-5FkKpSQe" role="doc-biblioref">61</a>,<a href="#ref-gVNjawAX" role="doc-biblioref">62</a>]</span>. (Figure[??]a)
KGs may include links (also called edges) or nodes that are specific to the rare disease of interest (e.g., an FDA approved treatment would be a specific disease-compound edge in the KG) as well as edges that are more generalized (e.g., gene-gene interactions noted in the literature for a different disease). (Figure <a href="#fig:4">3</a>a)</p>
<p>Rare disease researchers can repurpose general (i.e., not rare disease-specific) biological or chemical knowledge graphs to answer rare disease-based research questions <span class="citation" data-cites="uDR1FuFx">[<a href="#ref-uDR1FuFx" role="doc-biblioref">63</a>]</span>.
There are a variety of tactics to sift through the large amounts of complex data in knowledge graphs.
One such tactic is to calculate the distances between nodes of interest (e.g., diseases and drugs to identify drugs for repurposing in rare disease <span class="citation" data-cites="uDR1FuFx">[<a href="#ref-uDR1FuFx" role="doc-biblioref">63</a>]</span>); this is often done by determining the “embeddings” (linear representations of the position and connections of a particular point in the graph) for nodes in the knowledge graph, and calculating the similarity between these embeddings.
Effective methods to calculate node embeddings that can generate actionable insights for rare diseases is an active area of research <span class="citation" data-cites="uDR1FuFx">[<a href="#ref-uDR1FuFx" role="doc-biblioref">63</a>]</span>.</p>
<p>Another application of KGs is to augment or refine a dataset <span class="citation" data-cites="1BjxYCRrD">[<a href="#ref-1BjxYCRrD" role="doc-biblioref">64</a>]</span>.
For example, Li et. al.<span class="citation" data-cites="gVNjawAX">[<a href="#ref-gVNjawAX" role="doc-biblioref">62</a>]</span> used a KG to identify linked terms in a medical corpus from a large number of patients, some with rare disease diagnoses.
They were able to augment their text dataset by identifying related terms in the clinical text to map them to the same term - e.g., mapping “cancer” and “malignancy” in different patients to the same clinical concept.
With this augmented and improved dataset, they were able to train and test a variety of text classification algorithms to identify rare disease patients within their corpus. (Figure [<a href="#fig:4">3</a>]b)</p>
<p>Finally, another possible tactic for rare disease researchers is to take a knowledge graph, or an integration of several knowledge graphs, and apply neural network-based algorithms optimized for graph data, such as a graph convolutional neural network.
Rao and colleagues <span class="citation" data-cites="15XcIvOBC">[<a href="#ref-15XcIvOBC" role="doc-biblioref">65</a>]</span> describe the construction of a KG using phenotype information (Human Phenotype Ontology) and rare disease information (Orphanet) and curated gene interaction/pathway data (Lit-BM-13, WikiPathways) <span class="citation" data-cites="2ty1l07G LCyCrr7W pzgOjFLZ">[<a href="#ref-2ty1l07G" role="doc-biblioref">66</a>,<a href="#ref-LCyCrr7W" role="doc-biblioref">67</a>,<a href="#ref-pzgOjFLZ" role="doc-biblioref">68</a>]</span>.
They then trained a spectral graph convolution neural network on this KG to identify and rank potentially causal genes for the rare diseases from Orphanet, and were able to use this model to accurately predict causal genes for a ground truth dataset of rare diseases with known causal genes.
While several groups have already published on the use of KGs to study rare diseases, we expect that the growth of multi-modal datasets and methods to analyze KGs will make them a more popular and important tool in the application of ML in rare disease.</p>
<div id="fig:4" class="fignos">
<figure>
<img src="images/figures/pdfs/figure-4-KG.png" alt="" /><figcaption><span>Figure 3:</span> Application of knowledge graphs can improve machine learning in rare disease. a) Knowledge graphs integrate different data types (e.g., genetic, functional, clinical, chemical, and ontological data) and may allow models to learn from connections that are rare disease-specific or happen in many biomedical contexts. There are a variety of possible applications of this approach, including identifying new disease-drug relationships <span class="citation" data-cites="uDR1FuFx">[<a href="#ref-uDR1FuFx" role="doc-biblioref">63</a>]</span>, augmenting data to improve accuracy of models trained on the data <span class="citation" data-cites="1BjxYCRrD">[<a href="#ref-1BjxYCRrD" role="doc-biblioref">64</a>]</span>, or mining prior knowledge to discover important gene sets and pathways in rare diseases <span class="citation" data-cites="15XcIvOBC">[<a href="#ref-15XcIvOBC" role="doc-biblioref">65</a>]</span>. b) Knowledge graphs can also be used to augment data. Li et. al. <span class="citation" data-cites="gVNjawAX">[<a href="#ref-gVNjawAX" role="doc-biblioref">62</a>]</span> applied a classifier to an EHR corpus to identify rare disease patients. They trained a classifier on the EHR data alone (e.g., thrombocytopenia, anemia) and trained another classifier on data augmented with medically-related concepts from a knowledge graph (e.g., neutropenia, stroke). The classifier trained on knowledge-graph augmented data has lower error and higher accuracy (right panel).</figcaption>
</figure>
</div>
<p>Another approach that builds on prior knowledge and large volumes of related data is transfer learning.
Transfer learning leverages shared features, e.g., normal developmental processes that are aberrant in disease or an imaging anomaly present in both rare and common diseases, to advance our understanding of rare diseases.
Transfer learning, where a model trained for one task or domain (source domain) is applied to another related task or domain (target domain), can be supervised or unsupervised.
Among various types of transfer learning, feature-representation-transfer approaches learn representations from the source domain and apply them to a target domain <span class="citation" data-cites="12JtL2o6T">[<a href="#ref-12JtL2o6T" role="doc-biblioref">69</a>]</span>(Figure [<a href="#fig:5">4</a>]a-c).
That is, representation learning, as discussed in an earlier section, does not need to be applied only to describe the dataset on which the algorithm was trained – it can also be used to elucidate signals in sufficiently similar data (Figure [<a href="#fig:5">4</a>]c) and may offer an improvement in descriptive capability over models trained on small rare disease datasets alone (Fig [<a href="#fig:5">4</a>]c).
For instance, low-dimensional representations can be learned from tumor transcriptomic data and transferred to describe patterns associated with genetic alterations in cell line data <span class="citation" data-cites="NsW0qxZF">[<a href="#ref-NsW0qxZF" role="doc-biblioref">26</a>]</span>(Figure [<a href="#fig:5">4</a>]c).
In the next section, we will summarize specific instances of applying transfer learning, along with other techniques described herein, to the study of rare diseases.</p>
<div id="fig:5" class="fignos">
<figure>
<img src="images/figures/pdfs/figure-5-transfer-learning.png" alt="" /><figcaption><span>Figure 4:</span> Feature-representation-transfer approaches learn representations from a source domain and apply them to a target domain. a) Combination of features representing samples of a large dataset (transcriptomic data from tumors) are learned by an ML model through representation learning. b) When applied to a small cell line dataset, the representations extracted by an ML model tend to be incomplete and correlate poorly with clinical or drug sensitivity features. c) When a representation learning model trained on the large dataset (a) is applied to the small cell line dataset to extract consistent combinations of features based on the combinations found in the larger training dataset, the extracted representations correlate strongly with the clinical or drug sensitivity features</figcaption>
</figure>
</div>
<h3 id="combining-approaches-is-required-for-the-successful-application-of-machine-learning-to-rare-diseases">Combining approaches is required for the successful application of machine learning to rare diseases</h3>
<p>We have described multiple approaches for maximizing the success of ML applications in rare disease, but it is rarely sufficient to use any of these techniques in isolation.
Below, we highlight two recent examples in the rare disease domain that draw on concepts of feature-representation-transfer, use of prior data, and regularization.</p>
<p>A large public dataset of acute myeloid leukemia (AML) patient samples with no drug response data and a small <em>in vitro</em> experiment with drug response data form the basis of our first example <span class="citation" data-cites="160WNxTq0">[<a href="#ref-160WNxTq0" role="doc-biblioref">70</a>]</span>.
Training an ML model on the small <em>in vitro</em> dataset alone faced the <em>curse of dimensionality</em> and the dataset size prohibited representation learning.
Dincer et al. trained a variational autoencoder (VAE; see <a href="#definitions">definitions</a>) on a reasonably large, aggregated dataset of AML patient samples from 96 independent studies to learn meaningful representations in an approach termed DeepProfile <span class="citation" data-cites="17HK9o457">[<a href="#ref-17HK9o457" role="doc-biblioref">52</a>]</span> (Figure[<a href="#fig:6">5</a>]a).
The representations or <em>encodings</em> learned by the VAE were then <em>transferred</em> to the small <em>in vitro</em> dataset reducing it’s number of features from thousands to eight, and improving the performance of the final LASSO linear regression model.
In addition to improvement in performance, the <em>encodings</em> learned by the VAE captured more biological pathways than PCA, which may be attributable to the constraints on the encodings imposed during the training process (see <a href="#definitions">definitions</a>).
Similar results were observed for prediction of histopathology in another rare cancer dataset <span class="citation" data-cites="17HK9o457">[<a href="#ref-17HK9o457" role="doc-biblioref">52</a>]</span>.</p>
<p>While DeepProfile was centered on training on an individual disease and tissue combination, some rare diseases affect multiple tissues that a researcher may want to study collectively for the purpose of biological discovery.
Studying multiple tissues poses significant challenges and a cross-tissue analysis may require comparing representations from multiple models.
Models trained on a low number of samples may learn representations that “lump together” multiple biological signals, reducing the interpretability of the results.
To address these challenges, Taroni et al. trained a Pathway-Level Information ExtractoR (PLIER) (a matrix factorization approach that takes prior knowledge in the form of gene sets or pathways) <span class="citation" data-cites="Ki2ij7zE">[<a href="#ref-Ki2ij7zE" role="doc-biblioref">71</a>]</span> on a large generic collection of human transcriptomic data <span class="citation" data-cites="14rnBunuZ">[<a href="#ref-14rnBunuZ" role="doc-biblioref">72</a>]</span>.
PLIER used constraints (regularization) that learned <em>latent variables</em> aligned with a small number of input gene sets, making it suitable for biological discovery or description of rare disease data.
The authors <em>transferred</em> the representations or <em>latent variables</em> learned by the model to describe transcriptomic data from the unseen rare diseases antineutrophil cytoplasmic antibody (ANCA)-associated vasculitis (AAV) and medulloblastoma in an approach termed MultiPLIER <span class="citation" data-cites="14rnBunuZ">[<a href="#ref-14rnBunuZ" role="doc-biblioref">72</a>]</span>. (Figure[<a href="#fig:6">5</a>]b)
MultiPLIER used one model to describe multiple datasets instead of reconciling output from multiple models, thus making it possible to identify commonalities among disease manifestations or affected tissues.</p>
<p>DeepProfile <span class="citation" data-cites="17HK9o457">[<a href="#ref-17HK9o457" role="doc-biblioref">52</a>]</span> and MultiPLIER <span class="citation" data-cites="14rnBunuZ">[<a href="#ref-14rnBunuZ" role="doc-biblioref">72</a>]</span> exemplify modeling approaches that can incorporate prior knowledge – thereby constraining the model space according to plausible or expected biology – or that can share information across datasets.
These two methods capitalize on the fact that similar biological processes are observed across different biological contexts and that the methods underlying the approaches can effectively learn about those processes.</p>
<div id="fig:6" class="fignos">
<figure>
<img src="images/figures/pdfs/figure-6.png" alt="" /><figcaption><span>Figure 5:</span> Combining multiple strategies strengthens the performance of ML models in rare disease. a) The authors of DeepProfile trained a variational autoencoder (VAE) to learn a representation from acute myeloid leukemia data without phenotype labels, transferred those representations to a small dataset with phenotype labels, and found that it improved prediction performance in a drug sensitivity prediction task <span class="citation" data-cites="17HK9o457">[<a href="#ref-17HK9o457" role="doc-biblioref">52</a>]</span>. b) The authors of MultiPLIER trained a Pathway-Level Information ExtractoR (PLIER) model on a large, heterogeneous collection of expression data (recount2 <span class="citation" data-cites="6SPTvFXq">[<a href="#ref-6SPTvFXq" role="doc-biblioref">73</a>]</span>) and transferred the representations (termed latent variables) to multiple datasets from rare diseases that were not in the training set <span class="citation" data-cites="Ki2ij7zE">[<a href="#ref-Ki2ij7zE" role="doc-biblioref">71</a>]</span>. Expression of PLIER latent variables can be used to check for concordance between datasets, among other applications.</figcaption>
</figure>
</div>
<h2 id="outlook">Outlook</h2>
<p>Throughout this perspective, we highlighted various challenges in applying ML methods to rare disease data as well as examples of approaches that address these challenges.
Small sample size, while significant, is not the only roadblock towards application of ML in rare disease data.
The high dimensionality of modern data requires creative approaches, such as learning new representations of the data, to manage the curse of dimensionality.
Leveraging prior knowledge and transfer learning methods to appropriately interpret data is also required.
Furthermore, we posit that researchers applying machine learning methods on rare disease data should use techniques that increase confidence (i.e., bootstrapping) and penalize complexity of the resultant models (i.e., regularization) to enhance the generalizability of their work.
Beyond rare disease, the approaches described in the previous sections may also be useful in the context of other areas where a paucity of data makes analysis difficult, such as precision medicine applications in which customized treatment plans are developed for an individual patient’s unique genotype and phenotype.</p>
<p>All of the approaches highlighted in this perspective come with weaknesses that may undermine investigators’ confidence in using these techniques for rare disease research.
We believe that the challenges in applying ML to rare disease are opportunities to improve data generation and method development going forward.
In particular, we have identified the following two areas as important for the field to explore to increase the utility of machine learning in rare disease.</p>
<h3 id="intentional-data-generation-and-sharing-mechanisms-are-key-for-powering-the-future-of-rare-disease-data-analysis">Intentional data generation and sharing mechanisms are key for powering the future of rare disease data analysis</h3>
<p>While there are many techniques to collate rare data from different sources, low-quality data may hurt the end goal even if it increases the size of the dataset.
In our experience, collaboration with domain experts has proved to be critical in gaining insight into potential sources of variation in the datasets.
An anecdotal example from the authors’ personal experience: conversations with a rare disease clinician revealed that samples in a particular tumor dataset were collected using vastly different surgical techniques (laser ablation and excision vs standard excision).
This information was not readily available to non-experts, but was obvious to the clinician.
Such instances underline the fact that continuous collaboration with domain experts and the sharing of well-annotated data is needed to generate robust datasets in the future.</p>
<p>In addition to sample scarcity, there is a dearth of comprehensive phenotypic-genotypic databases in rare disease.
While rare disease studies that collect genomic and phenotypic data are becoming more common <span class="citation" data-cites="15UbILeOM LSggBya9 6lu5irln">[<a href="#ref-15UbILeOM" role="doc-biblioref">74</a>,<a href="#ref-LSggBya9" role="doc-biblioref">75</a>,<a href="#ref-6lu5irln" role="doc-biblioref">76</a>]</span>, an important next step is to develop comprehensive genomics-based genotype-phenotype databases that prioritize clinical and genomics data standards in order to fuel interpretation of features extracted using ML methods, possibly by funding or otherwise fostering collaboration between biobanking projects and patient registry initiatives.
Mindful sharing of data with proper metadata and attribution to enable prompt data reuse is important in building datasets that can be of great value in rare disease <span class="citation" data-cites="6uid5yCL">[<a href="#ref-6uid5yCL" role="doc-biblioref">77</a>]</span>.
Finally, federated learning methods, such as those used in mobile health <span class="citation" data-cites="Ocnhl9GL">[<a href="#ref-Ocnhl9GL" role="doc-biblioref">78</a>]</span> and electronic healthcare records studies <span class="citation" data-cites="1CG1N5B62">[<a href="#ref-1CG1N5B62" role="doc-biblioref">79</a>]</span>, may allow researchers to develop ML models on data from larger numbers of people with rare diseases whilst protecting patient privacy.</p>
<h3 id="methods-that-reliably-support-mechanistic-interrogation-of-specific-rare-diseases-are-an-unmet-need">Methods that reliably support mechanistic interrogation of specific rare diseases are an unmet need</h3>
<p>The majority of ML methods for rare disease that we have investigated are applied to classification tasks.
We found very few examples of methodologies that interrogate biological mechanisms of rare diseases.
This is likely a consequence of a dearth of methods that can tolerate the various constraints imposed by rare disease data as discussed throughout this article.
An intentional push towards developing methods or analytical workflows that address this will be critical in applying machine learning approaches to rare disease data.</p>
<p>Method development with rare disease applications in mind requires the developers to bear the responsibility of ensuring that the resulting model is trustworthy.
The field of natural language processing has a few examples of how this can be achieved <span class="citation" data-cites="q5rxB78C">[<a href="#ref-q5rxB78C" role="doc-biblioref">80</a>]</span>.
One way to increase trust in a developed model is by helping users understand the behavior of the developed model through providing explanations regarding why a certain model made certain predictions <span class="citation" data-cites="q5rxB78C">[<a href="#ref-q5rxB78C" role="doc-biblioref">80</a>]</span>.
Another approach is to provide robust <em>error analysis</em> for newly developed models to help users understand the strengths and weaknesses of a model <span class="citation" data-cites="HovsEtqX sa8SP0BL uvZAopDf">[<a href="#ref-HovsEtqX" role="doc-biblioref">81</a>,<a href="#ref-sa8SP0BL" role="doc-biblioref">82</a>,<a href="#ref-uvZAopDf" role="doc-biblioref">83</a>]</span>.
Adoption of these approaches into biomedical ML is quickly becoming necessary as machine learning approaches become mainstream in research and clinical settings.</p>
<p>Finally, methods that can reliably integrate disparate datasets will likely always remain a need in rare disease research.
To facilitate such analyses in rare disease, methods that rely on finding structural correspondence between datasets (“anchors”) may be able to transform the status-quo of using machine learning methods in rare disease <span class="citation" data-cites="16wWzu3NO oZmhjP9I bOT9Zmn2">[<a href="#ref-16wWzu3NO" role="doc-biblioref">84</a>,<a href="#ref-oZmhjP9I" role="doc-biblioref">85</a>,<a href="#ref-bOT9Zmn2" role="doc-biblioref">86</a>]</span>.
We speculate that this an important and burgeoning area of research, and we are optimistic about the future of applying machine learning approaches to rare diseases.</p>
<h2 class="page_break_before" id="definitions">Definitions</h2>
<h3 id="vae">VAE</h3>
<p>Variational Autoencoders or VAEs are unsupervised neural networks that use hidden layers to learn or encode representations from available data while mapping the input data to the output data.
VAEs are distinct from other autoencoders since the distribution of the encodings are regularized such that they are close to a normal distribution, which may contribute to learning more biologically relevant signals <span class="citation" data-cites="NsW0qxZF">[<a href="#ref-NsW0qxZF" role="doc-biblioref">26</a>]</span>.</p>
<h3 id="machine-learning">Machine Learning</h3>
<p>Machine learning is a scientific discipline at the intersection of computer science and statistics, which combines computational and statistical methods to identify patterns in sample data.<span class="citation" data-cites="c8wzz15m">[<a href="#ref-c8wzz15m" role="doc-biblioref">87</a>]</span>
In this discipline, one intends to use data as input and apply or fit predictive models to recognize patterns in the data or identify informative groups among the data using objective computational methods.</p>
<h3 id="transfer-learning">Transfer Learning</h3>
<p>Transfer learning is an approach where a model trained for one task or domain (source domain) is applied to another, typically related task or domain (target domain), for example a model pre-trained natural images from the ImageNet dataset can potentially be used to classify medical images.<span class="citation" data-cites="1GAyqYBNZ">[<a href="#ref-1GAyqYBNZ" role="doc-biblioref">89</a>]</span>
Transfer learning can be supervised (one or both of the source and target domains have labels), or unsupervised (both domains are unlabeled).</p>
<h3 id="regularization">Regularization</h3>
<p>Regularization is an approach to reduce overfitting of models to training data, where a penalty or constraint is added to a model trained on a training dataset to avoid making large prediction errors on the evaluation dataset.</p>
<h3 id="knowledge-graph">Knowledge Graph</h3>
<p>A knowledge graph is a network representation of human knowledge about a domain, abstracted into nodes and edges.
Any entity of interest (for example a gene, a disease, a protein, or a cell-line) can be represented as a node in a knowledge graph.
All nodes can be linked through edges that represent known relationships between the nodes.
Edges can be directed, indicating that the order of the nodes is important for encoding the relationship, or undirected.
For example, a gene (node) can be linked to a protein (node) using a directed edge that represents the relationship that the protein is generated through the transcription and translation of the gene.
Knowledge graphs serve to integrate data that exist in distributed sources, encode human readable knowledge in machine readable format, and evolve in a flexible manner to integrate new knowledge as it becomes available.</p>
<h3 id="rare-disease">Rare Disease</h3>
<p>According to the Orphan Drug Act<span class="citation" data-cites="wwF0mDld">[<a href="#ref-wwF0mDld" role="doc-biblioref">4</a>]</span> of United States of America, diseases or conditions that impact less than 200,000 people in the U.S are considered to be rare diseases.
The European Union defines a disease as rare when it affects less than 1 in 2,000 people.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-12bOkHKJU">
<p>1. <strong>The use of machine learning in rare diseases: a scoping review</strong> <br />
Julia Schaefer, Moritz Lehne, Josef Schepers, Fabian Prasser, Sylvia Thun<br />
<em>Orphanet Journal of Rare Diseases</em> (2020-12) <a href="https://doi.org/ghb3wx">https://doi.org/ghb3wx</a> <br />
DOI: <a href="https://doi.org/10.1186/s13023-020-01424-6">10.1186/s13023-020-01424-6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32517778">32517778</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7285453">PMC7285453</a></p>
</div>
<div id="ref-1DlwO80sJ">
<p>2. <strong>Opportunities and Challenges for Machine Learning in Rare Diseases</strong> <br />
Sergio Decherchi, Elena Pedrini, Marina Mordenti, Andrea Cavalli, Luca Sangiorgi<br />
<em>Frontiers in Medicine</em> (2021-10-05) <a href="https://doi.org/gpthzr">https://doi.org/gpthzr</a> <br />
DOI: <a href="https://doi.org/10.3389/fmed.2021.747612">10.3389/fmed.2021.747612</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34676229">34676229</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8523988">PMC8523988</a></p>
</div>
<div id="ref-18Ysd1Qjh">
<p>3. <strong>Unsupervised Analysis of Transcriptomic Profiles Reveals Six Glioma Subtypes</strong> <br />
Aiguo Li, Jennifer Walling, Susie Ahn, Yuri Kotliarov, Qin Su, Martha Quezado, J. Carl Oberholtzer, John Park, Jean C. Zenklusen, Howard A. Fine<br />
<em>Cancer Research</em> (2009-03-01) <a href="https://doi.org/d3kvzt">https://doi.org/d3kvzt</a> <br />
DOI: <a href="https://doi.org/10.1158/0008-5472.can-08-2100">10.1158/0008-5472.can-08-2100</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19244127">19244127</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2845963">PMC2845963</a></p>
</div>
<div id="ref-wwF0mDld">
<p>4. <a href="https://www.fda.gov/media/99546/download">https://www.fda.gov/media/99546/download</a></p>
</div>
<div id="ref-G5HC64pk">
<p>5. <strong>Learning statistical models of phenotypes using noisy labeled training data</strong> <br />
Vibhu Agarwal, Tanya Podchiyska, Juan M Banda, Veena Goel, Tiffany I Leung, Evan P Minty, Timothy E Sweeney, Elsie Gyang, Nigam H Shah<br />
<em>Journal of the American Medical Informatics Association</em> (2016-11-01) <a href="https://doi.org/f9bxf9">https://doi.org/f9bxf9</a> <br />
DOI: <a href="https://doi.org/10.1093/jamia/ocw028">10.1093/jamia/ocw028</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27174893">27174893</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5070523">PMC5070523</a></p>
</div>
<div id="ref-16kfJJap4">
<p>6. <strong>Classification in the Presence of Label Noise: A Survey</strong> <br />
Benoit Frenay, Michel Verleysen<br />
<em>IEEE Transactions on Neural Networks and Learning Systems</em> (2014-05) <a href="https://doi.org/f5zdgq">https://doi.org/f5zdgq</a> <br />
DOI: <a href="https://doi.org/10.1109/tnnls.2013.2292894">10.1109/tnnls.2013.2292894</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24808033">24808033</a></p>
</div>
<div id="ref-Zoj0hKzb">
<p>7. <strong>Looking beyond the hype: Applied AI and machine learning in translational medicine</strong> <br />
Tzen S. Toh, Frank Dondelinger, Dennis Wang<br />
<em>EBioMedicine</em> (2019-09) <a href="https://doi.org/gg9dcx">https://doi.org/gg9dcx</a> <br />
DOI: <a href="https://doi.org/10.1016/j.ebiom.2019.08.027">10.1016/j.ebiom.2019.08.027</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31466916">31466916</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6796516">PMC6796516</a></p>
</div>
<div id="ref-KOD2gdVS">
<p>8. <strong>The properties of high-dimensional data spaces: implications for exploring gene and protein expression data</strong> <br />
Robert Clarke, Habtom W. Ressom, Antai Wang, Jianhua Xuan, Minetta C. Liu, Edmund A. Gehan, Yue Wang<br />
<em>Nature Reviews Cancer</em> (2008-01) <a href="https://doi.org/ffksnf">https://doi.org/ffksnf</a> <br />
DOI: <a href="https://doi.org/10.1038/nrc2294">10.1038/nrc2294</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18097463">18097463</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2238676">PMC2238676</a></p>
</div>
<div id="ref-c6DKSPdm">
<p>9. <strong>The curse(s) of dimensionality</strong> <br />
Naomi Altman, Martin Krzywinski<br />
<em>Nature Methods</em> (2018-06) <a href="https://doi.org/ghrqhp">https://doi.org/ghrqhp</a> <br />
DOI: <a href="https://doi.org/10.1038/s41592-018-0019-x">10.1038/s41592-018-0019-x</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29855577">29855577</a></p>
</div>
<div id="ref-1HahRBkyb">
<p>10. <strong>Adjusting batch effects in microarray expression data using empirical Bayes methods</strong> <br />
W. Evan Johnson, Cheng Li, Ariel Rabinovic<br />
<em>Biostatistics</em> (2007-01-01) <a href="https://doi.org/dsf386">https://doi.org/dsf386</a> <br />
DOI: <a href="https://doi.org/10.1093/biostatistics/kxj037">10.1093/biostatistics/kxj037</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16632515">16632515</a></p>
</div>
<div id="ref-XJiH4M02">
<p>11. <strong>svaseq: removing batch effects and other unwanted noise from sequencing data</strong> <br />
Jeffrey T. Leek<br />
<em>Nucleic Acids Research</em> (2014-12-01) <a href="https://doi.org/f8k8kf">https://doi.org/f8k8kf</a> <br />
DOI: <a href="https://doi.org/10.1093/nar/gku864">10.1093/nar/gku864</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25294822">25294822</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4245966">PMC4245966</a></p>
</div>
<div id="ref-19neBSN5B">
<p>12. <strong>A scaling normalization method for differential expression analysis of RNA-seq data</strong> <br />
Mark D Robinson, Alicia Oshlack<br />
<em>Genome Biology</em> (2010) <a href="https://doi.org/cq6f8b">https://doi.org/cq6f8b</a> <br />
DOI: <a href="https://doi.org/10.1186/gb-2010-11-3-r25">10.1186/gb-2010-11-3-r25</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20196867">20196867</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864565">PMC2864565</a></p>
</div>
<div id="ref-LE2agOLt">
<p>13. <strong>Phenopackets: Standardizing and Exchanging Patient Phenotypic Data</strong> <a href="https://www.ga4gh.org/news/phenopackets-standardizing-and-exchanging-patient-phenotypic-data/">https://www.ga4gh.org/news/phenopackets-standardizing-and-exchanging-patient-phenotypic-data/</a></p>
</div>
<div id="ref-g6a6KX9t">
<p>14. <strong>What is a Phenopacket? — phenopacket-schema 2.0 documentation</strong> <a href="https://phenopacket-schema.readthedocs.io/en/2.0.0/basics.html">https://phenopacket-schema.readthedocs.io/en/2.0.0/basics.html</a></p>
</div>
<div id="ref-sFnMb5kB">
<p>15. <strong>Applied Predictive Modeling</strong> <br />
Max Kuhn, Kjell Johnson<br />
<em>Springer New York</em> (2013) <a href="https://doi.org/c432">https://doi.org/c432</a> <br />
DOI: <a href="https://doi.org/10.1007/978-1-4614-6849-3">10.1007/978-1-4614-6849-3</a> · ISBN: <a href="https://worldcat.org/isbn/9781461468486">9781461468486</a></p>
</div>
<div id="ref-AZCOtvbC">
<p>16. <strong>The art of using t-SNE for single-cell transcriptomics</strong> <br />
Dmitry Kobak, Philipp Berens<br />
<em>Nature Communications</em> (2019-12) <a href="https://doi.org/ggdrfz">https://doi.org/ggdrfz</a> <br />
DOI: <a href="https://doi.org/10.1038/s41467-019-13056-x">10.1038/s41467-019-13056-x</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31780648">31780648</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6882829">PMC6882829</a></p>
</div>
<div id="ref-12XiicejZ">
<p>17. <strong>Dimensionality reduction by UMAP to visualize physical and genetic interactions</strong> <br />
Michael W. Dorrity, Lauren M. Saunders, Christine Queitsch, Stanley Fields, Cole Trapnell<br />
<em>Nature Communications</em> (2020-12) <a href="https://doi.org/ggqcqp">https://doi.org/ggqcqp</a> <br />
DOI: <a href="https://doi.org/10.1038/s41467-020-15351-4">10.1038/s41467-020-15351-4</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32210240">32210240</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7093466">PMC7093466</a></p>
</div>
<div id="ref-15yIhkDpY">
<p>18. <strong>Feature Selection</strong> <br />
Rama Chellappa, Pavan Turaga<br />
<em>Computer Vision</em> (2020) <a href="https://doi.org/ghgqb9">https://doi.org/ghgqb9</a> <br />
DOI: <a href="https://doi.org/10.1007/978-3-030-03243-2_299-1">10.1007/978-3-030-03243-2_299-1</a> · ISBN: <a href="https://worldcat.org/isbn/9783030032432">9783030032432</a></p>
</div>
<div id="ref-1HICCTHVj">
<p>19. <strong>Handbook of Data Visualization</strong> <br />
Chun-houh Chen, Wolfgang Härdle, Antony Unwin<br />
<em>Springer Berlin Heidelberg</em> (2008) <a href="https://doi.org/ckmkfp">https://doi.org/ckmkfp</a> <br />
DOI: <a href="https://doi.org/10.1007/978-3-540-33037-0">10.1007/978-3-540-33037-0</a> · ISBN: <a href="https://worldcat.org/isbn/9783540330363">9783540330363</a></p>
</div>
<div id="ref-qRi1wkz4">
<p>20. <strong>Principal component analysis: a review and recent developments</strong> <br />
Ian T. Jolliffe, Jorge Cadima<br />
<em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em> (2016-04-13) <a href="https://doi.org/gcsfk7">https://doi.org/gcsfk7</a> <br />
DOI: <a href="https://doi.org/10.1098/rsta.2015.0202">10.1098/rsta.2015.0202</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26953178">26953178</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4792409">PMC4792409</a></p>
</div>
<div id="ref-BsfyICXU">
<p>21. <strong>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</strong> <br />
Leland McInnes, John Healy, James Melville<br />
<em>arXiv</em> (2020-09-17) <a href="http://arxiv.org/abs/1802.03426">http://arxiv.org/abs/1802.03426</a></p>
</div>
<div id="ref-1Ak4JFhvU">
<p>22. <strong>Automatic detection of rare pathologies in fundus photographs using few-shot learning</strong> <br />
Gwenolé Quellec, Mathieu Lamard, Pierre-Henri Conze, Pascale Massin, Béatrice Cochener<br />
<em>Medical Image Analysis</em> (2020-04) <a href="https://doi.org/ggsrc7">https://doi.org/ggsrc7</a> <br />
DOI: <a href="https://doi.org/10.1016/j.media.2020.101660">10.1016/j.media.2020.101660</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32028213">32028213</a></p>
</div>
<div id="ref-gqTS2Uy7">
<p>23. <strong>Sensitive detection of rare disease-associated cell subsets via representation learning</strong> <br />
Eirini Arvaniti, Manfred Claassen<br />
<em>Nature Communications</em> (2017-04) <a href="https://doi.org/gf9t7w">https://doi.org/gf9t7w</a> <br />
DOI: <a href="https://doi.org/10.1038/ncomms14825">10.1038/ncomms14825</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28382969">28382969</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5384229">PMC5384229</a></p>
</div>
<div id="ref-skX0eEFg">
<p>24. <strong>Visualizing Data using t-SNE</strong> <br />
Laurens van der Maaten, Geoffrey Hinton<br />
<em>Journal of Machine Learning Research</em> (2008) <a href="http://jmlr.org/papers/v9/vandermaaten08a.html">http://jmlr.org/papers/v9/vandermaaten08a.html</a></p>
</div>
<div id="ref-Lby4PmSX">
<p>25. <strong>How to Use t-SNE Effectively</strong> <br />
Martin Wattenberg, Fernanda Viégas, Ian Johnson<br />
<em>Distill</em> (2016-10-13) <a href="https://doi.org/gffk7g">https://doi.org/gffk7g</a> <br />
DOI: <a href="https://doi.org/10.23915/distill.00002">10.23915/distill.00002</a></p>
</div>
<div id="ref-NsW0qxZF">
<p>26. <strong>Compressing gene expression data using multiple latent space dimensionalities learns complementary biological representations</strong> <br />
Gregory P. Way, Michael Zietz, Vincent Rubinetti, Daniel S. Himmelstein, Casey S. Greene<br />
<em>Genome Biology</em> (2020-12) <a href="https://doi.org/gg2mjh">https://doi.org/gg2mjh</a> <br />
DOI: <a href="https://doi.org/10.1186/s13059-020-02021-3">10.1186/s13059-020-02021-3</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32393369">32393369</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7212571">PMC7212571</a></p>
</div>
<div id="ref-Pyg7FNxd">
<p>27. <strong>Ten quick tips for effective dimensionality reduction</strong> <br />
Lan Huong Nguyen, Susan Holmes<br />
<em>PLOS Computational Biology</em> (2019-06-20) <a href="https://doi.org/gf3583">https://doi.org/gf3583</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1006907">10.1371/journal.pcbi.1006907</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31220072">31220072</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6586259">PMC6586259</a></p>
</div>
<div id="ref-11QYztxcm">
<p>28. <strong>Clustering cancer gene expression data: a comparative study</strong> <br />
Marcilio CP de Souto, Ivan G Costa, Daniel SA de Araujo, Teresa B Ludermir, Alexander Schliep<br />
<em>BMC Bioinformatics</em> (2008-12) <a href="https://doi.org/dqqbn6">https://doi.org/dqqbn6</a> <br />
DOI: <a href="https://doi.org/10.1186/1471-2105-9-497">10.1186/1471-2105-9-497</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19038021">19038021</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2632677">PMC2632677</a></p>
</div>
<div id="ref-U2RMvmE5">
<p>29. <strong>Removing Batch Effects From Histopathological Images for Enhanced Cancer Diagnosis</strong> <br />
Sonal Kothari, John H. Phan, Todd H. Stokes, Adeboye O. Osunkoya, Andrew N. Young, May D. Wang<br />
<em>IEEE Journal of Biomedical and Health Informatics</em> (2014-05) <a href="https://doi.org/gdm9jd">https://doi.org/gdm9jd</a> <br />
DOI: <a href="https://doi.org/10.1109/jbhi.2013.2276766">10.1109/jbhi.2013.2276766</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24808220">24808220</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5003052">PMC5003052</a></p>
</div>
<div id="ref-ChpTIk5j">
<p>30. <strong>Deriving disease modules from the compressed transcriptional space embedded in a deep autoencoder</strong> <br />
Sanjiv K. Dwivedi, Andreas Tjärnberg, Jesper Tegnér, Mika Gustafsson<br />
<em>Nature Communications</em> (2020-12) <a href="https://doi.org/gg7krm">https://doi.org/gg7krm</a> <br />
DOI: <a href="https://doi.org/10.1038/s41467-020-14666-6">10.1038/s41467-020-14666-6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32051402">32051402</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7016183">PMC7016183</a></p>
</div>
<div id="ref-1DrhKLdVp">
<p>31. <strong>CoGAPS: an R/C++ package to identify patterns and biological process activity in transcriptomic data</strong> <br />
Elana J. Fertig, Jie Ding, Alexander V. Favorov, Giovanni Parmigiani, Michael F. Ochs<br />
<em>Bioinformatics</em> (2010-11-01) <a href="https://doi.org/cwqsv4">https://doi.org/cwqsv4</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btq503">10.1093/bioinformatics/btq503</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20810601">20810601</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025742">PMC3025742</a></p>
</div>
<div id="ref-YuD6CEIZ">
<p>32. <strong>Enhancing techniques for learning decision trees from imbalanced data</strong> <br />
Ikram Chaabane, Radhouane Guermazi, Mohamed Hammami<br />
<em>Advances in Data Analysis and Classification</em> (2020-09) <a href="https://doi.org/ghz4sz">https://doi.org/ghz4sz</a> <br />
DOI: <a href="https://doi.org/10.1007/s11634-019-00354-x">10.1007/s11634-019-00354-x</a></p>
</div>
<div id="ref-16uxtBBBG">
<p>33. <strong>Random Forests</strong> <br />
Leo Breiman<br />
<em>Machine Learning</em> (2001-10-01) <a href="https://doi.org/10.1023/A:1010933404324">https://doi.org/10.1023/A:1010933404324</a> <br />
DOI: <a href="https://doi.org/10.1023/A:1010933404324">10.1023/a:1010933404324</a></p>
</div>
<div id="ref-14J3u9pnR">
<p>34. <strong>Evaluating predictive modeling algorithms to assess patient eligibility for clinical trials from routine data</strong> <br />
Felix Köpcke, Dorota Lubgan, Rainer Fietkau, Axel Scholler, Carla Nau, Michael Stürzl, Roland Croner, Hans-Ulrich Prokosch, Dennis Toddenroth<br />
<em>BMC Medical Informatics and Decision Making</em> (2013-12) <a href="https://doi.org/f5jqvh">https://doi.org/f5jqvh</a> <br />
DOI: <a href="https://doi.org/10.1186/1472-6947-13-134">10.1186/1472-6947-13-134</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24321610">24321610</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4029400">PMC4029400</a></p>
</div>
<div id="ref-wv3oXzet">
<p>35. <strong>Integrative Analysis Identifies Candidate Tumor Microenvironment and Intracellular Signaling Pathways that Define Tumor Heterogeneity in NF1</strong> <br />
Jineta Banerjee, Robert J Allaway, Jaclyn N Taroni, Aaron Baker, Xiaochun Zhang, Chang In Moon, Christine A Pratilas, Jaishri O Blakeley, Justin Guinney, Angela Hirbe, … Sara JC Gosline<br />
<em>Genes</em> (2020-02-21) <a href="https://doi.org/gg4rbj">https://doi.org/gg4rbj</a> <br />
DOI: <a href="https://doi.org/10.3390/genes11020226">10.3390/genes11020226</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32098059">32098059</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7073563">PMC7073563</a></p>
</div>
<div id="ref-HWIKCkVI">
<p>36. <strong>Learning to Identify Rare Disease Patients from Electronic Health Records.</strong> <br />
Rich Colbaugh, Kristin Glass, Christopher Rudolf, Mike Tremblay Volv Global Lausanne Switzerland<br />
<em>AMIA … Annual Symposium proceedings. AMIA Symposium</em> (2018-12-05) <a href="https://www.ncbi.nlm.nih.gov/pubmed/30815073">https://www.ncbi.nlm.nih.gov/pubmed/30815073</a> <br />
PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30815073">30815073</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371307">PMC6371307</a></p>
</div>
<div id="ref-Q25GV92r">
<p>37. <strong>Component-based face detection</strong> <br />
B. Heiselet, T. Serre, M. Pontil, T. Poggio<br />
<em>Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001</em> (2001) <a href="https://doi.org/c89p2b">https://doi.org/c89p2b</a> <br />
DOI: <a href="https://doi.org/10.1109/cvpr.2001.990537">10.1109/cvpr.2001.990537</a> · ISBN: <a href="https://worldcat.org/isbn/9780769512723">9780769512723</a></p>
</div>
<div id="ref-ThoSnmu3">
<p>38. <strong>The Architecture of the Face and Eyes Detection System Based on Cascade Classifiers</strong> <br />
Andrzej Kasinski, Adam Schmidt<br />
<em>Computer Recognition Systems 2</em> (2007) <a href="https://doi.org/cbzq9n">https://doi.org/cbzq9n</a> <br />
DOI: <a href="https://doi.org/10.1007/978-3-540-75175-5_16">10.1007/978-3-540-75175-5_16</a> · ISBN: <a href="https://worldcat.org/isbn/9783540751748">9783540751748</a></p>
</div>
<div id="ref-1GhHIDxuW">
<p>39. <strong>Efficient Estimation of Word Representations in Vector Space</strong> <br />
Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean<br />
<em>arXiv</em> (2013-09-10) <a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a></p>
</div>
<div id="ref-orPSUYei">
<p>40. <strong>Improving random forest predictions in small datasets from two-phase sampling designs</strong> <br />
Sunwoo Han, Brian D. Williamson, Youyi Fong<br />
<em>BMC Medical Informatics and Decision Making</em> (2021-12) <a href="https://doi.org/gp5pj6">https://doi.org/gp5pj6</a> <br />
DOI: <a href="https://doi.org/10.1186/s12911-021-01688-3">10.1186/s12911-021-01688-3</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34809631">34809631</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8607560">PMC8607560</a></p>
</div>
<div id="ref-fMU2mxEc">
<p>41. <strong>A System for Classifying Disease Comorbidity Status from Medical Discharge Summaries Using Automated Hotspot and Negated Concept Detection</strong> <br />
K. H. Ambert, A. M. Cohen<br />
<em>Journal of the American Medical Informatics Association</em> (2009-07-01) <a href="https://doi.org/dhg6jb">https://doi.org/dhg6jb</a> <br />
DOI: <a href="https://doi.org/10.1197/jamia.m3095">10.1197/jamia.m3095</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19390099">19390099</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2705265">PMC2705265</a></p>
</div>
<div id="ref-U1rmHW8N">
<p>42. <strong>SMOTE: Synthetic Minority Over-sampling Technique</strong> <br />
N. V. Chawla, K. W. Bowyer, L. O. Hall, W. P. Kegelmeyer<br />
<em>Journal of Artificial Intelligence Research</em> (2002-06-01) <a href="https://www.jair.org/index.php/jair/article/view/10302">https://www.jair.org/index.php/jair/article/view/10302</a> <br />
DOI: <a href="https://doi.org/10.1613/jair.953">10.1613/jair.953</a></p>
</div>
<div id="ref-19Gunahwx">
<p>43. <strong>Survey of resampling techniques for improving classification performance in unbalanced datasets</strong> <br />
Ajinkya More<br />
<em>arXiv</em> (2016) <a href="https://doi.org/gp5pj7">https://doi.org/gp5pj7</a> <br />
DOI: <a href="https://doi.org/10.48550/arxiv.1608.06048">10.48550/arxiv.1608.06048</a></p>
</div>
<div id="ref-wFHvLXy8">
<p>44. <strong>Deep learning</strong> <br />
Ian Goodfellow, Yoshua Bengio, Aaron Courville<br />
<em>The MIT Press</em> (2016) <br />
ISBN: <a href="https://worldcat.org/isbn/9780262035613">9780262035613</a></p>
</div>
<div id="ref-SDzZeG0c">
<p>45. <strong>Generalization in Clinical Prediction Models: The Blessing and Curse of Measurement Indicator Variables</strong> <br />
Joseph Futoma, Morgan Simons, Finale Doshi-Velez, Rishikesan Kamaleswaran<br />
<em>Critical care explorations</em> (2021-06-25) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8238368/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8238368/</a> <br />
DOI: <a href="https://doi.org/10.1097/CCE.0000000000000453">10.1097/cce.0000000000000453</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34235453">34235453</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8238368">PMC8238368</a></p>
</div>
<div id="ref-biC8xxbd">
<p>46. <strong>Regularized Machine Learning in the Genetic Prediction of Complex Traits</strong> <br />
Sebastian Okser, Tapio Pahikkala, Antti Airola, Tapio Salakoski, Samuli Ripatti, Tero Aittokallio<br />
<em>PLoS Genetics</em> (2014-11-13) <a href="https://doi.org/ghrqhq">https://doi.org/ghrqhq</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pgen.1004754">10.1371/journal.pgen.1004754</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25393026">25393026</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4230844">PMC4230844</a></p>
</div>
<div id="ref-rfLLR7gS">
<p>47. <strong>Review and evaluation of penalised regression methods for risk prediction in low‐dimensional data with few events</strong> <br />
Menelaos Pavlou, Gareth Ambler, Shaun Seaman, Maria De Iorio, Rumana Z Omar<br />
<em>Statistics in Medicine</em> (2016-03-30) <a href="https://doi.org/ggn9zg">https://doi.org/ggn9zg</a> <br />
DOI: <a href="https://doi.org/10.1002/sim.6782">10.1002/sim.6782</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26514699">26514699</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4982098">PMC4982098</a></p>
</div>
<div id="ref-JZNkB8d7">
<p>48. <strong>Regularization and variable selection via the elastic net</strong> <br />
Hui Zou, Trevor Hastie<br />
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> (2005-04) <a href="https://doi.org/b8cwwr">https://doi.org/b8cwwr</a> <br />
DOI: <a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x">10.1111/j.1467-9868.2005.00503.x</a></p>
</div>
<div id="ref-fPp30wsy">
<p>49. <strong>Comparison of statistical approaches to rare variant analysis for quantitative traits</strong> <br />
Han Chen, Audrey E Hendricks, Yansong Cheng, Adrienne L Cupples, Josée Dupuis, Ching-Ti Liu<br />
<em>BMC Proceedings</em> (2011-12) <a href="https://doi.org/b9mf4x">https://doi.org/b9mf4x</a> <br />
DOI: <a href="https://doi.org/10.1186/1753-6561-5-s9-s113">10.1186/1753-6561-5-s9-s113</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22373209">22373209</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3287837">PMC3287837</a></p>
</div>
<div id="ref-lXiw1iso">
<p>50. <strong>Regularized logistic regression with adjusted adaptive elastic net for gene selection in high dimensional cancer classification</strong> <br />
Zakariya Yahya Algamal, Muhammad Hisyam Lee<br />
<em>Computers in Biology and Medicine</em> (2015-12) <a href="https://doi.org/f73xvj">https://doi.org/f73xvj</a> <br />
DOI: <a href="https://doi.org/10.1016/j.compbiomed.2015.10.008">10.1016/j.compbiomed.2015.10.008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26520484">26520484</a></p>
</div>
<div id="ref-JkWXgEgV">
<p>51. <strong>An elastic-net logistic regression approach to generate classifiers and gene signatures for types of immune cells and T helper cell subsets</strong> <br />
Arezo Torang, Paraag Gupta, David J. Klinke<br />
<em>BMC Bioinformatics</em> (2019-12) <a href="https://doi.org/gg5hmj">https://doi.org/gg5hmj</a> <br />
DOI: <a href="https://doi.org/10.1186/s12859-019-2994-z">10.1186/s12859-019-2994-z</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31438843">31438843</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6704630">PMC6704630</a></p>
</div>
<div id="ref-17HK9o457">
<p>52. <strong>DeepProfile: Deep learning of cancer molecular profiles for precision medicine</strong> <br />
Ayse Berceste Dincer, Safiye Celik, Naozumi Hiranuma, Su-In Lee<br />
<em>Bioinformatics</em> (2018-03-08) <a href="https://doi.org/gdj2j4">https://doi.org/gdj2j4</a> <br />
DOI: <a href="https://doi.org/10.1101/278739">10.1101/278739</a></p>
</div>
<div id="ref-EOUjThUk">
<p>53. <strong>Auto-Encoding Variational Bayes</strong> <br />
Diederik P Kingma, Max Welling<br />
<em>arXiv</em> (2013) <a href="https://doi.org/gpp5xv">https://doi.org/gpp5xv</a> <br />
DOI: <a href="https://doi.org/10.48550/arxiv.1312.6114">10.48550/arxiv.1312.6114</a></p>
</div>
<div id="ref-i5ynU2dS">
<p>54. <strong>Deep learning in rare disease. Detection of tubers in tuberous sclerosis complex</strong> <br />
Iván Sánchez Fernández, Edward Yang, Paola Calvachi, Marta Amengual-Gual, Joyce Y. Wu, Darcy Krueger, Hope Northrup, Martina E. Bebin, Mustafa Sahin, Kun-Hsing Yu, … on behalf of the TACERN Study Group<br />
<em>PLOS ONE</em> (2020-04-29) <a href="https://doi.org/gpp5xt">https://doi.org/gpp5xt</a> <br />
DOI: <a href="https://doi.org/10.1371/journal.pone.0232376">10.1371/journal.pone.0232376</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32348367">32348367</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7190137">PMC7190137</a></p>
</div>
<div id="ref-5cHHEM6Q">
<p>55. <strong>The Monarch Initiative: an integrative data and analytic platform connecting phenotypes to genotypes across species</strong> <br />
Christopher J. Mungall, Julie A. McMurry, Sebastian Köhler, James P. Balhoff, Charles Borromeo, Matthew Brush, Seth Carbon, Tom Conlin, Nathan Dunn, Mark Engelstad, … Melissa A. Haendel<br />
<em>Nucleic Acids Research</em> (2017-01-04) <a href="https://doi.org/f9v7bz">https://doi.org/f9v7bz</a> <br />
DOI: <a href="https://doi.org/10.1093/nar/gkw1128">10.1093/nar/gkw1128</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27899636">27899636</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5210586">PMC5210586</a></p>
</div>
<div id="ref-O21tn8vf">
<p>56. <strong>Systematic integration of biomedical knowledge prioritizes drugs for repurposing</strong> <br />
Daniel Scott Himmelstein, Antoine Lizee, Christine Hessler, Leo Brueggeman, Sabrina L Chen, Dexter Hadley, Ari Green, Pouya Khankhanian, Sergio E Baranzini<br />
<em>eLife</em> (2017-09-22) <a href="https://doi.org/cdfk">https://doi.org/cdfk</a> <br />
DOI: <a href="https://doi.org/10.7554/elife.26726">10.7554/elife.26726</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28936969">28936969</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5640425">PMC5640425</a></p>
</div>
<div id="ref-1H2nqqKV7">
<p>57. <strong>A Framework for Automated Construction of Heterogeneous Large-Scale Biomedical Knowledge Graphs</strong> <br />
Tiffany J. Callahan, Ignacio J. Tripodi, Lawrence E. Hunter, William A. Baumgartner<br />
<em>Bioinformatics</em> (2020-05-02) <a href="https://doi.org/gg338z">https://doi.org/gg338z</a> <br />
DOI: <a href="https://doi.org/10.1101/2020.04.30.071407">10.1101/2020.04.30.071407</a></p>
</div>
<div id="ref-CSiMoOrI">
<p>58. <strong>A global network of biomedical relationships derived from text</strong> <br />
Bethany Percha, Russ B Altman<br />
<em>Bioinformatics</em> (2018-08-01) <a href="https://doi.org/gc3ndk">https://doi.org/gc3ndk</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bty114">10.1093/bioinformatics/bty114</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29490008">29490008</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6061699">PMC6061699</a></p>
</div>
<div id="ref-wjHFUHNC">
<p>59. <strong>Orphanet</strong> <a href="https://www.orpha.net/consor/cgi-bin/index.php">https://www.orpha.net/consor/cgi-bin/index.php</a></p>
</div>
<div id="ref-1DCdPxaef">
<p>60. <strong>Structured reviews for data and knowledge-driven research</strong> <br />
Núria Queralt-Rosinach, Gregory S Stupp, Tong Shu Li, Michael Mayers, Maureen E Hoatlin, Matthew Might, Benjamin M Good, Andrew I Su<br />
<em>Database</em> (2020-01-01) <a href="https://doi.org/ggsdkj">https://doi.org/ggsdkj</a> <br />
DOI: <a href="https://doi.org/10.1093/database/baaa015">10.1093/database/baaa015</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32283553">32283553</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7153956">PMC7153956</a></p>
</div>
<div id="ref-5FkKpSQe">
<p>61. <strong>Learning Drug-Disease-Target Embedding (DDTE) from knowledge graphs to inform drug repurposing hypotheses</strong> <br />
Changsung Moon, Chunming Jin, Xialan Dong, Saad Abrar, Weifan Zheng, Rada Y. Chirkova, Alexander Tropsha<br />
<em>Journal of Biomedical Informatics</em> (2021-07) <a href="https://doi.org/gmpgs6">https://doi.org/gmpgs6</a> <br />
DOI: <a href="https://doi.org/10.1016/j.jbi.2021.103838">10.1016/j.jbi.2021.103838</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34119691">34119691</a></p>
</div>
<div id="ref-gVNjawAX">
<p>62. <strong>Improving rare disease classification using imperfect knowledge graph</strong> <br />
Xuedong Li, Yue Wang, Dongwu Wang, Walter Yuan, Dezhong Peng, Qiaozhu Mei<br />
<em>BMC Medical Informatics and Decision Making</em> (2019-12) <a href="https://doi.org/gg5j65">https://doi.org/gg5j65</a> <br />
DOI: <a href="https://doi.org/10.1186/s12911-019-0938-1">10.1186/s12911-019-0938-1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31801534">31801534</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6894101">PMC6894101</a></p>
</div>
<div id="ref-uDR1FuFx">
<p>63. <strong>A Literature-Based Knowledge Graph Embedding Method for Identifying Drug Repurposing Opportunities in Rare Diseases</strong> <br />
Daniel N. Sosa, Alexander Derry, Margaret Guo, Eric Wei, Connor Brinton, Russ B. Altman<br />
<em>Biocomputing 2020</em> (2019-12) <a href="https://doi.org/gmpgs7">https://doi.org/gmpgs7</a> <br />
DOI: <a href="https://doi.org/10.1142/9789811215636_0041">10.1142/9789811215636_0041</a> · ISBN: <a href="https://worldcat.org/isbn/9789811215629">9789811215629</a></p>
</div>
<div id="ref-1BjxYCRrD">
<p>64. <strong>Rare disease knowledge enrichment through a data-driven approach</strong> <br />
Feichen Shen, Yiqing Zhao, Liwei Wang, Majid Rastegar Mojarad, Yanshan Wang, Sijia Liu, Hongfang Liu<br />
<em>BMC Medical Informatics and Decision Making</em> (2019-12) <a href="https://doi.org/gm48cq">https://doi.org/gm48cq</a> <br />
DOI: <a href="https://doi.org/10.1186/s12911-019-0752-9">10.1186/s12911-019-0752-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30764825">30764825</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6376651">PMC6376651</a></p>
</div>
<div id="ref-15XcIvOBC">
<p>65. <strong>Phenotype-driven gene prioritization for rare diseases using graph convolution on heterogeneous networks</strong> <br />
Aditya Rao, Saipradeep Vg, Thomas Joseph, Sujatha Kotte, Naveen Sivadasan, Rajgopal Srinivasan<br />
<em>BMC Medical Genomics</em> (2018-12) <a href="https://doi.org/gnb3q7">https://doi.org/gnb3q7</a> <br />
DOI: <a href="https://doi.org/10.1186/s12920-018-0372-8">10.1186/s12920-018-0372-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29980210">29980210</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6035401">PMC6035401</a></p>
</div>
<div id="ref-2ty1l07G">
<p>66. <strong>The Human Phenotype Ontology in 2021</strong> <br />
Sebastian Köhler, Michael Gargano, Nicolas Matentzoglu, Leigh C Carmody, David Lewis-Smith, Nicole A Vasilevsky, Daniel Danis, Ganna Balagura, Gareth Baynam, Amy M Brower, … Peter N Robinson<br />
<em>Nucleic acids research</em> (2021-01-08) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7778952/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7778952/</a> <br />
DOI: <a href="https://doi.org/10.1093/nar/gkaa1043">10.1093/nar/gkaa1043</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33264411">33264411</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7778952">PMC7778952</a></p>
</div>
<div id="ref-LCyCrr7W">
<p>67. <strong>A Proteome-Scale Map of the Human Interactome Network</strong> <br />
Thomas Rolland, Murat Taşan, Benoit Charloteaux, Samuel J. Pevzner, Quan Zhong, Nidhi Sahni, Song Yi, Irma Lemmens, Celia Fontanillo, Roberto Mosca, … Marc Vidal<br />
<em>Cell</em> (2014-11) <a href="https://doi.org/f3mn6x">https://doi.org/f3mn6x</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2014.10.050">10.1016/j.cell.2014.10.050</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25416956">25416956</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4266588">PMC4266588</a></p>
</div>
<div id="ref-pzgOjFLZ">
<p>68. <strong>WikiPathways: connecting communities</strong> <br />
Marvin Martens, Ammar Ammar, Anders Riutta, Andra Waagmeester, Denise N Slenter, Kristina Hanspers, Ryan A. Miller, Daniela Digles, Elisson N Lopes, Friederike Ehrhart, … Martina Kutmon<br />
<em>Nucleic Acids Research</em> (2021-01-08) <a href="https://doi.org/gh6dq2">https://doi.org/gh6dq2</a> <br />
DOI: <a href="https://doi.org/10.1093/nar/gkaa1024">10.1093/nar/gkaa1024</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33211851">33211851</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7779061">PMC7779061</a></p>
</div>
<div id="ref-12JtL2o6T">
<p>69. <strong>A Survey on Transfer Learning</strong> <br />
Sinno Jialin Pan, Qiang Yang<br />
<em>IEEE Transactions on Knowledge and Data Engineering</em> (2010-10) <a href="https://doi.org/bc4vws">https://doi.org/bc4vws</a> <br />
DOI: <a href="https://doi.org/10.1109/tkde.2009.191">10.1109/tkde.2009.191</a></p>
</div>
<div id="ref-160WNxTq0">
<p>70. <strong>A machine learning approach to integrate big data for precision medicine in acute myeloid leukemia</strong> <br />
Su-In Lee, Safiye Celik, Benjamin A. Logsdon, Scott M. Lundberg, Timothy J. Martins, Vivian G. Oehler, Elihu H. Estey, Chris P. Miller, Sylvia Chien, Jin Dai, … Pamela S. Becker<br />
<em>Nature Communications</em> (2018-12) <a href="https://doi.org/gcpx72">https://doi.org/gcpx72</a> <br />
DOI: <a href="https://doi.org/10.1038/s41467-017-02465-5">10.1038/s41467-017-02465-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29298978">29298978</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752671">PMC5752671</a></p>
</div>
<div id="ref-Ki2ij7zE">
<p>71. <strong>Pathway-level information extractor (PLIER) for gene expression data</strong> <br />
Weiguang Mao, Elena Zaslavsky, Boris M. Hartmann, Stuart C. Sealfon, Maria Chikina<br />
<em>Nature Methods</em> (2019-07) <a href="https://doi.org/gf75g6">https://doi.org/gf75g6</a> <br />
DOI: <a href="https://doi.org/10.1038/s41592-019-0456-1">10.1038/s41592-019-0456-1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31249421">31249421</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7262669">PMC7262669</a></p>
</div>
<div id="ref-14rnBunuZ">
<p>72. <strong>MultiPLIER: A Transfer Learning Framework for Transcriptomics Reveals Systemic Features of Rare Disease</strong> <br />
Jaclyn N. Taroni, Peter C. Grayson, Qiwen Hu, Sean Eddy, Matthias Kretzler, Peter A. Merkel, Casey S. Greene<br />
<em>Cell Systems</em> (2019-05) <a href="https://doi.org/gf75g5">https://doi.org/gf75g5</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cels.2019.04.003">10.1016/j.cels.2019.04.003</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31121115">31121115</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6538307">PMC6538307</a></p>
</div>
<div id="ref-6SPTvFXq">
<p>73. <strong>Reproducible RNA-seq analysis using recount2</strong> <br />
Leonardo Collado-Torres, Abhinav Nellore, Kai Kammers, Shannon E Ellis, Margaret A Taub, Kasper D Hansen, Andrew E Jaffe, Ben Langmead, Jeffrey T Leek<br />
<em>Nature Biotechnology</em> (2017-04) <a href="https://doi.org/gf75hp">https://doi.org/gf75hp</a> <br />
DOI: <a href="https://doi.org/10.1038/nbt.3838">10.1038/nbt.3838</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28398307">28398307</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6742427">PMC6742427</a></p>
</div>
<div id="ref-15UbILeOM">
<p>74. <strong>Rare-disease genetics in the era of next-generation sequencing: discovery to translation</strong> <br />
Kym M. Boycott, Megan R. Vanstone, Dennis E. Bulman, Alex E. MacKenzie<br />
<em>Nature Reviews Genetics</em> (2013-10) <a href="https://doi.org/ghvhsd">https://doi.org/ghvhsd</a> <br />
DOI: <a href="https://doi.org/10.1038/nrg3555">10.1038/nrg3555</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23999272">23999272</a></p>
</div>
<div id="ref-LSggBya9">
<p>75. <strong>Paediatric genomics: diagnosing rare disease in children</strong> <br />
Caroline F. Wright, David R. FitzPatrick, Helen V. Firth<br />
<em>Nature Reviews Genetics</em> (2018-05) <a href="https://doi.org/gcxbr8">https://doi.org/gcxbr8</a> <br />
DOI: <a href="https://doi.org/10.1038/nrg.2017.116">10.1038/nrg.2017.116</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29398702">29398702</a></p>
</div>
<div id="ref-6lu5irln">
<p>76. <strong>Next-Generation Sequencing to Diagnose Suspected Genetic Disorders</strong> <br />
David R. Adams, Christine M. Eng<br />
<em>New England Journal of Medicine</em> (2018-10-04) <a href="https://doi.org/gf49m7">https://doi.org/gf49m7</a> <br />
DOI: <a href="https://doi.org/10.1056/nejmra1711801">10.1056/nejmra1711801</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30281996">30281996</a></p>
</div>
<div id="ref-6uid5yCL">
<p>77. <strong>Responsible, practical genomic data sharing that accelerates research</strong> <br />
James Brian Byrd, Anna C. Greene, Deepashree Venkatesh Prasad, Xiaoqian Jiang, Casey S. Greene<br />
<em>Nature Reviews Genetics</em> (2020-10) <a href="https://www.nature.com/articles/s41576-020-0257-5">https://www.nature.com/articles/s41576-020-0257-5</a> <br />
DOI: <a href="https://doi.org/10.1038/s41576-020-0257-5">10.1038/s41576-020-0257-5</a></p>
</div>
<div id="ref-Ocnhl9GL">
<p>78. <strong>The future of digital health with federated learning</strong> <br />
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletarì, Holger R. Roth, Shadi Albarqouni, Spyridon Bakas, Mathieu N. Galtier, Bennett A. Landman, Klaus Maier-Hein, … M. Jorge Cardoso<br />
<em>npj Digital Medicine</em> (2020-12) <a href="https://doi.org/ghmnwd">https://doi.org/ghmnwd</a> <br />
DOI: <a href="https://doi.org/10.1038/s41746-020-00323-1">10.1038/s41746-020-00323-1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33015372">33015372</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7490367">PMC7490367</a></p>
</div>
<div id="ref-1CG1N5B62">
<p>79. <strong>A Continuously Benchmarked and Crowdsourced Challenge for Rapid Development and Evaluation of Models to Predict COVID-19 Diagnosis and Hospitalization</strong> <br />
Yao Yan, Thomas Schaffter, Timothy Bergquist, Thomas Yu, Justin Prosser, Zafer Aydin, Amhar Jabeer, Ivan Brugere, Jifan Gao, Guanhua Chen, … Jimmy Phuong<br />
<em>JAMA Network Open</em> (2021-10-11) <a href="https://doi.org/gpz2bw">https://doi.org/gpz2bw</a> <br />
DOI: <a href="https://doi.org/10.1001/jamanetworkopen.2021.24946">10.1001/jamanetworkopen.2021.24946</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34633425">34633425</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8506231">PMC8506231</a></p>
</div>
<div id="ref-q5rxB78C">
<p>80. <strong>“Why Should I Trust You?”: Explaining the Predictions of Any Classifier</strong> <br />
Marco Ribeiro, Sameer Singh, Carlos Guestrin<br />
<em>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</em> (2016) <a href="https://doi.org/gg8ggh">https://doi.org/gg8ggh</a> <br />
DOI: <a href="https://doi.org/10.18653/v1/n16-3020">10.18653/v1/n16-3020</a></p>
</div>
<div id="ref-HovsEtqX">
<p>81. <strong>Errudite: Scalable, Reproducible, and Testable Error Analysis</strong> <br />
Tongshuang Wu, Marco Tulio Ribeiro, Jeffrey Heer, Daniel Weld<br />
<em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em> (2019) <a href="https://doi.org/ggb9kk">https://doi.org/ggb9kk</a> <br />
DOI: <a href="https://doi.org/10.18653/v1/p19-1073">10.18653/v1/p19-1073</a></p>
</div>
<div id="ref-sa8SP0BL">
<p>82. <a href="https://direct.mit.edu/coli/article/37/4/657/2124/Towards-Automatic-Error-Analysis-of-Machine">https://direct.mit.edu/coli/article/37/4/657/2124/Towards-Automatic-Error-Analysis-of-Machine</a></p>
</div>
<div id="ref-uvZAopDf">
<p>83. <strong>Recognizing names in biomedical texts: a machine learning approach</strong> <br />
G. Zhou, J. Zhang, J. Su, D. Shen, C. Tan<br />
<em>Bioinformatics</em> (2004-05-01) <a href="https://doi.org/bxts7r">https://doi.org/bxts7r</a> <br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bth060">10.1093/bioinformatics/bth060</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14871877">14871877</a></p>
</div>
<div id="ref-16wWzu3NO">
<p>84. <strong>Domain Adaptation with Structural Correspondence Learning</strong> <br />
John Blitzer, Ryan McDonald, Fernando Pereira<br />
<em>Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</em> (2006-07) <a href="https://aclanthology.org/W06-1615">https://aclanthology.org/W06-1615</a></p>
</div>
<div id="ref-oZmhjP9I">
<p>85. <strong>Heterogeneous domain adaptation using manifold alignment</strong> <br />
Chang Wang, Sridhar Mahadevan<br />
<em>Proceedings of the Twenty-Second international joint conference on Artificial Intelligence - Volume Volume Two</em> (2011-07-16) <a href="https://dl.acm.org/doi/10.5555/2283516.2283652">https://dl.acm.org/doi/10.5555/2283516.2283652</a> <br />
ISBN: <a href="https://worldcat.org/isbn/9781577355144">9781577355144</a></p>
</div>
<div id="ref-bOT9Zmn2">
<p>86. <strong>Comprehensive Integration of Single-Cell Data</strong> <br />
Tim Stuart, Andrew Butler, Paul Hoffman, Christoph Hafemeister, Efthymia Papalexi, William M. Mauck, Yuhan Hao, Marlon Stoeckius, Peter Smibert, Rahul Satija<br />
<em>Cell</em> (2019-06) <a href="https://doi.org/gf3sxv">https://doi.org/gf3sxv</a> <br />
DOI: <a href="https://doi.org/10.1016/j.cell.2019.05.031">10.1016/j.cell.2019.05.031</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31178118">31178118</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6687398">PMC6687398</a></p>
</div>
<div id="ref-c8wzz15m">
<p>87. <strong>The Elements of Statistical Learning</strong> <a href="https://link.springer.com/book/10.1007/978-0-387-21606-5">https://link.springer.com/book/10.1007/978-0-387-21606-5</a></p>
</div>
<div id="ref-urca2RD9">
<p>88. <strong>A guide to machine learning for biologists</strong> <br />
Joe G. Greener, Shaun M. Kandathil, Lewis Moffat, David T. Jones<br />
<em>Nature Reviews Molecular Cell Biology</em> (2022-01) <a href="https://doi.org/gmsvvn">https://doi.org/gmsvvn</a> <br />
DOI: <a href="https://doi.org/10.1038/s41580-021-00407-0">10.1038/s41580-021-00407-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34518686">34518686</a></p>
</div>
<div id="ref-1GAyqYBNZ">
<p>89. <strong>Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning</strong> <br />
Hoo-Chang Shin, Holger R. Roth, Mingchen Gao, Le Lu, Ziyue Xu, Isabella Nogues, Jianhua Yao, Daniel Mollura, Ronald M. Summers<br />
<em>IEEE Transactions on Medical Imaging</em> (2016-05) <a href="https://doi.org/gcgmbg">https://doi.org/gcgmbg</a> <br />
DOI: <a href="https://doi.org/10.1109/tmi.2016.2528162">10.1109/tmi.2016.2528162</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26886976">26886976</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4890616">PMC4890616</a></p>
</div>
</div>
<!-- default theme -->

<style>
    /* import google fonts */
    @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
    @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

    /* -------------------------------------------------- */
    /* global */
    /* -------------------------------------------------- */

    /* all elements */
    * {
        /* force sans-serif font unless specified otherwise */
        font-family: "Open Sans", "Helvetica", sans-serif;

        /* prevent text inflation on some mobile browsers */
        -webkit-text-size-adjust: none !important;
        -moz-text-size-adjust: none !important;
        -o-text-size-adjust: none !important;
        text-size-adjust: none !important;
    }

    @media only screen {
        /* "page" element */
        body {
            position: relative;
            box-sizing: border-box;
            font-size: 12pt;
            line-height: 1.5;
            max-width: 8.5in;
            margin: 20px auto;
            padding: 40px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* "page" element */
        body {
            padding: 20px;
            margin: 0;
            border-radius: 0;
            border: none;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
            background: none;
        }
    }

    /* -------------------------------------------------- */
    /* headings */
    /* -------------------------------------------------- */

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 20px 0;
        padding: 0;
        font-weight: bold;
    }

    /* biggest heading */
    h1 {
        margin: 40px 0;
        text-align: center;
    }

    /* second biggest heading */
    h2 {
        margin-top: 30px;
        padding-bottom: 5px;
        border-bottom: solid 1px #bdbdbd;
    }

    /* heading font sizes */
    h1 {
        font-size: 2em;
    }
    h2 {
        font-size: 1.5em;
    }
    h3{
        font-size: 1.35em;
    }
    h4 {
        font-size: 1.25em;
    }
    h5 {
        font-size: 1.15em;
    }
    h6 {
        font-size: 1em;
    }

    /* -------------------------------------------------- */
    /* manuscript header */
    /* -------------------------------------------------- */

    /* manuscript title */
    header > h1 {
        margin: 0;
    }

    /* manuscript title caption text (ie "automatically generated on") */
    header + p {
        text-align: center;
        margin-top: 10px;
    }

    /* -------------------------------------------------- */
    /* text elements */
    /* -------------------------------------------------- */

    /* links */
    a {
        color: #2196f3;
        overflow-wrap: break-word;
    }

    /* normal links (not empty, not button link, not syntax highlighting link) */
    a:not(:empty):not(.button):not(.sourceLine) {
        padding-left: 1px;
        padding-right: 1px;
    }

    /* superscripts and subscripts */
    sub,
    sup {
        /* prevent from affecting line height */
        line-height: 0;
    }

    /* unordered and ordered lists*/
    ul,
    ol {
        padding-left: 20px;
    }

    /* class for styling text semibold */
    .semibold {
        font-weight: 600;
    }

    /* class for styling elements horizontally left aligned */
    .left {
        display: block;
        text-align: left;
        margin-left: auto;
        margin-right: 0;
        justify-content: left;
    }

    /* class for styling elements horizontally centered */
    .center {
        display: block;
        text-align: center;
        margin-left: auto;
        margin-right: auto;
        justify-content: center;
    }

    /* class for styling elements horizontally right aligned */
    .right {
        display: block;
        text-align: right;
        margin-left: 0;
        margin-right: auto;
        justify-content: right;
    }

    /* -------------------------------------------------- */
    /* section elements */
    /* -------------------------------------------------- */

    /* horizontal divider line */
    hr {
        border: none;
        height: 1px;
        background: #bdbdbd;
    }

    /* paragraphs, horizontal dividers, figures, tables, code */
    p,
    hr,
    figure,
    table,
    pre {
        /* treat all as "paragraphs", with consistent vertical margins */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* figures */
    /* -------------------------------------------------- */

    /* figure */
    figure {
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure caption */
    figcaption {
        padding: 0;
        padding-top: 10px;
    }

    /* figure image element */
    figure > img,
    figure > svg {
        max-width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure auto-number */
    img + figcaption > span:first-of-type,
    svg + figcaption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* tables */
    /* -------------------------------------------------- */

    /* table */
    table {
        border-collapse: collapse;
        border-spacing: 0;
        width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* table cells */
    th,
    td {
        border: solid 1px #bdbdbd;
        padding: 10px;
        /* squash table if too wide for page by forcing line breaks */
        overflow-wrap: break-word;
        word-break: break-word;
    }

    /* header row and even rows */
    th,
    tr:nth-child(2n) {
        background-color: #fafafa;
    }

    /* odd rows */
    tr:nth-child(2n + 1) {
        background-color: #ffffff;
    }

    /* table caption */
    caption {
        text-align: left;
        padding: 0;
        padding-bottom: 10px;
    }

    /* table auto-number */
    table > caption > span:first-of-type,
    div.table_wrapper > table > caption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* code */
    /* -------------------------------------------------- */

    /* multi-line code block */
    pre {
        padding: 10px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
        break-inside: avoid;
        text-align: left;
    }

    /* inline code, ie code within normal text */
    :not(pre) > code {
        padding: 0 4px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
    }

    /* code text */
    /* apply all children, to reach syntax highlighting sub-elements */
    code,
    code * {
        /* force monospace font */
        font-family: "Source Code Pro", "Courier New", monospace;
    }

    /* -------------------------------------------------- */
    /* quotes */
    /* -------------------------------------------------- */

    /* quoted text */
    blockquote {
        margin: 0;
        padding: 0;
        border-left: 4px solid #bdbdbd;
        padding-left: 16px;
        break-inside: avoid;
    }

    /* -------------------------------------------------- */
    /* banners */
    /* -------------------------------------------------- */

    /* info banners */
    .banner {
        box-sizing: border-box;
        display: block;
        position: relative;
        width: 100%;
        margin-top: 20px;
        margin-bottom: 20px;
        padding: 20px;
        text-align: center;
    }

    /* paragraph in banner */
    .banner > p {
        margin: 0;
    }

    /* -------------------------------------------------- */
    /* highlight colors */
    /* -------------------------------------------------- */

    .white {
        background: #ffffff;
    }
    .lightgrey {
        background: #eeeeee;
    }
    .grey {
        background: #757575;
    }
    .darkgrey {
        background: #424242;
    }
    .black {
        background: #000000;
    }
    .lightred {
        background: #ffcdd2;
    }
    .lightyellow {
        background: #ffecb3;
    }
    .lightgreen {
        background: #dcedc8;
    }
    .lightblue {
        background: #e3f2fd;
    }
    .lightpurple {
        background: #f3e5f5;
    }
    .red {
        background: #f44336;
    }
    .orange {
        background: #ff9800;
    }
    .yellow {
        background: #ffeb3b;
    }
    .green {
        background: #4caf50;
    }
    .blue {
        background: #2196f3;
    }
    .purple {
        background: #9c27b0;
    }
    .white,
    .lightgrey,
    .lightred,
    .lightyellow,
    .lightgreen,
    .lightblue,
    .lightpurple,
    .orange,
    .yellow,
    .white a,
    .lightgrey a,
    .lightred a,
    .lightyellow a,
    .lightgreen a,
    .lightblue a,
    .lightpurple a,
    .orange a,
    .yellow a {
        color: #000000;
    }
    .grey,
    .darkgrey,
    .black,
    .red,
    .green,
    .blue,
    .purple,
    .grey a,
    .darkgrey a,
    .black a,
    .red a,
    .green a,
    .blue a,
    .purple a {
        color: #ffffff;
    }

    /* -------------------------------------------------- */
    /* buttons */
    /* -------------------------------------------------- */

    /* class for styling links like buttons */
    .button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        margin: 5px;
        padding: 10px 20px;
        font-size: 0.75em;
        font-weight: 600;
        text-transform: uppercase;
        text-decoration: none;
        letter-spacing: 1px;
        background: none;
        color: #2196f3;
        border: solid 1px #bdbdbd;
        border-radius: 5px;
    }

    /* buttons when hovered */
    .button:hover:not([disabled]),
    .icon_button:hover:not([disabled]) {
        cursor: pointer;
        background: #f5f5f5;
    }

    /* buttons when disabled */
    .button[disabled],
    .icon_button[disabled] {
        opacity: 0.35;
        pointer-events: none;
    }

    /* class for styling buttons containg only single icon */
    .icon_button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        text-decoration: none;
        margin: 0;
        padding: 0;
        background: none;
        border-radius: 5px;
        border: none;
        width: 20px;
        height: 20px;
        min-width: 20px;
        min-height: 20px;
    }

    /* icon button inner svg image */
    .icon_button > svg {
        height: 16px;
    }

    /* -------------------------------------------------- */
    /* icons */
    /* -------------------------------------------------- */

    /* class for styling icons inline with text */
    .inline_icon {
        height: 1em;
        position: relative;
        top: 0.125em;
    }

    /* -------------------------------------------------- */
    /* print control */
    /* -------------------------------------------------- */

    @media print {
        @page {
            /* suggested printing margin */
            margin: 0.5in;
        }

        /* document and "page" elements */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
        }

        /* "page" element */
        body {
            font-size: 11pt !important;
            line-height: 1.35;
        }

        /* all headings */
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            margin: 15px 0;
        }

        /* figures and tables */
        figure, table {
            font-size: 0.85em;
        }

        /* table cells */
        th,
        td {
            padding: 5px;
        }

        /* shrink font awesome icons */
        i.fas,
        i.fab,
        i.far,
        i.fal {
            transform: scale(0.85);
        }

        /* decrease banner margins */
        .banner {
            margin-top: 15px;
            margin-bottom: 15px;
            padding: 15px;
        }

        /* class for centering an element vertically on its own page */
        .page_center {
            margin: auto;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            vertical-align: middle;
            break-before: page;
            break-after: page;
        }

        /* always insert a page break before the element */
        .page_break_before {
            break-before: page;
        }

        /* always insert a page break after the element */
        .page_break_after {
            break-after: page;
        }

        /* avoid page break before the element */
        .page_break_before_avoid {
            break-before: avoid;
        }

        /* avoid page break after the element */
        .page_break_after_avoid {
            break-after: avoid;
        }

        /* avoid page break inside the element */
        .page_break_inside_avoid {
            break-inside: avoid;
        }
    }

    /* -------------------------------------------------- */
    /* override pandoc css quirks */
    /* -------------------------------------------------- */

    .sourceCode {
        /* prevent unsightly overflow in wide code blocks */
        overflow: auto !important;
    }

    div.sourceCode {
        /* prevent background fill on top-most code block  container */
        background: none !important;
    }

    .sourceCode * {
        /* force consistent line spacing */
        line-height: 1.5 !important;
    }

    div.sourceCode {
        /* style code block margins same as <pre> element */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* tablenos */
    /* -------------------------------------------------- */

    /* tablenos wrapper */
    .tablenos {
        /* show scrollbar on tables if necessary to prevent overflow */
        width: 100%;
        margin: 20px 0;
    }

    .tablenos > table {
        /* move margins from table to table_wrapper to allow margin collapsing */
        margin: 0;
    }

    @media only screen {
        /* tablenos wrapper */
        .tablenos {
            /* show scrollbar on tables if necessary to prevent overflow */
            overflow-x: auto !important;
        }

        .tablenos th,
        .tablenos td {
            overflow-wrap: unset !important;
            word-break: unset !important;
        }

        /* table in wrapper */
        .tablenos table,
        .tablenos table * {
            /* don't break table words */
            overflow-wrap: normal !important;
        }
    }

    /* -------------------------------------------------- */
    /* mathjax */
    /* -------------------------------------------------- */

    /* mathjax containers */
    .math.display > span:not(.MathJax_Preview) {
        /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
        display: flex !important;
        overflow-x: auto !important;
        overflow-y: hidden !important;
        justify-content: center;
        align-items: center;
        margin: 0 !important;
    }

    /* right click menu */
    .MathJax_Menu {
        border-radius: 5px !important;
        border: solid 1px #bdbdbd !important;
        box-shadow: none !important;
    }

    /* equation auto-number */
    span[id^="eq:"] > span.math.display + span {
        font-weight: 600;
    }

    /* equation */
    span[id^="eq:"] > span.math.display > span {
        /* nudge to make room for equation auto-number and anchor */
        margin-right: 60px !important;
    }

    /* -------------------------------------------------- */
    /* anchors plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anchor button */
        .anchor {
            opacity: 0;
            margin-left: 5px;
        }

        /* anchor buttons within <h2>'s */
        h2 .anchor {
            margin-left: 10px;
        }

        /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
        *:hover > .anchor,
        .anchor:hover,
        .anchor:focus {
            opacity: 1;
        }

        /* anchor button when hovered */
        .anchor:hover {
            cursor: pointer;
        }
    }

    /* always show anchor button on devices with no mouse/hover ability */
    @media (hover: none) {
        .anchor {
            opacity: 1;
        }
    }

    /* always hide anchor button on print */
    @media only print {
        .anchor {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* accordion plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* accordion arrow button */
        .accordion_arrow {
            margin-right: 10px;
        }

        /* arrow icon when <h2> data-collapsed attribute true */
        h2[data-collapsed="true"] > .accordion_arrow > svg {
            transform: rotate(-90deg);
        }

        /* all elements (except <h2>'s) when data-collapsed attribute true */
        *:not(h2)[data-collapsed="true"] {
            display: none;
        }

        /* accordion arrow button when hovered and <h2>'s when hovered */
        .accordion_arrow:hover,
        h2[data-collapsed="true"]:hover,
        h2[data-collapsed="false"]:hover {
            cursor: pointer;
        }
    }

    /* always hide accordion arrow button on print */
    @media only print {
        .accordion_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* tooltips plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* tooltip container */
        #tooltip {
            position: absolute;
            width: 50%;
            min-width: 240px;
            max-width: 75%;
            z-index: 1;
        }

        /* tooltip content */
        #tooltip_content {
            margin-bottom: 5px;
            padding: 20px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
            overflow-wrap: break-word;
        }

        /* tooltip copy of paragraphs and figures */
        #tooltip_content > p,
        #tooltip_content > figure {
            margin: 0;
            max-height: 320px;
            overflow-y: auto;
        }

        /* tooltip copy of <img> */
        #tooltip_content > figure > img,
        #tooltip_content > figure > svg {
            max-height: 260px;
        }

        /* navigation bar */
        #tooltip_nav_bar {
            margin-top: 10px;
            text-align: center;
        }

        /* navigation bar previous/next buton */
        #tooltip_nav_bar > .icon_button {
            position: relative;
            top: 3px;
        }

        /* navigation bar previous button */
        #tooltip_nav_bar > .icon_button:first-of-type {
            margin-right: 5px;
        }

        /* navigation bar next button */
        #tooltip_nav_bar > .icon_button:last-of-type {
            margin-left: 5px;
        }
    }

    /* always hide tooltip on print */
    @media only print {
        #tooltip {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* jump to first plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* jump button */
        .jump_arrow {
            position: relative;
            top: 0.125em;
            margin-right: 5px;
        }
    }

    /* always hide jump button on print */
    @media only print {
        .jump_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* link highlight plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anything with data-highlighted attribute true */
        [data-highlighted="true"] {
            background: #ffeb3b;
        }

        /* anything with data-selected attribute true */
        [data-selected="true"] {
            background: #ff8a65 !important;
        }

        /* animation definition for glow */
        @keyframes highlight_glow {
            0% {
                background: none;
            }
            10% {
                background: #bbdefb;
            }
            100% {
                background: none;
            }
        }

        /* anything with data-glow attribute true */
        [data-glow="true"] {
            animation: highlight_glow 2s;
        }
    }

    /* -------------------------------------------------- */
    /* table of contents plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* toc panel */
        #toc_panel {
            box-sizing: border-box;
            position: fixed;
            top: 0;
            left: 0;
            background: #ffffff;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            z-index: 2;
        }

        /* toc panel when closed */
        #toc_panel[data-open="false"] {
            min-width: 60px;
            width: 60px;
            height: 60px;
            border-right: solid 1px #bdbdbd;
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc panel when open */
        #toc_panel[data-open="true"] {
            min-width: 260px;
            max-width: 480px;
            /* keep panel edge consistent distance away from "page" edge */
            width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
            bottom: 0;
            border-right: solid 1px #bdbdbd;
        }

        /* toc panel header */
        #toc_header {
            box-sizing: border-box;
            display: flex;
            flex-direction: row;
            align-items: center;
            height: 60px;
            margin: 0;
            padding: 20px;
        }

        /* toc panel header when hovered */
        #toc_header:hover {
            cursor: pointer;
        }

        /* toc panel header when panel open */
        #toc_panel[data-open="true"] > #toc_header {
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc open/close header button */
        #toc_button {
            margin-right: 20px;
        }

        /* hide toc list and header text when closed */
        #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
        #toc_panel[data-open="false"] > #toc_list {
            display: none;
        }

        /* toc list of entries */
        #toc_list {
            box-sizing: border-box;
            width: 100%;
            padding: 20px;
            position: absolute;
            top: calc(60px + 1px);
            bottom: 0;
            overflow: auto;
        }

        /* toc entry, link to section in document */
        .toc_link {
            display: block;
            padding: 5px;
            position: relative;
            font-weight: 600;
            text-decoration: none;
        }

        /* toc entry when hovered or when "viewed" */
        .toc_link:hover,
        .toc_link[data-viewing="true"] {
            background: #f5f5f5;
        }

        /* toc entry, level 1 indentation */
        .toc_link[data-level="1"] {
            margin-left: 0;
        }

        /* toc entry, level 2 indentation */
        .toc_link[data-level="2"] {
            margin-left: 20px;
        }

        /* toc entry, level 3 indentation */
        .toc_link[data-level="3"] {
            margin-left: 40px;
        }

        /* toc entry, level 4 indentation */
        .toc_link[data-level="4"] {
            margin-left: 60px;
        }

        /* toc entry bullets */
        #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
            position: absolute;
            left: -15px;
            top: -1px;
            font-size: 1.5em;
        }

        /* toc entry, level 2 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
            content: "\2022";
        }

        /* toc entry, level 3 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
            content: "\25AB";
        }

        /* toc entry, level 4 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
            content: "-";
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* push <body> ("page") element down to make room for toc icon */
        .toc_body_nudge {
            padding-top: 60px;
        }

        /* toc icon when panel closed and not hovered */
        #toc_panel[data-open="false"]:not(:hover) {
            background: rgba(255, 255, 255, 0.75);
        }
    }

    /* always hide toc panel on print */
    @media only print {
        #toc_panel {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* lightbox plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* regular <img> in document when hovered */
        img.lightbox_document_img:hover {
            cursor: pointer;
        }

        .body_no_scroll {
            overflow: hidden !important;
        }

        /* screen overlay */
        #lightbox_overlay {
            display: flex;
            flex-direction: column;
            position: fixed;
            left: 0;
            top: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.75);
            z-index: 3;
        }

        /* middle area containing lightbox image */
        #lightbox_image_container {
            flex-grow: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            position: relative;
            padding: 20px;
        }

        /* bottom area containing caption */
        #lightbox_bottom_container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100px;
            min-height: 100px;
            max-height: 100px;
            background: rgba(0, 0, 0, 0.5);
        }

        /* image number info text box */
        #lightbox_number_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            left: 2px;
            top: 0;
            z-index: 4;
        }

        /* zoom info text box */
        #lightbox_zoom_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            right: 2px;
            top: 0;
            z-index: 4;
        }

        /* copy of image caption */
        #lightbox_caption {
            box-sizing: border-box;
            display: inline-block;
            width: 100%;
            max-height: 100%;
            padding: 10px 0;
            text-align: center;
            overflow-y: auto;
            color: #ffffff;
        }

        /* navigation previous/next button */
        .lightbox_button {
            width: 100px;
            height: 100%;
            min-width: 100px;
            min-height: 100%;
            color: #ffffff;
        }

        /* navigation previous/next button when hovered */
        .lightbox_button:hover {
            background: none !important;
        }

        /* navigation button icon */
        .lightbox_button > svg {
            height: 25px;
        }

        /* figure auto-number */
        #lightbox_caption > span:first-of-type {
            font-weight: bold;
            margin-right: 5px;
        }

        /* lightbox image when hovered */
        #lightbox_img:hover {
            cursor: grab;
        }

        /* lightbox image when grabbed */
        #lightbox_img:active {
            cursor: grabbing;
        }
    }

    /* when on screen < 480px wide */
    @media only screen and (max-width: 480px) {
        /* make navigation buttons skinnier on small screens to make more room for caption text */
        .lightbox_button {
            width: 50px;
            min-width: 50px;
        }
    }

    /* always hide lightbox on print */
    @media only print {
        #lightbox_overlay {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* hypothesis (annotations) plugin */
    /* -------------------------------------------------- */

    /* hypothesis activation button */
    #hypothesis_button {
        box-sizing: border-box;
        position: fixed;
        top: 0;
        right: 0;
        width: 60px;
        height: 60px;
        background: #ffffff;
        border-radius: 0;
        border-left: solid 1px #bdbdbd;
        border-bottom: solid 1px #bdbdbd;
        box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
        z-index: 2;
    }

    /* hypothesis button svg */
    #hypothesis_button > svg {
        position: relative;
        top: -4px;
    }

    /* hypothesis annotation count */
    #hypothesis_count {
        position: absolute;
        left: 0;
        right: 0;
        bottom: 5px;
    }

    /* side panel */
    .annotator-frame {
        width: 280px !important;
    }

    /* match highlight color to rest of theme */
    .annotator-highlights-always-on .annotator-hl {
        background-color: #ffeb3b !important;
    }

    /* match focused color to rest of theme */
    .annotator-hl.annotator-hl-focused {
        background-color: #ff8a65 !important;
    }

    /* match bucket bar color to rest of theme */
    .annotator-bucket-bar {
        background: #f5f5f5 !important;
    }

    /* always hide button, toolbar, and tooltip on print */
    @media only print {
        #hypothesis_button {
            display: none;
        }

        .annotator-frame {
            display: none !important;
        }

        hypothesis-adder {
            display: none !important;
        }
    }
</style>
<!-- anchors plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds an anchor next to each of a certain type
        // of element that provides a human-readable url to that specific
        // item/position in the document (eg "manuscript.html#abstract"). It
        // also makes it such that scrolling out of view of a target removes
        // its identifier from the url.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'anchors';

        // default plugin options
        const options = {
            // which types of elements to add anchors next to, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3, [id^="fig:"], [id^="tbl:"], [id^="eq:"]',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // add anchor to each element of specified types
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements)
                addAnchor(element);

            // attach scroll listener to window
            window.addEventListener('scroll', onScroll);
        }

        // when window is scrolled
        function onScroll() {
            // if url has hash and user has scrolled out of view of hash
            // target, remove hash from url
            const tolerance = 100;
            const target = getHashTarget();
            if (target) {
                if (
                    target.getBoundingClientRect().top >
                        window.innerHeight + tolerance ||
                    target.getBoundingClientRect().bottom < 0 - tolerance
                )
                    history.pushState(null, null, ' ');
            }
        }

        // add anchor to element
        function addAnchor(element) {
            let addTo; // element to add anchor button to

            // if figure or table, modify withId and addTo to get expected
            // elements
            if (element.id.indexOf('fig:') === 0) {
                addTo = element.querySelector('figcaption');
            } else if (element.id.indexOf('tbl:') === 0) {
                addTo = element.querySelector('caption');
            } else if (element.id.indexOf('eq:') === 0) {
                addTo = element.querySelector('.eqnos-number');
            }

            addTo = addTo || element;
            const id = element.id || null;

            // do not add anchor if element doesn't have assigned id.
            // id is generated by pandoc and is assumed to be unique and
            // human-readable
            if (!id)
                return;

            // create anchor button
            const anchor = document.createElement('a');
            anchor.innerHTML = document.querySelector('.icon_link').innerHTML;
            anchor.title = 'Link to this part of the document';
            anchor.classList.add('icon_button', 'anchor');
            anchor.dataset.ignore = 'true';
            anchor.href = '#' + id;
            addTo.appendChild(anchor);
        }

        // get element that is target of link or url hash
        function getHashTarget() {
            const hash = window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- link icon -->

<template class="icon_link">
    <!-- modified from: https://fontawesome.com/icons/link -->
    <svg width="16" height="16" viewBox="0 0 512 512">
        <path
            fill="currentColor"
            d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
        ></path>
    </svg>
</template>
<!-- accordion plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows sections of content under <h2> headings
        // to be collapsible.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'accordion';

        // default plugin options
        const options = {
            // whether to always start expanded ('false'), always start
            // collapsed ('true'), or start collapsed when screen small ('auto')
            startCollapsed: 'auto',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <h2> heading
            const headings = document.querySelectorAll('h2');
            for (const heading of headings) {
                addArrow(heading);

                // start expanded/collapsed based on option
                if (
                    options.startCollapsed === 'true' ||
                    (options.startCollapsed === 'auto' && isSmallScreen())
                )
                    collapseHeading(heading);
                else
                    expandHeading(heading);
            }

            // attach hash change listener to window
            window.addEventListener('hashchange', onHashChange);
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                goToElement(target);
        }

        // add arrow to heading
        function addArrow(heading) {
            // add arrow button
            const arrow = document.createElement('button');
            arrow.innerHTML = document.querySelector(
                '.icon_angle_down'
            ).innerHTML;
            arrow.classList.add('icon_button', 'accordion_arrow');
            heading.insertBefore(arrow, heading.firstChild);

            // attach click listener to heading and button
            heading.addEventListener('click', onHeadingClick);
            arrow.addEventListener('click', onArrowClick);
        }

        // determine if on mobile-like device with small screen
        function isSmallScreen() {
            return Math.min(window.innerWidth, window.innerHeight) < 480;
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get element that is target of hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');
            if (id.indexOf('tbl:') === 0)
                target = target.querySelector('table');

            return target;
        }

        // when <h2> heading is clicked
        function onHeadingClick(event) {
            // only collapse if <h2> itself is target of click (eg, user did
            // not click on anchor within <h2>)
            if (event.target === this)
                toggleCollapse(this);
        }

        // when arrow button is clicked
        function onArrowClick() {
            toggleCollapse(this.parentNode);
        }

        // collapse section if expanded, expand if collapsed
        function toggleCollapse(heading) {
            if (heading.dataset.collapsed === 'false')
                collapseHeading(heading);
            else
                expandHeading(heading);
        }

        // elements to exclude from collapse, such as table of contents panel,
        // hypothesis panel, etc
        const exclude = '#toc_panel, div.annotator-frame, #lightbox_overlay';

        // collapse section
        function collapseHeading(heading) {
            heading.setAttribute('data-collapsed', 'true');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'true');
        }

        // expand section
        function expandHeading(heading) {
            heading.setAttribute('data-collapsed', 'false');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'false');
        }

        // get list of elements between this <h2> and next <h2> or <h1>
        // ("children" of the <h2> section)
        function getChildren(heading) {
            return nextUntil(heading, 'h2, h1', exclude);
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get list of elements after a start element up to element matching
        // query
        function nextUntil(element, query, exclude) {
            const elements = [];
            while (element = element.nextElementSibling, element) {
                if (element.matches(query))
                    break;
                if (!element.matches(exclude))
                    elements.push(element);
            }
            return elements;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
    <!-- modified from: https://fontawesome.com/icons/angle-down -->
    <svg width="16" height="16" viewBox="0 0 448 512">
        <path
            fill="currentColor"
            d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
        ></path>
    </svg>
</template>
<!-- tooltips plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when the user hovers or
        // focuses a link to a citation or figure, a tooltip appears with a
        // preview of the reference content, along with arrows to navigate
        // between instances of the same reference in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tooltips';

        // default plugin options
        const options = {
            // whether user must click off to close tooltip instead of just
            // un-hovering
            clickClose: 'false',
            // delay (in ms) between opening and closing tooltip
            delay: '100',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach hover and focus listeners to link
                link.addEventListener('mouseover', onLinkHover);
                link.addEventListener('mouseleave', onLinkUnhover);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('touchend', onLinkTouch);
            }

            // attach mouse, key, and resize listeners to window
            window.addEventListener('mousedown', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('keyup', onKeyUp);
            window.addEventListener('resize', onResize);
        }

        // when link is hovered
        function onLinkHover() {
            // function to open tooltip
            const delayOpenTooltip = function() {
                openTooltip(this);
            }.bind(this);

            // run open function after delay
            this.openTooltipTimer = window.setTimeout(
                delayOpenTooltip,
                options.delay
            );
        }

        // when mouse leaves link
        function onLinkUnhover() {
            // cancel opening tooltip
            window.clearTimeout(this.openTooltipTimer);

            // don't close on unhover if option specifies
            if (options.clickClose === 'true')
                return;

            // function to close tooltip
            const delayCloseTooltip = function() {
                // if tooltip open and if mouse isn't over tooltip, close
                const tooltip = document.getElementById('tooltip');
                if (tooltip && !tooltip.matches(':hover'))
                    closeTooltip();
            };

            // run close function after delay
            this.closeTooltipTimer = window.setTimeout(
                delayCloseTooltip,
                options.delay
            );
        }

        // when link is focused (tabbed to)
        function onLinkFocus(event) {
            openTooltip(this);
        }

        // when link is touched on touch screen
        function onLinkTouch(event) {
            // attempt to force hover state on first tap always, and trigger
            // regular link click (and navigation) on second tap
            if (event.target === document.activeElement)
                event.target.click();
            else {
                document.activeElement.blur();
                event.target.focus();
            }
            if (event.cancelable)
                event.preventDefault();
            event.stopPropagation();
            return false;
        }

        // when mouse is clicked anywhere in window
        function onClick(event) {
            closeTooltip();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'tooltip_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'tooltip_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeTooltip();
                    break;
            }
        }

        // when window is resized or zoomed
        function onResize() {
            closeTooltip();
        }

        // get all links of types we wish to handle
        function getLinks() {
            const queries = [];
            // exclude buttons, anchor links, toc links, etc
            const exclude =
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            queries.push('a[href^="#ref-"]' + exclude); // citation links
            queries.push('a[href^="#fig:"]' + exclude); // figure links
            const query = queries.join(', ');
            return document.querySelectorAll(query);
        }

        // get links with same target, get index of link in set, get total
        // same links
        function getSameLinks(link) {
            const sameLinks = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    sameLinks.push(otherLink);
            }

            return {
                elements: sameLinks,
                index: sameLinks.indexOf(link),
                total: sameLinks.length
            };
        }

        // open tooltip
        function openTooltip(link) {
            // delete tooltip if it exists, start fresh
            closeTooltip();

            // make tooltip element
            const tooltip = makeTooltip(link);

            // if source couldn't be found and tooltip not made, exit
            if (!tooltip)
                return;

            // make navbar elements
            const navBar = makeNavBar(link);
            if (navBar)
                tooltip.firstElementChild.appendChild(navBar);

            // attach tooltip to page
            document.body.appendChild(tooltip);

            // position tooltip
            const position = function() {
                positionTooltip(link);
            };
            position();

            // if tooltip contains images, position again after they've loaded
            const imgs = tooltip.querySelectorAll('img');
            for (const img of imgs)
                img.addEventListener('load', position);
        }

        // close (delete) tooltip
        function closeTooltip() {
            const tooltip = document.getElementById('tooltip');
            if (tooltip)
                tooltip.remove();
        }

        // make tooltip
        function makeTooltip(link) {
            // get target element that link points to
            const source = getSource(link);

            // if source can't be found, exit
            if (!source)
                return;

            // create new tooltip
            const tooltip = document.createElement('div');
            tooltip.id = 'tooltip';
            const tooltipContent = document.createElement('div');
            tooltipContent.id = 'tooltip_content';
            tooltip.appendChild(tooltipContent);

            // make copy of source node and put in tooltip
            const sourceCopy = makeCopy(source);
            tooltipContent.appendChild(sourceCopy);

            // attach mouse event listeners
            tooltip.addEventListener('click', onTooltipClick);
            tooltip.addEventListener('mousedown', onTooltipClick);
            tooltip.addEventListener('touchstart', onTooltipClick);
            tooltip.addEventListener('mouseleave', onTooltipUnhover);

            // (for interaction with lightbox plugin)
            // transfer click on tooltip copied img to original img
            const sourceImg = source.querySelector('img');
            const sourceCopyImg = sourceCopy.querySelector('img');
            if (sourceImg && sourceCopyImg) {
                const clickImg = function() {
                    sourceImg.click();
                    closeTooltip();
                };
                sourceCopyImg.addEventListener('click', clickImg);
            }

            return tooltip;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // when tooltip is clicked
        function onTooltipClick(event) {
            // when user clicks on tooltip, stop click from transferring
            // outside of tooltip (eg, click off to close tooltip, or eg click
            // off to unhighlight same refs)
            event.stopPropagation();
        }

        // when tooltip is unhovered
        function onTooltipUnhover(event) {
            if (options.clickClose === 'true')
                return;

            // make sure new mouse/touch/focus no longer over tooltip or any
            // element within it
            const tooltip = document.getElementById('tooltip');
            if (!tooltip)
                return;
            if (this.contains(event.relatedTarget))
                return;

            closeTooltip();
        }

        // make nav bar to go betwen prev/next instances of same reference
        function makeNavBar(link) {
            // find other links to the same source
            const sameLinks = getSameLinks(link);

            // don't show nav bar when singular reference
            if (sameLinks.total <= 1)
                return;

            // find prev/next links with same target
            const prevLink = getPrevLink(link, sameLinks);
            const nextLink = getNextLink(link, sameLinks);

            // create nav bar
            const navBar = document.createElement('div');
            navBar.id = 'tooltip_nav_bar';
            const text = sameLinks.index + 1 + ' of ' + sameLinks.total;

            // create nav bar prev/next buttons
            const prevButton = document.createElement('button');
            const nextButton = document.createElement('button');
            prevButton.id = 'tooltip_prev_button';
            nextButton.id = 'tooltip_next_button';
            prevButton.title =
                'Jump to the previous occurence of this item in the document [←]';
            nextButton.title =
                'Jump to the next occurence of this item in the document [→]';
            prevButton.classList.add('icon_button');
            nextButton.classList.add('icon_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;
            navBar.appendChild(prevButton);
            navBar.appendChild(document.createTextNode(text));
            navBar.appendChild(nextButton);

            // attach click listeners to buttons
            prevButton.addEventListener('click', function() {
                onPrevNextClick(link, prevLink);
            });
            nextButton.addEventListener('click', function() {
                onPrevNextClick(link, nextLink);
            });

            return navBar;
        }

        // get previous link with same target
        function getPrevLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if < 1
            let index;
            if (sameLinks.index - 1 >= 0)
                index = sameLinks.index - 1;
            else
                index = sameLinks.total - 1;
            return sameLinks.elements[index];
        }

        // get next link with same target
        function getNextLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if > total
            let index;
            if (sameLinks.index + 1 <= sameLinks.total - 1)
                index = sameLinks.index + 1;
            else
                index = 0;
            return sameLinks.elements[index];
        }

        // get element that is target of link or url hash
        function getSource(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            // if ref or figure, modify target to get expected element
            if (id.indexOf('ref-') === 0)
                target = target.querySelector('p');
            else if (id.indexOf('fig:') === 0)
                target = target.querySelector('figure');

            return target;
        }

        // when prev/next arrow button is clicked
        function onPrevNextClick(link, prevNextLink) {
            if (link && prevNextLink)
                goToElement(prevNextLink, window.innerHeight * 0.5);
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // determine position to place tooltip based on link position in
        // viewport and tooltip size
        function positionTooltip(link, left, top) {
            const tooltipElement = document.getElementById('tooltip');
            if (!tooltipElement)
                return;

            // get convenient vars for position/dimensions of
            // link/tooltip/page/view
            link = getRectInPage(link);
            const tooltip = getRectInPage(tooltipElement);
            const view = getRectInPage();

            // horizontal positioning
            if (left)
                // use explicit value
                left = left;
            else if (link.left + tooltip.width < view.right)
                // fit tooltip to right of link
                left = link.left;
            else if (link.right - tooltip.width > view.left)
                // fit tooltip to left of link
                left = link.right - tooltip.width;
            // center tooltip in view
            else
                left = (view.right - view.left) / 2 - tooltip.width / 2;

            // vertical positioning
            if (top)
                // use explicit value
                top = top;
            else if (link.top - tooltip.height > view.top)
                // fit tooltip above link
                top = link.top - tooltip.height;
            else if (link.bottom + tooltip.height < view.bottom)
                // fit tooltip below link
                top = link.bottom;
            else {
                // center tooltip in view
                top = view.top + view.height / 2 - tooltip.height / 2;
                // nudge off of link to left/right if possible
                if (link.right + tooltip.width < view.right)
                    left = link.right;
                else if (link.left - tooltip.width > view.left)
                    left = link.left - tooltip.width;
            }

            tooltipElement.style.left = left + 'px';
            tooltipElement.style.top = top + 'px';
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get position of element relative to page
        function getRectInPage(element) {
            const rect = getRectInView(element);
            const body = getRectInView(document.body);

            const newRect = {};
            newRect.left = rect.left - body.left;
            newRect.top = rect.top - body.top;
            newRect.right = rect.right - body.left;
            newRect.bottom = rect.bottom - body.top;
            newRect.width = rect.width;
            newRect.height = rect.height;

            return newRect;
        }

        // (for interaction with accordion plugin)
        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // (for interaction with accordion plugin)
        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- jump to first plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds a button next to each reference entry,
        // figure, and table that jumps the page to the first occurrence of a
        // link to that item in the manuscript.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'jumpToFirst';

        // default plugin options
        const options = {
            // whether to add buttons next to reference entries
            references: 'true',
            // whether to add buttons next to figures
            figures: 'true',
            // whether to add buttons next to tables
            tables: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            if (options.references !== 'false')
                makeReferenceButtons();
            if (options.figures !== 'false')
                makeFigureButtons();
            if (options.tables !== 'false')
                makeTableButtons();
        }

        // when jump button clicked
        function onButtonClick() {
            const first = getFirstOccurrence(this.dataset.id);
            if (!first)
                return;

            // update url hash so navigating "back" in history will return
            // user to jump button
            window.location.hash = this.dataset.id;
            // scroll to link
            window.setTimeout(function() {
                goToElement(first, window.innerHeight * 0.5);
            }, 0);
        }

        // get first occurence of link to item in document
        function getFirstOccurrence(id) {
            let query = 'a';
            query += '[href="#' + id + '"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelector(query);
        }

        // add button next to each reference entry
        function makeReferenceButtons() {
            const references = document.querySelectorAll('div[id^="ref-"]');
            for (const reference of references) {
                // get reference id and element to add button to
                const id = reference.id;
                const container = reference.firstElementChild;
                const first = getFirstOccurrence(id);

                // if can't find link to reference, ignore
                if (!first)
                    continue;

                // make jump button
                let button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this reference in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.innerHTML = button.outerHTML + container.innerHTML;
                button = container.firstElementChild;
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeFigureButtons() {
            const figures = document.querySelectorAll('[id^="fig:"]');
            for (const figure of figures) {
                // get figure id and element to add button to
                const id = figure.id;
                const container = figure.querySelector('figcaption') || figure;
                const first = getFirstOccurrence(id);

                // if can't find link to figure, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this figure in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeTableButtons() {
            const tables = document.querySelectorAll('[id^="tbl:"]');
            for (const table of tables) {
                // get ref id and element to add button to
                const id = table.id;
                const container = table.querySelector('caption') || table;
                const first = getFirstOccurrence(id);

                // if can't find link to table, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this table in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
    <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
    <svg width="16" height="16" viewBox="0 0 320 512">
        <path
            fill="currentColor"
            d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
        ></path>
    </svg>
</template>
<!-- link highlight plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user hovers or
        // focuses a link, other links that have the same target will be
        // highlighted. It also makes it such that when clicking a link, the
        // target of the link (eg reference, figure, table) is briefly
        // highlighted.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'linkHighlight';

        // default plugin options
        const options = {
            // whether to also highlight links that go to external urls
            externalLinks: 'false',
            // whether user must click off to unhighlight instead of just
            // un-hovering
            clickUnhighlight: 'false',
            // whether to also highlight links that are unique
            highlightUnique: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach mouse and focus listeners to link
                link.addEventListener('mouseenter', onLinkFocus);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('mouseleave', onLinkUnhover);
            }

            // attach click and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('hashchange', onHashChange);

            // run hash change on window load in case user has navigated
            // directly to hash
            onHashChange();
        }

        // when link is focused (tabbed to) or hovered
        function onLinkFocus() {
            highlight(this);
        }

        // when link is unhovered
        function onLinkUnhover() {
            if (options.clickUnhighlight !== 'true')
                unhighlightAll();
        }

        // when the mouse is clicked anywhere in window
        function onClick(event) {
            unhighlightAll();
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                glowElement(target);
        }

        // get element that is target of link or url hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector('[id="' + id + '"]');
            if (!target)
                return;

            return target;
        }

        // start glow sequence on an element
        function glowElement(element) {
            const startGlow = function() {
                onGlowEnd();
                element.dataset.glow = 'true';
                element.addEventListener('animationend', onGlowEnd);
            };
            const onGlowEnd = function() {
                element.removeAttribute('data-glow');
                element.removeEventListener('animationend', onGlowEnd);
            };
            startGlow();
        }

        // highlight link and all others with same target
        function highlight(link) {
            // force unhighlight all to start fresh
            unhighlightAll();

            // get links with same target
            if (!link)
                return;
            const sameLinks = getSameLinks(link);

            // if link unique and option is off, exit and don't highlight
            if (sameLinks.length <= 1 && options.highlightUnique !== 'true')
                return;

            // highlight all same links, and "select" (special highlight) this
            // one
            for (const sameLink of sameLinks) {
                if (sameLink === link)
                    sameLink.setAttribute('data-selected', 'true');
                else
                    sameLink.setAttribute('data-highlighted', 'true');
            }
        }

        // unhighlight all links
        function unhighlightAll() {
            const links = getLinks();
            for (const link of links) {
                link.setAttribute('data-selected', 'false');
                link.setAttribute('data-highlighted', 'false');
            }
        }

        // get links with same target
        function getSameLinks(link) {
            const results = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    results.push(otherLink);
            }
            return results;
        }

        // get all links of types we wish to handle
        function getLinks() {
            let query = 'a';
            if (options.externalLinks !== 'true')
                query += '[href^="#"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelectorAll(query);
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin provides a "table of contents" (toc) panel on
        // the side of the document that allows the user to conveniently
        // navigate between sections of the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tableOfContents';

        // default plugin options
        const options = {
            // which types of elements to add links for, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3',
            // whether toc starts open. use 'true' or 'false', or 'auto' to
            // use 'true' behavior when screen wide enough and 'false' when not
            startOpen: 'false',
            // whether toc closes when clicking on toc link. use 'true' or
            // 'false', or 'auto' to use 'false' behavior when screen wide
            // enough and 'true' when not
            clickClose: 'auto',
            // if list item is more than this many characters, text will be
            // truncated
            charLimit: '50',
            // whether or not to show bullets next to each toc item
            bullets: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // make toc panel and populate with entries (links to document
            // sections)
            const panel = makePanel();
            if (!panel)
                return;
            makeEntries(panel);
            // attach panel to document after making entries, so 'toc' heading
            // in panel isn't included in toc
            document.body.insertBefore(panel, document.body.firstChild);

            // initial panel state
            if (
                options.startOpen === 'true' ||
                (options.startOpen === 'auto' && !isSmallScreen())
            )
                openPanel();
            else
                closePanel();

            // attach click, scroll, and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('scroll', onScroll);
            window.addEventListener('hashchange', onScroll);
            window.addEventListener('keyup', onKeyUp);
            onScroll();

            // add class to push document body down out of way of toc button
            document.body.classList.add('toc_body_nudge');
        }

        // determine if screen wide enough to fit toc panel
        function isSmallScreen() {
            // in default theme:
            // 816px = 8.5in = width of "page" (<body>) element
            // 260px = min width of toc panel (*2 for both sides of <body>)
            return window.innerWidth < 816 + 260 * 2;
        }

        // when mouse is clicked anywhere in window
        function onClick() {
            if (isSmallScreen())
                closePanel();
        }

        // when window is scrolled or hash changed
        function onScroll() {
            highlightViewed();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            // close on esc
            if (event.key === 'Escape')
                closePanel();
        }

        // find entry of currently viewed document section in toc and highlight
        function highlightViewed() {
            const firstId = getFirstInView(options.typesQuery);

            // get toc entries (links), unhighlight all, then highlight viewed
            const list = document.getElementById('toc_list');
            if (!firstId || !list)
                return;
            const links = list.querySelectorAll('a');
            for (const link of links)
                link.dataset.viewing = 'false';
            const link = list.querySelector('a[href="#' + firstId + '"]');
            if (!link)
                return;
            link.dataset.viewing = 'true';
        }

        // get first or previous toc listed element in top half of view
        function getFirstInView(query) {
            // get all elements matching query and with id
            const elements = document.querySelectorAll(query);
            const elementsWithIds = [];
            for (const element of elements) {
                if (element.id)
                    elementsWithIds.push(element);
            }


            // get first or previous element in top half of view
            for (let i = 0; i < elementsWithIds.length; i++) {
                const element = elementsWithIds[i];
                const prevElement = elementsWithIds[Math.max(0, i - 1)];
                if (element.getBoundingClientRect().top >= 0) {
                    if (
                        element.getBoundingClientRect().top <
                        window.innerHeight / 2
                    )
                        return element.id;
                    else
                        return prevElement.id;
                }
            }
        }

        // make panel
        function makePanel() {
            // create panel
            const panel = document.createElement('div');
            panel.id = 'toc_panel';
            if (options.bullets === 'true')
                panel.dataset.bullets = 'true';

            // create header
            const header = document.createElement('div');
            header.id = 'toc_header';

            // create toc button
            const button = document.createElement('button');
            button.id = 'toc_button';
            button.innerHTML = document.querySelector('.icon_th_list').innerHTML;
            button.title = 'Table of Contents';
            button.classList.add('icon_button');

            // create header text
            const text = document.createElement('h4');
            text.innerHTML = 'Table of Contents';

            // create container for toc list
            const list = document.createElement('div');
            list.id = 'toc_list';

            // attach click listeners
            panel.addEventListener('click', onPanelClick);
            header.addEventListener('click', onHeaderClick);
            button.addEventListener('click', onButtonClick);

            // attach elements
            header.appendChild(button);
            header.appendChild(text);
            panel.appendChild(header);
            panel.appendChild(list);

            return panel;
        }

        // create toc entries (links) to each element of the specified types
        function makeEntries(panel) {
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements) {
                // do not add link if element doesn't have assigned id
                if (!element.id)
                    continue;

                // create link/list item
                const link = document.createElement('a');
                link.classList.add('toc_link');
                switch (element.tagName.toLowerCase()) {
                    case 'h1':
                        link.dataset.level = '1';
                        break;
                    case 'h2':
                        link.dataset.level = '2';
                        break;
                    case 'h3':
                        link.dataset.level = '3';
                        break;
                    case 'h4':
                        link.dataset.level = '4';
                        break;
                }
                link.title = element.innerText;
                let text = element.innerText;
                if (text.length > options.charLimit)
                    text = text.slice(0, options.charLimit) + '...';
                link.innerHTML = text;
                link.href = '#' + element.id;
                link.addEventListener('click', onLinkClick);

                // attach link
                panel.querySelector('#toc_list').appendChild(link);
            }
        }

        // when panel is clicked
        function onPanelClick(event) {
            // stop click from propagating to window/document and closing panel
            event.stopPropagation();
        }

        // when header itself is clicked
        function onHeaderClick(event) {
            togglePanel();
        }

        // when button is clicked
        function onButtonClick(event) {
            togglePanel();
            // stop header underneath button from also being clicked
            event.stopPropagation();
        }

        // when link is clicked
        function onLinkClick(event) {
            if (
                options.clickClose === 'true' ||
                (options.clickClose === 'auto' && isSmallScreen())
            )
                closePanel();
            else
                openPanel();
        }

        // open panel if closed, close if opened
        function togglePanel() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                closePanel();
            else
                openPanel();
        }

        // open panel
        function openPanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'true';
        }

        // close panel
        function closePanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'false';
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- th list icon -->

<template class="icon_th_list">
    <!-- modified from: https://fontawesome.com/icons/th-list -->
    <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
        <path
            fill="currentColor"
            d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- lightbox plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user clicks on an
        // image, the image fills the screen and the user can pan/drag/zoom
        // the image and navigate between other images in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'lightbox';

        // default plugin options
        const options = {
            // list of possible zoom/scale factors
            zoomSteps:
                '0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1,' +
                '1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8',
            // whether to fit image to view ('fit'), display at 100% and shrink
            // if necessary ('shrink'), or always display at 100% ('100')
            defaultZoom: 'fit',
            // whether to zoom in/out toward center of view ('true') or mouse
            // ('false')
            centerZoom: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <img> element
            const imgs = document.querySelectorAll('figure > img');
            let count = 1;
            for (const img of imgs) {
                img.classList.add('lightbox_document_img');
                img.dataset.number = count;
                img.dataset.total = imgs.length;
                img.addEventListener('click', openLightbox);
                count++;
            }

            // attach mouse and key listeners to window
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('keyup', onKeyUp);
        }

        // when mouse is moved anywhere in window
        function onWindowMouseMove(event) {
            window.mouseX = event.clientX;
            window.mouseY = event.clientY;
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'lightbox_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'lightbox_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeLightbox();
                    break;
            }
        }

        // open lightbox
        function openLightbox() {
            const lightbox = makeLightbox(this);
            if (!lightbox)
                return;

            blurBody(lightbox);
            document.body.appendChild(lightbox);
        }

        // make lightbox
        function makeLightbox(img) {
            // delete lightbox if it exists, start fresh
            closeLightbox();

            // create screen overlay containing lightbox
            const overlay = document.createElement('div');
            overlay.id = 'lightbox_overlay';

            // create image info boxes
            const numberInfo = document.createElement('div');
            const zoomInfo = document.createElement('div');
            numberInfo.id = 'lightbox_number_info';
            zoomInfo.id = 'lightbox_zoom_info';

            // create container for image
            const imageContainer = document.createElement('div');
            imageContainer.id = 'lightbox_image_container';
            const lightboxImg = makeLightboxImg(
                img,
                imageContainer,
                numberInfo,
                zoomInfo
            );
            imageContainer.appendChild(lightboxImg);

            // create bottom container for caption and navigation buttons
            const bottomContainer = document.createElement('div');
            bottomContainer.id = 'lightbox_bottom_container';
            const caption = makeCaption(img);
            const prevButton = makePrevButton(img);
            const nextButton = makeNextButton(img);
            bottomContainer.appendChild(prevButton);
            bottomContainer.appendChild(caption);
            bottomContainer.appendChild(nextButton);

            // attach top middle and bottom to overlay
            overlay.appendChild(numberInfo);
            overlay.appendChild(zoomInfo);
            overlay.appendChild(imageContainer);
            overlay.appendChild(bottomContainer);

            return overlay;
        }

        // make <img> object that is intuitively draggable and zoomable
        function makeLightboxImg(
            sourceImg,
            container,
            numberInfoBox,
            zoomInfoBox
        ) {
            // create copy of source <img>
            const img = sourceImg.cloneNode(true);
            img.classList.remove('lightbox_document_img');
            img.removeAttribute('id');
            img.removeAttribute('width');
            img.removeAttribute('height');
            img.style.position = 'unset';
            img.style.margin = '0';
            img.style.padding = '0';
            img.style.width = '';
            img.style.height = '';
            img.style.minWidth = '';
            img.style.minHeight = '';
            img.style.maxWidth = '';
            img.style.maxHeight = '';
            img.id = 'lightbox_img';

            // build sorted list of unique zoomSteps, always including a 100%
            let zoomSteps = [];
            const optionsZooms = options.zoomSteps.split(/[^0-9.]/);
            for (const optionZoom of optionsZooms) {
                const newZoom = parseFloat(optionZoom);
                if (newZoom && !zoomSteps.includes(newZoom))
                    zoomSteps.push(newZoom);
            }
            if (!zoomSteps.includes(1))
                zoomSteps.push(1);
            zoomSteps = zoomSteps.sort(function sortNumber(a, b) {
                return a - b;
            });

            // <img> object property variables
            let zoom = 1;
            let translateX = 0;
            let translateY = 0;
            let clickMouseX = undefined;
            let clickMouseY = undefined;
            let clickTranslateX = undefined;
            let clickTranslateY = undefined;

            updateNumberInfo();

            // update image numbers displayed in info box
            function updateNumberInfo() {
                numberInfoBox.innerHTML =
                    sourceImg.dataset.number + ' of ' + sourceImg.dataset.total;
            }

            // update zoom displayed in info box
            function updateZoomInfo() {
                let zoomInfo = zoom * 100;
                if (!Number.isInteger(zoomInfo))
                    zoomInfo = zoomInfo.toFixed(2);
                zoomInfoBox.innerHTML = zoomInfo + '%';
            }

            // move to closest zoom step above current zoom
            const zoomIn = function() {
                for (const zoomStep of zoomSteps) {
                    if (zoomStep > zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                updateTransform();
            };

            // move to closest zoom step above current zoom
            const zoomOut = function() {
                zoomSteps.reverse();
                for (const zoomStep of zoomSteps) {
                    if (zoomStep < zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                zoomSteps.reverse();

                updateTransform();
            };

            // update display of <img> based on scale/translate properties
            const updateTransform = function() {
                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                // get new width/height after scale
                const rect = img.getBoundingClientRect();
                // limit translate
                translateX = Math.max(translateX, -rect.width / 2);
                translateX = Math.min(translateX, rect.width / 2);
                translateY = Math.max(translateY, -rect.height / 2);
                translateY = Math.min(translateY, rect.height / 2);

                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                updateZoomInfo();
            };

            // fit <img> to container
            const fit = function() {
                // no x/y offset, 100% zoom by default
                translateX = 0;
                translateY = 0;
                zoom = 1;

                // widths of <img> and container
                const imgWidth = img.naturalWidth;
                const imgHeight = img.naturalHeight;
                const containerWidth = parseFloat(
                    window.getComputedStyle(container).width
                );
                const containerHeight = parseFloat(
                    window.getComputedStyle(container).height
                );

                // how much zooming is needed to fit <img> to container
                const xRatio = imgWidth / containerWidth;
                const yRatio = imgHeight / containerHeight;
                const maxRatio = Math.max(xRatio, yRatio);
                const newZoom = 1 / maxRatio;

                // fit <img> to container according to option
                if (options.defaultZoom === 'shrink') {
                    if (maxRatio > 1)
                        zoom = newZoom;
                } else if (options.defaultZoom === 'fit')
                    zoom = newZoom;

                updateTransform();
            };

            // when mouse wheel is rolled anywhere in container
            const onContainerWheel = function(event) {
                if (!event)
                    return;

                // let ctrl + mouse wheel to zoom behave as normal
                if (event.ctrlKey)
                    return;

                // prevent normal scroll behavior
                event.preventDefault();
                event.stopPropagation();

                // point around which to scale img
                const viewRect = container.getBoundingClientRect();
                const viewX = (viewRect.left + viewRect.right) / 2;
                const viewY = (viewRect.top + viewRect.bottom) / 2;
                const originX = options.centerZoom === 'true' ? viewX : mouseX;
                const originY = options.centerZoom === 'true' ? viewY : mouseY;

                // get point on image under origin
                const oldRect = img.getBoundingClientRect();
                const oldPercentX = (originX - oldRect.left) / oldRect.width;
                const oldPercentY = (originY - oldRect.top) / oldRect.height;

                // increment/decrement zoom
                if (event.deltaY < 0)
                    zoomIn();
                if (event.deltaY > 0)
                    zoomOut();

                // get offset between previous image point and origin
                const newRect = img.getBoundingClientRect();
                const offsetX =
                    originX - (newRect.left + newRect.width * oldPercentX);
                const offsetY =
                    originY - (newRect.top + newRect.height * oldPercentY);

                // translate image to keep image point under origin
                translateX += offsetX;
                translateY += offsetY;

                // perform translate
                updateTransform();
            };

            // when container is clicked
            function onContainerClick(event) {
                // if container itself is target of click, and not other
                // element above it
                if (event.target === this)
                    closeLightbox();
            }

            // when mouse button is pressed on image
            const onImageMouseDown = function(event) {
                // store original mouse position relative to image
                clickMouseX = window.mouseX;
                clickMouseY = window.mouseY;
                clickTranslateX = translateX;
                clickTranslateY = translateY;
                event.stopPropagation();
                event.preventDefault();
            };

            // when mouse button is released anywhere in window
            const onWindowMouseUp = function(event) {
                // reset original mouse position
                clickMouseX = undefined;
                clickMouseY = undefined;
                clickTranslateX = undefined;
                clickTranslateY = undefined;

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mouseup', onWindowMouseUp);
            };

            // when mouse is moved anywhere in window
            const onWindowMouseMove = function(event) {
                if (
                    clickMouseX === undefined ||
                    clickMouseY === undefined ||
                    clickTranslateX === undefined ||
                    clickTranslateY === undefined
                )
                    return;

                // offset image based on original and current mouse position
                translateX = clickTranslateX + window.mouseX - clickMouseX;
                translateY = clickTranslateY + window.mouseY - clickMouseY;
                updateTransform();
                event.preventDefault();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mousemove', onWindowMouseMove);
            };

            // when window is resized
            const onWindowResize = function(event) {
                fit();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('resize', onWindowResize);
            };

            // attach the necessary event listeners
            img.addEventListener('dblclick', fit);
            img.addEventListener('mousedown', onImageMouseDown);
            container.addEventListener('wheel', onContainerWheel);
            container.addEventListener('mousedown', onContainerClick);
            container.addEventListener('touchstart', onContainerClick);
            window.addEventListener('mouseup', onWindowMouseUp);
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('resize', onWindowResize);

            // run fit() after lightbox atttached to document and <img> Loaded
            // so needed container and img dimensions available
            img.addEventListener('load', fit);

            return img;
        }

        // make caption
        function makeCaption(img) {
            const caption = document.createElement('div');
            caption.id = 'lightbox_caption';
            const captionSource = img.nextElementSibling;
            if (captionSource.tagName.toLowerCase() === 'figcaption') {
                const captionCopy = makeCopy(captionSource);
                caption.innerHTML = captionCopy.innerHTML;
            }

            caption.addEventListener('touchstart', function(event) {
                event.stopPropagation();
            });

            return caption;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // make button to jump to previous image in document
        function makePrevButton(img) {
            const prevButton = document.createElement('button');
            prevButton.id = 'lightbox_prev_button';
            prevButton.title = 'Jump to the previous image in the document [←]';
            prevButton.classList.add('icon_button', 'lightbox_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;

            // attach click listeners to button
            prevButton.addEventListener('click', function() {
                getPrevImg(img).click();
            });

            return prevButton;
        }

        // make button to jump to next image in document
        function makeNextButton(img) {
            const nextButton = document.createElement('button');
            nextButton.id = 'lightbox_next_button';
            nextButton.title = 'Jump to the next image in the document [→]';
            nextButton.classList.add('icon_button', 'lightbox_button');
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;

            // attach click listeners to button
            nextButton.addEventListener('click', function() {
                getNextImg(img).click();
            });

            return nextButton;
        }

        // get previous image in document
        function getPrevImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if < 1
            if (index - 1 >= 0)
                index--;
            else
                index = imgs.length - 1;
            return imgs[index];
        }

        // get next image in document
        function getNextImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if > total
            if (index + 1 <= imgs.length - 1)
                index++;
            else
                index = 0;
            return imgs[index];
        }

        // close lightbox
        function closeLightbox() {
            focusBody();

            const lightbox = document.getElementById('lightbox_overlay');
            if (lightbox)
                lightbox.remove();
        }

        // make all elements behind lightbox non-focusable
        function blurBody(overlay) {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.tabIndex = -1;
            document.body.classList.add('body_no_scroll');
        }

        // make all elements focusable again
        function focusBody() {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.removeAttribute('tabIndex');
            document.body.classList.remove('body_no_scroll');
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- attributes plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows arbitrary HTML attributes to be attached
        // to (almost) any element. Place an HTML comment inside or next to the
        // desired element in the format <!-- $attribute="value" -->

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'attributes';

        // default plugin options
        const options = {
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // get list of comments in document
            const comments = findComments();

            for(const comment of comments)
                if (comment.parentElement)
                    addAttributes(
                        comment.parentElement,
                        comment.nodeValue.trim()
                    );
        }

        // add html attributes to specified element based on string of 
        // html attributes and values
        function addAttributes(element, text) {
            // regex's for finding attribute/value pairs in the format of
            // attribute="value" or attribute='value
            const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
            const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

            // loop through attribute/value pairs
            let match;
            while(match = text.match(regex2) || text.match(regex1)) {
                // get attribute and value from regex capture groups
                let attribute = match[1];
                let value = match[2];

                // remove from string
                text = text.substring(match.index + match[0].length);

                if (!attribute || !value)
                    break;

                // set attribute of parent element
                try {
                    element.setAttribute(attribute, value);
                } catch(error) {
                    console.log(error);
                }

                // special case for colspan
                if (attribute === 'colspan')
                    removeTableCells(element, value);
            }
        }

        // get list of comment elements in document
        function findComments() {
            const comments = [];

            // iterate over comment nodes in document
            function acceptNode(node) {
                return NodeFilter.FILTER_ACCEPT;
            }
            const iterator = document.createNodeIterator(
                document.body,
                NodeFilter.SHOW_COMMENT,
                acceptNode
            );
            let node;
            while(node = iterator.nextNode())
                comments.push(node);

            return comments;
        }

        // remove certain number of cells after specified cell
        function removeTableCells(cell, number) {
            number = parseInt(number);
            if (!number)
                return;

            // remove elements
            for(; number > 1; number--) {
                if (cell.nextElementSibling)
                    cell.nextElementSibling.remove();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- mathjax plugin configuration -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "CommonHTML": { linebreaks: { automatic: true } },
        "HTML-CSS": { linebreaks: { automatic: true } },
        "SVG": { linebreaks: { automatic: true } },
        "fast-preview": { disabled: true }
  });
</script>

<!-- mathjax plugin -->

<script
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
    integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
    crossorigin="anonymous"
>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'MathJax' allows the proper rendering of
    // math/equations written in LaTeX.

    // https://www.mathjax.org/
</script>
<!-- annotations plugin -->

<script>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'Hypothesis' allows public annotation of the
    // manuscript.

    // https://web.hypothes.is/

    // plugin configuration
    window.hypothesisConfig = function() {
        return {
            branding: {
                accentColor: '#2196f3',
                appBackgroundColor: '#f8f8f8',
                ctaBackgroundColor: '#f8f8f8',
                ctaTextColor: '#000000',
                selectionFontFamily: 'Open Sans, Helvetica, sans serif',
                annotationFontFamily: 'Open Sans, Helvetica, sans serif'
            }
        };
    };

    // hypothesis client script
    const embed = 'https://hypothes.is/embed.js';
    // hypothesis annotation count query url
    const query = 'https://api.hypothes.is/api/search?limit=0&url='

    
    // start script
    function start() {
        const button = makeButton();
        document.body.insertBefore(button, document.body.firstChild);
        insertCount(button);
    }

    // make button
    function makeButton() {
        // create button
        const button = document.createElement('button');
        button.id = 'hypothesis_button';
        button.innerHTML = document.querySelector('.icon_hypothesis').innerHTML;
        button.title = 'Hypothesis annotations';
        button.classList.add('icon_button');

        function onClick(event) {
            onButtonClick(event, button);
        }

        // attach click listeners
        button.addEventListener('click', onClick);

        return button;
    }

    // insert annotations count
    async function insertCount(button) {
        // get annotation count from Hypothesis based on url
        let count = '-';
        try {
            const canonical = document.querySelector('link[rel="canonical"]');
            const location = window.location;
            const url = encodeURIComponent((canonical || location).href);
            const response = await fetch(query + url);
            const json = await response.json();
            count = json.total || '-';
        } catch(error) {
            console.log(error);
        }
        
        // put count into button
        const counter = document.createElement('span');
        counter.id = 'hypothesis_count';
        counter.innerHTML = count;
        button.title = 'View ' + count + ' Hypothesis annotations';
        button.append(counter);
    }

    // when button is clicked
    function onButtonClick(event, button) {
        const script = document.createElement('script');
        script.src = embed;
        document.body.append(script);
        button.remove();
    }

    window.addEventListener('load', start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
    <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
    <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
        <path
            fill="currentColor"
            d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- analytics plugin -->

<!-- copy and paste code from Google Analytics or similar service here -->
</body>
</html>
