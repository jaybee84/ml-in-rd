---
author-meta:
- Jineta Banerjee
- Robert J Allaway
- Jaclyn N Taroni
- Casey Greene
- Justin Guinney
bibliography:
- content/manual-references.json
date-meta: '2021-01-29'
header-includes: "<!--\nManubot generated metadata rendered from header-includes-template.html.\nSuggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html\n-->\n<meta name=\"dc.format\" content=\"text/html\" />\n<meta name=\"dc.title\" content=\"Machine learning methods for rare diseases\" />\n<meta name=\"citation_title\" content=\"Machine learning methods for rare diseases\" />\n<meta property=\"og:title\" content=\"Machine learning methods for rare diseases\" />\n<meta property=\"twitter:title\" content=\"Machine learning methods for rare diseases\" />\n<meta name=\"dc.date\" content=\"2021-01-29\" />\n<meta name=\"citation_publication_date\" content=\"2021-01-29\" />\n<meta name=\"dc.language\" content=\"en-US\" />\n<meta name=\"citation_language\" content=\"en-US\" />\n<meta name=\"dc.relation.ispartof\" content=\"Manubot\" />\n<meta name=\"dc.publisher\" content=\"Manubot\" />\n<meta name=\"citation_journal_title\" content=\"Manubot\" />\n<meta name=\"citation_technical_report_institution\" content=\"Manubot\" />\n<meta name=\"citation_author\" content=\"Jineta Banerjee\" />\n<meta name=\"citation_author_institution\" content=\"Sage Bionetworks\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0002-1775-3645\" />\n<meta name=\"citation_author\" content=\"Robert J Allaway\" />\n<meta name=\"citation_author_institution\" content=\"Sage Bionetworks\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0003-3573-3565\" />\n<meta name=\"twitter:creator\" content=\"@allawayr\" />\n<meta name=\"citation_author\" content=\"Jaclyn N Taroni\" />\n<meta name=\"citation_author_institution\" content=\"Childhood Cancer Data Lab, Alex\u2019s Lemonade Stand Foundation\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0003-4734-4508\" />\n<meta name=\"citation_author\" content=\"Casey Greene\" />\n<meta name=\"citation_author_institution\" content=\"Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania\" />\n<meta name=\"citation_author_institution\" content=\"Childhood Cancer Data Lab, Alex\u2019s Lemonade Stand Foundation\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0001-8713-9213\" />\n<meta name=\"citation_author\" content=\"Justin Guinney\" />\n<meta name=\"citation_author_institution\" content=\"Sage Bionetworks\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0003-1477-1888\" />\n<link rel=\"canonical\" href=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta property=\"og:url\" content=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta property=\"twitter:url\" content=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta name=\"citation_fulltext_html_url\" content=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta name=\"citation_pdf_url\" content=\"https://jaybee84.github.io/ml-in-rd/manuscript.pdf\" />\n<link rel=\"alternate\" type=\"application/pdf\" href=\"https://jaybee84.github.io/ml-in-rd/manuscript.pdf\" />\n<link rel=\"alternate\" type=\"text/html\" href=\"https://jaybee84.github.io/ml-in-rd/v/fccb1082662c74be27992f105b285bda47a527f8/\" />\n<meta name=\"manubot_html_url_versioned\" content=\"https://jaybee84.github.io/ml-in-rd/v/fccb1082662c74be27992f105b285bda47a527f8/\" />\n<meta name=\"manubot_pdf_url_versioned\" content=\"https://jaybee84.github.io/ml-in-rd/v/fccb1082662c74be27992f105b285bda47a527f8/manuscript.pdf\" />\n<meta property=\"og:type\" content=\"article\" />\n<meta property=\"twitter:card\" content=\"summary_large_image\" />\n<link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"https://manubot.org/favicon-192x192.png\" />\n<link rel=\"mask-icon\" href=\"https://manubot.org/safari-pinned-tab.svg\" color=\"#ad1457\" />\n<meta name=\"theme-color\" content=\"#ad1457\" />\n<!-- end Manubot generated metadata -->"
keywords:
- rare disease
- machine learning
- transfer learning
lang: en-US
manubot-clear-requests-cache: false
manubot-output-bibliography: output/references.json
manubot-output-citekeys: output/citations.tsv
manubot-requests-cache-path: ci/cache/requests-cache
title: Machine learning methods for rare diseases
...






<small><em>
This manuscript
([permalink](https://jaybee84.github.io/ml-in-rd/v/fccb1082662c74be27992f105b285bda47a527f8/))
was automatically generated
from [jaybee84/ml-in-rd@fccb108](https://github.com/jaybee84/ml-in-rd/tree/fccb1082662c74be27992f105b285bda47a527f8)
on January 29, 2021.
</em></small>

## Authors



+ **Jineta Banerjee**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0002-1775-3645](https://orcid.org/0000-0002-1775-3645)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [jaybee84](https://github.com/jaybee84)<br>
  <small>
     Sage Bionetworks
     · Funded by Neurofibromatosis Therapeutic Acceleration Program; Children's Tumor Foundation
  </small>

+ **Robert J Allaway**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-3573-3565](https://orcid.org/0000-0003-3573-3565)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [allaway](https://github.com/allaway)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [allawayr](https://twitter.com/allawayr)<br>
  <small>
     Sage Bionetworks
     · Funded by Neurofibromatosis Therapeutic Acceleration Program; Children's Tumor Foundation
  </small>

+ **Jaclyn N Taroni**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-4734-4508](https://orcid.org/0000-0003-4734-4508)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [jaclyn-taroni](https://github.com/jaclyn-taroni)<br>
  <small>
     Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation
  </small>

+ **Casey Greene**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0001-8713-9213](https://orcid.org/0000-0001-8713-9213)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [cgreene](https://github.com/cgreene)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania; Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation
  </small>

+ **Justin Guinney**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-1477-1888](https://orcid.org/0000-0003-1477-1888)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [jguinney](https://github.com/jguinney)<br>
  <small>
     Sage Bionetworks
     · Funded by Neurofibromatosis Therapeutic Acceleration Program; Children's Tumor Foundation
  </small>



## Synopsis {.page_break_before}

(Instructions: Describe the background, basic structure of the article, list material to be covered indicating depth of coverage, how they are logically arranged, include recent pubs in the area, 300-500 words)

Substantial technological advances have dramatically changed biomedicine by making deep characterization of patient samples routine and accelerating basic research.
These technologies provide a rich portrait of genes, cellular pathways, and cell types involved in complex phenotypes.
Machine learning is often a perfect fit to extract disease-relevant patterns from these high dimensional datasets.
Often, these methods require many samples to identify reproducible and biologically meaningful patterns.
With rare diseases, biological specimens and consequently data, are limited due to the rarity of the condition.
In this perspective, we outline the challenges and emerging solutions for using machine learning in rare disease settings.
We aim to spur the development of powerful machine learning techniques for rare diseases.
We also note that precision medicine presents a similar challenge, in which a common disease is partitioned into small subsets of patients with shared etiologies and treatment strategies.
Advances from rare disease research are likely to be highly informative for other applications as well.


## Introduction {.page_break_before}

Rare disease research is increasingly dependent on high-throughput profiling of samples and would greatly benefit from applications of machine learning (ML) in their analysis. 
Analyzing such high dimensional data from rare diseases (fewer than 200,000 cases in the United States [@https://www.fda.gov/media/99546/download]) is challenging, as datasets typically range from 20 to 99 samples [@doi:10.1186/s13023-020-01424-6].
Specialized computational methods that can learn patterns from small datasets that can be generalized to newly acquired data are required [@doi:10.1016/j.ebiom.2019.08.027]. 
Lack of statistical power and the susceptibility of ML methods to misinterpretation and unstable performance pose challenges when datasets are small.
Heterogeneity in available data creates additional difficulties. 
For example, successful training of ML models require training datasets made of “gold standard” data where the diagnosis or label of a data point has very little uncertainty (or “label-noise”) associated with it [@doi:10.1093/jamia/ocw028]. 
Due to the limited understanding of the biology of rare diseases, the symptoms or disease labels often come with a reasonable amount label-noise leading to a silver standard dataset [@doi:10.1109/tnnls.2013.2292894]. 
A systematic review of application of ML in rare disease in the last 10 years uncovered 211 human data studies in 74 different rare diseases employing ensemble methods (36.0%), support vector machines (32.2%) and artificial neural networks (31.8%) [@doi:10.1186/s13023-020-01424-6]. 
The review also showed that most studies used ML for diagnosis (40.8%) or prognosis (38.4%), but studies aiming to improve treatment were infrequent (4.7%) [@doi:10.1186/s13023-020-01424-6]. 
Moreover, in the context of rare disease, special considerations need to be made to safeguard against misinterpretation of results. 
Rare disease datasets are often limited in size and/or assembled from combining data from multiple institutions  from differently processed specimens collected with geographical and chronological disparity. 
Consequently, data analysis techniques must be robust to challenges posed by small sample sizes, as well as technical artifacts present in aggregated data. In this perspective, we discuss techniques for understanding the nature of rare disease data, including those that address or better tolerate the limitations of these data.


### Manage complex high-dimensional rare disease data

In rare diseases, the ability to get an enormous number of measurements from a vanishingly small number of samples using high-throughput methods is both the upside and the downfall of these methods. 
These ‘omic’ methods generate highly dimensional data - that is, data with many features (e.g., all of the mRNA transcripts in a sample). 
Perhaps counterintuitively, more feature-rich data can make a prediction problem more challenging. 
This is because statistical interrogation of a large number of measurements requires an abundance of samples or observations, which is often not the case in rare disease. 
This lack of samples gives rise to the “curse of dimensionality” (i.e., few samples but many features), which can be a major impediment in analyzing feature-rich data in sample-deficient contexts such as rare disease [@doi:10.1038/nrc2294] 
In particular, increased numbers of features results in increased sparsity (missing observations), more dissimilarity between samples, and increased redundancy between individual features or combinations of features [@doi:10.1038/s41592-018-0019-x]; the consequence of this additional data is a more challenging prediction problem, rather than an easier one. 
Furthermore, rare disease data collection and aggregation methods can add to these challenges by introducing technical variability into the data at hand.
In this section, we will discuss strategies like simplifying data and addressing technical artifacts through dimension reduction  which can help mitigate these challenges. 
Dimensionality reduction methods including unsupervised approaches like multidimensional scaling (MDS), principal components analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE), and uniform manifold approximation and projection (UMAP) [@doi:10.1007/978-3-540-33037-0; @doi:10.1098/rsta.2015.0202, @https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf; @https://arxiv.org/abs/1802.03426] can help ‘compress’ information from a large number of features into a smaller number of features. 
These techniques can be applied to characterize imaging data [@doi:10.1016/j.media.2020.101660], mass cytometry data [@doi:10.1038/ncomms14825], ‘omics data, and others. 
These methods not only help in reducing the number of features, but can also be used to visualize structure or artifacts in the data (e.g. [@doi:10.1038/s41467-019-13056-x]), define subgroups within data (e.g. [@doi:10.1038/s41467-020-15351-4], or for feature selection/extraction during application of specific machine learning models.[@doi:10.1007/978-3-030-03243-2_299-1] (Figure {@fig:1})

Rare disease datasets, like many other scenarios, can contain structure unrelated to the biology of the disease; e.g. structure related to batch, sample preparation methodology, or sequencing platform [@doi:10.23915/distill.00002]. 
The consequences of these artifacts are amplified when samples are rare and the cohort contains several phenotypes. Furthermore, datasets are often combined from multiple small studies where biological characteristics are confounded by technical variables. 
We can leverage dimensionality reduction methods like PCA, MDS, t-SNE, and UMAP to identify the effect of these variables on the data. All of these methods can be used to identify batch effects and other structures in the data, though some like t-SNE and UMAP may require tuning of hyperparameters that affect the output.[@https://arxiv.org/abs/1802.03426; @doi:10.23915/distill.00002] 
Way, et. al. [@doi:10.1186/s13059-020-02021-3] further suggests that a single dimensionality reduction method alone may not be sufficient to reveal all of the technical or biological heterogeneity; thus testing multiple methods may result in a more comprehensive portrait of the data. 
Additional important considerations for using dimensionality reduction methods such as criteria for selecting a dimensionality reduction method and interpretation of results are discussed in detail by Nguyen and Holmes.[@doi:10.1371/journal.pcbi.1006907] 

Beyond dimensionality reduction, unsupervised learning approaches such as k-means clustering or hierarchical clustering have also been used to characterize the structure present in genomic or imaging data. [@doi:10.1186/1471-2105-9-497; @doi:10.1109/jbhi.2013.2276766] 
If non-biological heterogeneity is detectable, common approaches like  reprocessing the raw data using a single analysis pipeline (if the data are obtained from different sources), application of batch correction methods [@doi:10.1093/biostatistics/kxj037; @doi:10.1093/nar/gku864], and normalization of raw values[@doi:10.1186/gb-2010-11-3-r25] may be required to obtain value from these datasets. 

Dimensionality reduction is, in fact, a type of representation learning (or feature learning), a process of learning low-dimensional representations or composites of features from raw data. 
Each learned composite feature becomes a new variable - representing a combination of original features - thereby reducing the dimension of the dataset. 
Representation learning through matrix factorization can extract composite features from transcriptomics datasets made of combinations of gene expression levels found in the training data that are descriptive in some way [@doi:10.1038/s41467-020-14666-6], and use them to interpret test input data.[@doi:10.1093/bioinformatics/btq503; @doi:10.1186/s13059-020-02021-3] 
Putting constraints on the features learned by the model, through regularization, can help ensure that the learned representations are generalizable and avoid overfitting of the resulting model [@doi:10.1371/journal.pgen.1004754, @doi:10.1002/sim.6782]. 
Low-dimensional representations trained on a collection of transcriptomic data can also be used as input to supervised machine learning methods.[@doi:10.1186/s12859-020-3427-8; @doi:10.1016/j.procs.2016.07.014; @doi:10.1098/rsif.2017.0387]

Representation learning generally requires many samples in complex biological systems and thus may appear to aggravate the curse of dimensionality. 
But it can be a powerful tool to learn low-dimensional patterns from large datasets and then find those patterns in smaller, related datasets. 
In the later sections of this perspective, we will discuss this method of leveraging large datasets to reduce dimensionality in smaller datasets, also known as feature-representation-transfer. 

![Dimension reduction can help manage the curse of dimensionality in rare disease data](https://github.com/jaybee84/ml-in-rd/blob/draft-branch/content/images/figures/pdfs/dimensionality-reduction.pdf){#fig:1}


### Manage model complexity while preserving the value of machine learning

Translating machine learning findings into testable hypotheses requires the applied models to be a) stable – the same predicted features should surface from the data if the model is run multiple times – and b) simple, as simple models guard against misinterpretation due to technical challenges. 
Meeting these requirements is challenging in rare disease datasets where there is high label-uncertainty (i.e., where the label given to a data point may not be correct due to imperfect understanding of the disease). 
In this section we highlight a few common ML techniques that can help improve the stability and simplicity of ML models applied to rare disease data.
Techniques like bootstrapping and ensemble learning can increase stability in machine learning predictions. 
Bootstrapping is a powerful statistical technique where resampling the data with replacements can help estimate population values from datasets of limited sample size [@doi:10.1080/01621459.1997.10474007].
While resampling with replacement is commonly used to find models that are robust to overfitting ([@doi:10.1023/A:1010933404324; @doi:10.1198/0003130043277; @doi:10.1016/s0925-2312(01)00650-6; @doi:10.1016/j.neucom.2004.11.017; @doi:10.1002/sim.4780111607]); resampling without replacement, when applied to rare disease data generated confidence intervals for the model predictions by iteratively exposing the models to incomplete datasets (mimicking real world cases where most rare disease datasets are incomplete) [@doi:10.3390/genes11020226].

Stability in predictions can also be achieved by combining various ML methods together (ensemble learning).(Figure[@fig:2]A-B) 
Ensemble learning methods like random forests use bagging of independent decision trees that use similar parameters but different paths to form a consensus about the important predictive features [@doi:10.1023/A:1010933404324; @doi:10.1186/1472-6947-13-134; @doi:10.1214/aos/1031689014; @doi:10.1177/2045894019890549; @doi:10.1016/s0031-3203(02)00169-3]. 
But such methods have shown limited success in rare disease datasets where the label-uncertainty can be high due to imperfect understanding of the disease (i.e., silver standard datasets). 
This has led to the adoption of cascade learning, where multiple methods leveraging distinct underlying assumptions are used in tandem. The methods may be augmented with algorithms like AdaBoost (boosting) to capture stable patterns existing in the silver standard data [@doi:10.1109/cvpr.2001.990537; @doi:10.1007/978-3-540-75175-5_16; @doi:10.1109/icpr.2004.1334680]. 
Cascade learning implemented to identify rare disease patients from electronic health records from the general population utilized independent steps for feature extraction (using natural language processing based word2vec [@https://arxiv.org/abs/1301.3781v343]), preliminary prediction (using an ensemble of decision trees with penalization for excessive tree-depth), and prediction refinement (using similarity of data points to resolve sample labels) [@pmid:30815073]. 
Combining these three methods resulted in better performance than other methods when implemented on the silver standard dataset in isolation.
The presence of multiple phenotypes (or classes) in rare disease datasets further decreases the available data-points per class. 
In such cases, a one-class-at-a-time cascade learning approach (where at each stage a binary classifier predicts a specific class against all others) has been found to produce simpler models that perform better compared to multi-class ensemble classifiers [@doi:10.1093/jamia/ocy109]. (Figure[@fig:2]D)

Simplification of models by making the feature space proportionate with the sample space can also be achieved through regularization. (Figure[@fig:2]C)
Regularization can not only protect ML models from poor generalizability that results from overfitting (where the model performs well for the training data but poorly for new test data) [@doi:10.1073/pnas.1900654116], but also help penalize model complexity and reduce the feature space to build simpler models using limited datasets. 
Three popular regularized methods include ridge regression, LASSO, and elastic-net. 
Ridge regression can minimize the magnitude of the features, but cannot remove unimportant features. 
LASSO regression, on the other hand, works well for selecting few important features since it can minimize the magnitude of some features more than the others [@doi:10.1038/nmeth.4014]. 
A combination of LASSO and ridge, elastic-net regression [@doi:10.1111/j.1467-9868.2005.00503.x] selects the most useful features, especially in presence of a large number of correlated features.

Rare variant discovery and immune cell signature discovery studies, like rare diseases, face challenges of the sparsity of observations (e.g. rare variants, or rare immune cells).
Studies leveraging regularization in these problems can provide important insights into its possible application in rare disease.  
In rare variant discovery, ridge regression has been utilized to combine rare variants into a single score to increase the signal of rare variants [@doi:10.1371/journal.pone.0044173], while LASSO was implemented along with group penalties to identify rare variants/low frequency predictors [@doi:10.1038/nrg2867; @doi:10.1093/bioinformatics/btq448]. 
Hybrid applications of LASSO have also been tested in rare variant discovery, including boosting the signal of rare variants by capturing combinations of variants [@doi:10.1016/j.ajhg.2008.06.024; @doi:10.1186/1753-6561-5-s9-s113], integration with a probabilistic logistic Bayesian approach [@doi:10.4137/cin.s17290], combining feature selection methods with a generalized pooling strategy [@doi:10.1371/journal.pone.0041694], and incorporating prior knowledge into the regularization step to select driver genes in a pathway of interest [@doi:10.1080/10618600.2012.681250]. 
In immune cell signature discovery, elastic-net regression has been used to reduce the feature space and was found to outperform other regression approaches [@doi:10.1111/j.1467-9868.2005.00503.x; @doi:10.1016/j.compbiomed.2015.10.008; @doi:10.1186/1471-2105-14-198; @doi:10.1186/s12859-019-2994-z]. 
Regularization methods like LASSO or elastic-net have been methods of choice for making models simpler by reducing the feature space; these methods should be explored while working with rare disease datasets. 

Thus by employing bootstrapping, ensemble learning, and regularization methods, researchers may be able to better generate stable, simple models that identify reliable biological phenomena underlying rare diseases .

![Strategies to simplify models and stabilize predictions preserve the value of machine learning in rare disease. A-B) Strategies to build confidence in model predictions; A) schematic showing the concept of bootstrap, B) schematic showing the concept of ensemble learning to converge on reliable models; C-D) Strategies to simplify models by penalizing complexity in ML models; C) schematic showing the concept of regularization to selectively learn relevant features, D)schematic showing the concept of one-class-at-a-time learning to select few features at a time. Horizontal bars represent health of a model, models are represented as a network of nodes (features) and edges (relationships), nodes with solid edges represent real patterns, nodes with broken edges represent spurious patterns](https://github.com/jaybee84/ml-in-rd/blob/draft-branch/content/images/figures/pdfs/statistical-techniques.pdf){#fig:2}



### Build upon prior knowledge and indirectly related data {.page_break_before}

Rare diseases often lack large, normalized datasets, limiting our ability to study key attributes of these diseases. 
Thus evaluating genotype-phenotype relationships or repurposing drugs using knowledge graphs can greatly benefit rare disease. 
Knowledge graphs (KGs) integrate related-but-different data types, creating a rich data source (e.g. Monarch Graph Database[@doi:10.1093/nar/gkw1128], hetionet[@doi:10.7554/elife.26726], PheKnowLator[@doi:10.1101/2020.04.30.071407], and the Global Network of Biomedical Relationships[@doi:10.1093/bioinformatics/bty114], Orphanet[@http://www.orpha.net]). 
These graphs connect genetic, functional, chemical, clinical, and ontological data to enable the exploration of relationships of data with disease phenotypes through manual review[@doi:10.1093/database/baaa015] or computational methods[@doi:10.1101/727925; @doi:10.1186/s12911-019-0938-1].(Figure[@fig:3]a)
KGs may include  links or nodes that are specific to the rare disease of interest (e.g. an FDA approved treatment  would be a specific disease-compound link in the KG ) as well as links that are more generalized (e.g. gene-gene interactions noted in the literature for a different disease). 

Rare disease researchers can leverage the entities and relationships outside of the specific disease-context, including common comorbidities that are more prevalent conditions[@doi:10.1101/727925], for prediction. 
Such approaches have been used in rare disease research in areas such as drug repurposing[@doi:10.1101/727925] and disease classification[@doi:10.1186/s12911-019-0938-1]. 
Identifying KG encoding methods that can provide actionable insights for a specific rare disease application is an active area of research. 
Other approaches that build upon prior knowledge and large volumes of related data include transfer learning, multitask learning, and few-shot learning approaches. 
These approaches leverage shared features, e.g. normal developmental processes that are aberrant in disease, or an imaging anomaly present in rare and common diseases, for advancing our understanding of rare diseases. 

Transfer learning, where a model trained for one task or domain (source domain) is applied to another related task or domain (target domain), can be supervised or unsupervised. 
Among various types of transfer learning we will mainly focus on feature-representation-transfer. (Figure[@fig:3]b)
Feature-representation-transfer approaches learn representations from the source domain and apply them to a target domain.[@doi:10.1109/tkde.2009.191]
For example, low-dimensional representations can be learned from tumor transcriptomic data and transferred to describe patterns associated with genetic alterations in cell line data [@doi:10.1186/s13059-020-02021-3].

Other approaches related to transfer learning, multitask and few-shot learning, are forms of supervised learning that often  rely on deep neural networks. 
In multitask learning classifiers use shared representations to learn multiple related but individual predictions (tasks) simultaneously [@doi:10.1023/a:1007379606734]. (Figure[@fig3]c-d)
Few-shot learning on the other hand generalizes a model trained on related tasks to a new task with limited labeled data (e.g., the detection of a patient with a rare disease from a low number of examples of that rare disease). 
While various approaches and architectures underlie multitask and few-shot learning (see [@https://arxiv.org/abs/1706.05098; @https://arxiv.org/abs/1707.08114v2; @https://arxiv.org/abs/1904.05046v3] for an overview), we will delve into a few selected studies to illustrate potential uses and limitations of these approaches in rare disease.

Examination of the effects of dataset size and task relatedness on multitask learning performance improvements (“multitask effect”) in drug discovery showed that smaller datasets tended to benefit most from multitask learning and the addition of more training data did not guarantee improved performance for multitask models [@https://arxiv.org/abs/1606.08793]. 
Another study demonstrated that performance gains were context-dependent, i.e., multitask neural networks outperformed single-task networks for predicting complex rare phenotypes from EHR data, but not common phenotypes [@https://arxiv.org/abs/1808.03331]. The top-performer in a recent DREAM challenge for predicting drug sensitivity in cancer cell lines, including cell lines from rare cancers, was a multitask learning approach [TODO: CTD-squared Chemogenomic DREAM Challenge citation]. 
From these studies and others, it is clear that multitask learning is a promising approach for rare disease research albeit with some important, context-specific limitations.
In contrast, one-shot or few-shot learning uses prior knowledge to generalize a distance metric learned from input data to compare with a low number of new examples for prediction [@https://arxiv.org/abs/1904.05046v3, @doi:10.1021/acscentsci.6b00367], e.g. a method developed for predicting small molecule activity learned a meaningful distance metric over the properties of various compounds [@doi:10.1021/acscentsci.6b00367]. 
But the authors’ results also suggest that structural similarity among compounds was a requirement for this desired performance boost. 
In a study of rare pathologies in fundus photographs, a few-shot learning approach had a performance advantage over multitask learning, since predicting common conditions simultaneously resulted in a loss of performance for the multitask learner [@doi:10.1016/j.media.2020.101660]. 
Thus transfer, multi-task, and few-shot learning are appealing for the study of rare diseases, conditions, or phenotypes, but their limits and potential utility are still open research questions. 
Nevertheless, selecting an appropriate model for a given task and evaluations that are well-aligned with a research question are crucial for applying these approaches in rare diseases.

![Strategies that build upon prior knowledge help ML models learn patterns in rare disease datasets.](https://github.com/jaybee84/ml-in-rd/blob/draft-branch/content/images/figures/pdfs/prior-knowledge.pdf){#fig:3}


### Using composite approaches can be a powerful strategy

We have described multiple approaches for maximizing the success of machine learning applications in rare disease research throughout. 
In practice, it is rarely sufficient to use one of these techniques in isolation. 
Below, we highlight two recent works in the rare disease domain that draw on multiple concepts covered in the earlier sections. 
Feature-representation-transfer, which incorporates dimension reduction through representation learning, prior data, and regularization underlie both approaches.

Thousands of acute myeloid leukemia (AML) patient gene expression samples have been collected over time and are publicly available.
Not all of these samples include the most relevant clinical or phenotypic data such as drug response.
However, these publicly available data include an _in vitro_ experiment that examined the response to 160 drugs for 30 AML patient samples, measured using genome-wide arrays which have tens of thousands of features [@doi:10.1038/s41467-017-02465-5].
Training on this drug response dataset alone poses challenges raised throughout –  many features combined with small sample size can result in ML models that are of limited utility and sample size can also be prohibitive when performing representation learning.
Dincer et al. trained a variational autoencoder on over 6500 AML samples (VAE; see [definitions]) [TODO: link between sections?] to reduce the dimensionality of the test set in an approach termed DeepProfile [@https://www.biorxiv.org/content/10.1101/278739v2].
The 30 AML test samples with drug response information were encoded using the VAE's low-dimensional representation or _transferred_, reducing the number of features from thousands to eight.
LASSO linear regression models that used encodings as features had better performance than models that used individual gene expression values as features on average.
In addition, the low-dimensional representation learned by the VAE captured more biological pathways than PCA, which may be attributable to the constraints on encodings imposed during the training process [definitions] [TODO: link between sections or cite what is in definitions?].
Similar results were observed for prediction of histopathology in another rare cancer (ovarian) [@https://www.biorxiv.org/content/10.1101/278739v2].

While DeepProfile was centered on training on an individual disease and tissue combination, some rare diseases affect multiple tissues that a researcher may be interested in studying together for the purpose of biological discovery. 
Studying multiple tissues poses significant challenges – features that can be appreciably measured may be tissue-specific even when looking at learned features or representations, a cross-tissue analysis may require an analyst to compare representations from multiple models and models trained on a low number of samples may learn representations that "lump together" multiple biological signals, reducing the interpretability of the results.
To address these challenges, Taroni et al. trained Pathway-Level Information ExtractoR (PLIER) [@doi:10.1038/s41592-019-0456-1] on a large generic collection of human transcriptomic data (recount2 [@doi:10.1038/nbt.3838]).
The authors used the latent variables learned by the model to describe transcriptomic data from the unseen rare diseases antineutrophil cytoplasmic antibody (ANCA)-associated vasculitis (AAV) and medulloblastoma in an approach termed MultiPLIER [@doi:10.1016/j.cels.2019.04.003]. 
(Here "unseen" refers to the fact that these diseases were not in the training set).
PLIER is a matrix factorization approach that takes prior knowledge in the form of gene sets or pathways and gene expression data as input [@doi:10.1038/s41592-019-0456-1]. 
PLIER includes constraints (regularization) such that some latent variables learned by the model will align with input gene sets and ideally latent variables will only be associated with a low number of related gene sets [@doi:10.1038/s41592-019-0456-1], which make it suitable for biological discovery or description of rare disease data. 
MultiPLIER allows us to use one model to describe multiple datasets instead of reconciling output from multiple models, which is highly beneficial when identifying commonalities among disease manifestations or affected tissues is a research goal.
(This benefit extends to studying multiple cohorts with a different model.)
The inclusion of a large number of samples from diverse biological conditions in the training set results in models with desirable features (e.g., similar pathways are disentangled or separated out in the learned representations).

Taken together, DeepProfile [@doi:10.1101/278739v2] and MultiPLIER [@doi:10.1016/j.cels.2019.04.003] suggest a combination of the techniques discussed throughout this article can be capitalized on for rare disease research. 
In cases where we have few samples from our disease of interest with the required phenotypic labels, we can leverage existing collections of data and knowledge if we select the models with the right attributes. 
The utility of DeepProfile and MultiPLIER stem from the fact that biological processes can be shared between biological contexts and that the methods underlying the approaches can effectively learn about those processes. 
In the natural images field, researchers have demonstrated that the transferability of features depends on relatedness of tasks [@arxiv:1411.1792]. 
The limits of transfer learning for and the concept of relatedness in high-dimensional biomedical data assaying rare diseases are open research questions. 
In the authors' opinion, selecting an appropriate model for a given task and evaluations that are well-aligned with a research goal are crucial for applying these approaches in rare diseases .


### Outlook

Throughout this perspective, we have highlighted various challenges in applying ML methods to rare disease data as well as examples of approaches that address these challenges.
Scarcity of samples, while significant, is not the only roadblock towards application of ML in rare disease data.
The high dimensionality of modern data requires creative approaches, such as learning new representations of the data, to manage the curse of dimensionality.
It further requires leveraging prior knowledge and transfer learning methods to appropriately interpret data. 
Additionally, anyone applying machine learning methods on rare disease data should use techniques that increase confidence (such as bootstrapping) and penalize complexity of the resultant models (such as regularization) to enhance the generalizability of their work. 

All of the approaches highlighted in this perspective come with certain challenges or inadequacies that breed mistrust in using these powerful techniques in rare disease.
We believe that the same challenges that are currently considered major pitfalls in applying ML to rare disease can be great opportunities for data generation as well as method development in moving the field forward.
During our journey through the various challenges, we identified two major areas where mindful strategies can immeasurably enhance the power of machine learning in rare disease and move the field forward.

_Emphasis on not just "more n" but "more meaningful n"_

Mindful addition of data is key for powering the next generation of analysis in rare disease data.
While there are many techniques to collate rare data from different sources, incorrect data generation may hurt the end goal even if it adds to the size of the dataset.
In our experience collaboration with domain experts have proved to be critical in gaining insight into potential sources of variation in the datasets.
As an example, an neurofibromatosis type 1 (NF1) dataset was found to contain samples collected using vastly different surgical techniques (laser ablation and excision vs standard excision). [@doi:10.3390/genes11020226] 
While the integrative analysis in the study using transfer learning techniques was able to minimize technique related signals [@doi:10.1016/j.cels.2019.04.003], a more traditional analysis may have resulted in surfacing of substantial biological differences that are a consequence of process (e.g. activation of heat shock protein related pathways), not disease related biology. 
Such instances underline the fact that continuous collaboration with domain experts is needed to generate robust datasets in the future.
A few such collaborations are beginning to show promise in generating valuable datasets for future use.[@doi:10.1038/s41597-020-0508-5]


In addition to sample scarcity, there is a dearth of comprehensive phenotypic-genotypic databases in rare disease.
With the ubiquity of sequencing platforms, genomic data has been, relatively speaking, easy to gather for rare disease patients.[@doi:10.1038/nrg3555; @doi:10.1038/nrg.2017.116; @doi:10.1056/NEJMra1711801]
An important next step is to develop comprehensive comprehensive genomics-driven genotype-phenotype databases that can fuel interpretation of features extracted using ML methods.
Finally, mindful sharing of data with proper metadata and attribution to enable prompt data reuse is of utmost important in building datasets that can be of great value in rare disease. [@https://www.nature.com/articles/s41576-020-0257-5]


_Development of methods that reliably support mechanistic interrogation of specific rare diseases_

The majority of ML methods for rare disease that we have investigated are applied to classification tasks. 
Conversely, we've found few examples of methodologies that interrogate biological mechanisms of rare diseases. 
This is likely a consequence of a dearth of methods that can tolerate the constraints imposed by rare disease research such as phenotypic heterogeneity and limited data.
An intentional push towards developing methods or analytical workflows that address this will be critical to apply machine learning approaches to rare disease data.

Method development with rare disease applications in mind requires the developers to bear the responsibility of ensuring that the resulting model is _trustworthy_.
The field of natural language processing has a few examples of how this can be achieved.[@https://www.aclweb.org/anthology/N16-3020.pdf, @https://www.aclweb.org/anthology/P19-1073.pdf]
One way to increase trust in a developed model is by helping users understand the behavior of the developed model through providing explanations regarding why a certain model made certain predictions.[@https://www.aclweb.org/anthology/N16-3020.pdf]
Another approach is to provide robust _error analysis_ for newly developed models to help users understand the strengths and weaknesses of a model.[@https://www.aclweb.org/anthology/P19-1073.pdf; @https://www.mitpressjournals.org/doi/abs/10.1162/COLI_a_00072; @doi:10.1093/bioinformatics/bth060]
Adoption of these kind of approaches into biological data and analysis is still rare but is quickly becoming necessary as machine learning approaches become mainstream in biomedicine.

Finally, methods that can reliably integrate disparate datasets will always remain a need of rare diseases.
Moreover, combining data that originated from diverse modalities to create a complete picture of the disease related biology is increasingly becoming common.
To facilitate such analyses in rare disease, methods that rely on finding structural correspondences between datasets ("anchors") may be able to transform the status-quo of using machine learning methods in rare disease.[@https://www.aclweb.org/anthology/W06-1615.pdf; @https://people.cs.umass.edu/~mahadeva/papers/IJCAI2011-DA.pdf; https://www.cell.com/cell/fulltext/S0092-8674(19)30559-8]
Overall, we speculate that this an important burgeoning area of research, and we are optimistic about the future of applying machine learning approaches to rare disease.


## Definitions {.page_break_before}

### Unsupervised learning: 
Machine learning algorithms which can learn features from unlabeled training data (e.g. datasets where the samples do not have disease or phenotype labels) to predict the class or phenotype of new or unseen test data are part of unsupervised learning. Examples of unsupervised learning include principal component analyses, multidimensional scaling, UMAP, t-SNE, k-means clustering etc [TODO - add REFs].

### Supervised learning: 
Machine learning algorithms that require training data with specific phenotype labels are part of supervised learning. 
Such algorithms learn correlations of features with the phenotype labels and use the learned correlations to predict the phenotype labels of unseen or new test data.

### VAE: 
Variational Autoencoders or VAEs are unsupervised neural networks that use hidden layers to learn or encode representations from available data while mapping the input data to the output data. 
VAEs are distinct from other autoencoders since the distribution of the encodings are regularized such that they are close to a normal distribution, which may contribute to learning more biologically relevant signals [@doi:10.1186/s13059-020-02021-3].


## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>
