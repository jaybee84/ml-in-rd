---
author-meta:
- Jineta Banerjee
- Robert J Allaway
- Jaclyn N Taroni
- Casey Greene
- Justin Guinney
bibliography:
- content/manual-references.json
date-meta: '2020-08-19'
header-includes: "<!--\nManubot generated metadata rendered from header-includes-template.html.\nSuggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html\n-->\n<meta name=\"dc.format\" content=\"text/html\" />\n<meta name=\"dc.title\" content=\"Machine learning methods for rare diseases\" />\n<meta name=\"citation_title\" content=\"Machine learning methods for rare diseases\" />\n<meta property=\"og:title\" content=\"Machine learning methods for rare diseases\" />\n<meta property=\"twitter:title\" content=\"Machine learning methods for rare diseases\" />\n<meta name=\"dc.date\" content=\"2020-08-19\" />\n<meta name=\"citation_publication_date\" content=\"2020-08-19\" />\n<meta name=\"dc.language\" content=\"en-US\" />\n<meta name=\"citation_language\" content=\"en-US\" />\n<meta name=\"dc.relation.ispartof\" content=\"Manubot\" />\n<meta name=\"dc.publisher\" content=\"Manubot\" />\n<meta name=\"citation_journal_title\" content=\"Manubot\" />\n<meta name=\"citation_technical_report_institution\" content=\"Manubot\" />\n<meta name=\"citation_author\" content=\"Jineta Banerjee\" />\n<meta name=\"citation_author_institution\" content=\"Sage Bionetworks\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0002-1775-3645\" />\n<meta name=\"citation_author\" content=\"Robert J Allaway\" />\n<meta name=\"citation_author_institution\" content=\"Sage Bionetworks\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0003-3573-3565\" />\n<meta name=\"twitter:creator\" content=\"@allawayr\" />\n<meta name=\"citation_author\" content=\"Jaclyn N Taroni\" />\n<meta name=\"citation_author_institution\" content=\"Childhood Cancer Data Lab, Alex\u2019s Lemonade Stand Foundation\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0003-4734-4508\" />\n<meta name=\"citation_author\" content=\"Casey Greene\" />\n<meta name=\"citation_author_institution\" content=\"Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania\" />\n<meta name=\"citation_author_institution\" content=\"Childhood Cancer Data Lab, Alex\u2019s Lemonade Stand Foundation\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0001-8713-9213\" />\n<meta name=\"citation_author\" content=\"Justin Guinney\" />\n<meta name=\"citation_author_institution\" content=\"Sage Bionetworks\" />\n<meta name=\"citation_author_orcid\" content=\"0000-0003-1477-1888\" />\n<link rel=\"canonical\" href=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta property=\"og:url\" content=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta property=\"twitter:url\" content=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta name=\"citation_fulltext_html_url\" content=\"https://jaybee84.github.io/ml-in-rd/\" />\n<meta name=\"citation_pdf_url\" content=\"https://jaybee84.github.io/ml-in-rd/manuscript.pdf\" />\n<link rel=\"alternate\" type=\"application/pdf\" href=\"https://jaybee84.github.io/ml-in-rd/manuscript.pdf\" />\n<link rel=\"alternate\" type=\"text/html\" href=\"https://jaybee84.github.io/ml-in-rd/v/097352b0d4cdfd84cc0d18fdacb15ee5e615a209/\" />\n<meta name=\"manubot_html_url_versioned\" content=\"https://jaybee84.github.io/ml-in-rd/v/097352b0d4cdfd84cc0d18fdacb15ee5e615a209/\" />\n<meta name=\"manubot_pdf_url_versioned\" content=\"https://jaybee84.github.io/ml-in-rd/v/097352b0d4cdfd84cc0d18fdacb15ee5e615a209/manuscript.pdf\" />\n<meta property=\"og:type\" content=\"article\" />\n<meta property=\"twitter:card\" content=\"summary_large_image\" />\n<link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"https://manubot.org/favicon-192x192.png\" />\n<link rel=\"mask-icon\" href=\"https://manubot.org/safari-pinned-tab.svg\" color=\"#ad1457\" />\n<meta name=\"theme-color\" content=\"#ad1457\" />\n<!-- end Manubot generated metadata -->"
keywords:
- rare disease
- machine learning
- transfer learning
lang: en-US
manubot-clear-requests-cache: false
manubot-output-bibliography: output/references.json
manubot-output-citekeys: output/citations.tsv
manubot-requests-cache-path: ci/cache/requests-cache
title: Machine learning methods for rare diseases
...






<small><em>
This manuscript
([permalink](https://jaybee84.github.io/ml-in-rd/v/097352b0d4cdfd84cc0d18fdacb15ee5e615a209/))
was automatically generated
from [jaybee84/ml-in-rd@097352b](https://github.com/jaybee84/ml-in-rd/tree/097352b0d4cdfd84cc0d18fdacb15ee5e615a209)
on August 19, 2020.
</em></small>

## Authors



+ **Jineta Banerjee**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0002-1775-3645](https://orcid.org/0000-0002-1775-3645)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [jaybee84](https://github.com/jaybee84)<br>
  <small>
     Sage Bionetworks
     · Funded by Neurofibromatosis Therapeutic Acceleration Program; Children's Tumor Foundation
  </small>

+ **Robert J Allaway**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-3573-3565](https://orcid.org/0000-0003-3573-3565)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [allaway](https://github.com/allaway)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [allawayr](https://twitter.com/allawayr)<br>
  <small>
     Sage Bionetworks
     · Funded by Neurofibromatosis Therapeutic Acceleration Program; Children's Tumor Foundation
  </small>

+ **Jaclyn N Taroni**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-4734-4508](https://orcid.org/0000-0003-4734-4508)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [jaclyn-taroni](https://github.com/jaclyn-taroni)<br>
  <small>
     Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation
  </small>

+ **Casey Greene**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0001-8713-9213](https://orcid.org/0000-0001-8713-9213)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [cgreene](https://github.com/cgreene)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania; Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation
  </small>

+ **Justin Guinney**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-1477-1888](https://orcid.org/0000-0003-1477-1888)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [jguinney](https://github.com/jguinney)<br>
  <small>
     Sage Bionetworks
     · Funded by Neurofibromatosis Therapeutic Acceleration Program; Children's Tumor Foundation
  </small>



## Synopsis {.page_break_before}

(Instructions: Describe the background, basic structure of the article, list material to be covered indicating depth of coverage, how they are logically arranged, include recent pubs in the area, 300-500 words)

Substantial technological advances have dramatically changed biomedicine by making deep characterization of patient samples routine. 
These technologies provide a rich portrait of genes, cellular pathways, and cell types involved in complex phenotypes. 
Machine learning is often a perfect fit for the types of data now being generated, and Nature Methods routinely has reports of machine learning methods that extract disease-relevant patterns from these high dimensional datasets. 
Often, these methods require a large number of samples to identify reproducible and biologically meaningful patterns. 
With rare diseases, biological specimens and consequently data, are limited due to the rarity of the condition. 
In this perspective, we outline the challenges and emerging solutions for using machine learning in these settings. 
We aim to spur the development of powerful machine learning techniques for rare diseases. 
We also note that precision medicine presents a similar challenge, in which a common disease is partitioned into small subsets of patients with shared etiologies and treatment strategies. 
Advances from rare disease research are likely to be highly informative for other applications as well.


## Introduction {.page_break_before}

Machine learning is gaining momentum in biomedical data analysis as data collection is increasingly high-throughput and algorithms or approaches become more transparent and interpretable. 

Application of machine learning to any dataset poses challenges, but the application to biomedical data and subsequent interpretation requires depth of knowledge not only in the biomedical domain but also a clear understanding of the methods and their underlying assumptions.

Rare disease research has not yet significantly benefited from machine learning applications for various reasons, including lack of statistical power in dataset size, heterogeneity in available data, and sensitivity of machine learning methods to misinterpretation in view of small datasets. 
We anticipate higher occurrence of such applications in the near future and aim to highlight the current state-of-art in this perspective.
However recent advances in the methodologies to accommodate rarity of samples and increased transparency in model outputs have encouraged application of machine learning in rare disease.


Application of machine learning to any kind of data consists of the following major steps: (1) data evaluation and question formulation, (2) selection of normalization/dimension reduction to mitigate technical differences, (3) selection of appropriate algorithms which select features to answer the formulated question, (4) evaluation of the answers generated by the algorithm. 
Each of these steps require the practitioner to choose from a variety of methodologies to apply. 
The selection of the methodologies at each of these steps need to be based upon robust reasoning to ensure stability of the results. 
Moreover, in the context of rare diseases, special considerations need to be made at each of the above mentioned steps to safeguard against misinterpretation of data.
Such considerations include incorporation of techniques that build upon prior domain-specific knowledge, methods that are resilient to challenges posed by small datasets, and methods that can mitigate technical disparities in the data.


### Knowledge graphs 
An intrinsic constraint in studying rare diseases is the lack of large, normalized datasets, which limits our ability to study key attributes of rare diseases. 
A potentially powerful strategy for evaluating genotype-phenotype relationships or repurposing drugs when large datasets are scarce is to use knowledge graphs.
Knowledge graphs integrate related-but-different data types, creating a rich data source. 
Examples of public biomedical knowledge graphs and frameworks that could be useful in rare disease include the Monarch Graph Database[@doi:10.1093/nar/gkw1128], hetionet[@doi:10.7554/eLife.26726], PheKnowLator[@doi:10.1101/2020.04.30.071407], and the Global Network of Biomedical Relationships[@doi:10.1093/bioinformatics/bty114]. 
These graphs connect information like genetic, functional, chemical, clinical, and ontological data to enable the exploration of relationships of data with disease phenotypes through manual review[@doi:10.1093/database/baaa015] or computational methods[@doi:10.1101/727925; @doi:10.1186/s12911-019-0938-1]. 

In the academic rare disease space, there a few pioneering examples of ML-based mining of knowledge graphs to repurpose drugs[@doi:10.1101/727925] and classify rare diseases[@doi:10.1186/s12911-019-0938-1].
These studies make it clear that there are some challenges in using machine learning using graph databases in rare disease.
For example, these papers rely on a gold standard dataset to validate the performance of the models; often, there are not robust gold standard datasets available for individual rare diseases.
They also evaluate rare diseases in an unbiased manner, rather than interrogating a specific disease of interest.
Consequently, it is not yet clear how effective these approaches, and knowledge graphs in general, are in studying a specific disease of interest; more work needs to be done to identify methods that can provide actionable insights for a specific rare disease application. 

Beyond the aforementioned studies, there are few examples of studies in the public domain that leverage knowledge graphs to characterize rare disease. 
Private entities (e.g. healx, Boehringer Ingelheim, DrugBankPlus) are performing an undisclosed amount of work to create proprietary rare disease knowledge graphs for ML-based drug discovery applications.  
The existence of private companies pursuing this idea, as well as the availability of several public knowledge graphs with relevance to rare disease, suggests to us that this is a likely fruitful and untapped area of rare disease research in the public sphere. 
More work needs to be done to assess 1) which graphs and graph features capture the salient information about rare diseases, 2) the utility of ML methods to obtain actionable insights about rare diseases and 3) which problems - like drug discovery, identification of novel rare diseases, or assessment of genotype-phenotype relationships - can be interrogated using ML of knowledge graphs.


### Techniques that build on prior knowledge and indirectly related data are necessary for many rare disease applications {.page_break_before}

#### Wisdom of the crowd: rare disease applications of ensemble methods
Implementing machine learning on data with low sample size and high label uncertainty can lead to unstable predictions. 
In such cases various machine learning methods together (also called _ensemble learning_) can help increase accuracy and stability of the predictions.
Ensemble learning can use multiple similar approaches stitched together to reach a consensus, or can be a collection of different approaches that perform better compared to any single algorithm.
For example, ensemble learning methods like random forests use bootstrap aggregation (or _bagging_) of independent decision trees that use similar parameters but different paths to form a consensus about the important predictive features hidden in the dataset [@doi:10.1186/1472-6947-13-134, @doi:10.1023/A:1010933404324, @doi:10.1214/aos/1031689014, @doi:10.1177/2045894019890549, @doi:10/btzfh6].
However, successful application of consensus based ensemble learning requires "gold standard" data where the diagnosis or label of a data point in the training dataset has very little uncertainty (or "label-noise") associated with it [@doi:10.1093/jamia/ocw028]. 
In most cases of rare disease, due to the inherent nature of being less defined, the symptoms as well as any underlying biology comes with a reasonable amount label-noise leading to a _silver standard_ dataset[@doi:10.1109/TNNLS.2013.2292894, @doi:10.1093/jamia/ocw028].
In such datasets, the limited success of the _bagging_ approach has led to the use of ensemble learning or _cascade learning_, where multiple methods leveraging distinct underlying assumptions are used in tandem and augmented with algorithms like AdaBoost (_boosting_) to capture stable patterns existing in the silver standard data and reduce uncertainty [@doi:10.1109/CVPR.2001.990537, @doi:10.1007/978-3-540-75175-5_16, @doi:10.1109/ICPR.2004.1334680].
A variation of cascade learning implemented to identify rare disease patients from electronic health records from the general population utilized independent steps for feature extraction (using word2vec [@arXiv:1301.3781v3]), preliminary prediction (ensemble of decision trees with penalization for excessive tree-depth), and prediction refinement (using similarity of data points to resolve sample labels) [@pmid:30815073].
This cascade learner benefited from the independence of the feature extraction step and the prediction refinement step from the preliminary classification of the labeled dataset to find stable patterns and perform better than other ensemble methods when implemented on this silver standard dataset.

In datasets with multiple classes, most cascade classifiers follow a _one-classifier-at-a-time_ approach where algorithms at each level predict all classes involved.
But instances where the need for high prediction accuracy for one class outweighs other classes, further modification of the cascade learning efforts is required.
An example of such modification was implemented for triaging psychiatric patients where the identification of one class of psychiatric patients ("severe") far outweighed the need for optimized overall classification accuracy [@pmid:30380082].
Due to the requirements of the problem, a _one-class-at-a-time_ cascade learning approach was adopted, where at each stage a binary classifier was used to predict a specific class against all others.
The final model implemented all models together each identifying one class sequentially and the union of the predictions of all the different models as the final prediction.
The cascade classifiers using the one-class-at-a-time approach were found to perform better than multi-class ensemble classifiers in most cases.

Thus ensemble learning can be helpful in producing stable predictions from rare disease data, but the choice of using bagging, boosting, independent algorithmic steps, or one-class-at-a-time approach depends on the nature of the prediction question.


#### Representation learning

Representation learning, also called feature learning, is the process of learning features from raw data, where a feature is an individual variable.
An algorithm or approach will construct features as part of training and, in a supervised application, use those features to predict labels on input data. 
Using an example from transcriptomics, an unsupervised method such as matrix factorization can be used to extract a low-dimensional representation of the gene-level data, learning features that are a combination of input genes' expression levels [@doi:10.1093/bioinformatics/btq503; @doi:10.1186/s13059-020-02021-3].
Low-dimensional representations trained on a collection of transcriptomic data can then be used as input to supervised machine learning methods [@doi:10.1186/s12859-020-3427-8]. 
Supervised neural networks used in medical imaging studies [@doi:10.1016/j.procs.2016.07.014] (reviewed in [@doi:10.1098/rsif.2017.0387]), which are trained to predict labels or classes, are also an example of representation learning. 
Learned features in the medical imaging domain may be a series of edges representing a blood vessel formation that discriminates between disease states.
Features learned from transcriptomic data could be coordinated sets of genes involved in a biological process that are descriptive in some way [@doi:10.1038/s41467-020-14666-6].

In the rare disease domain, Dincer et al. leveraged publicly available acute myeloid leukemia (AML) gene expression data to improve the prediction of _in vitro_ drug responses [@doi:10.1101/278739]. 
The authors trained a variational autoencoder (VAE) on AML data that had been collected over time without the phenotypic information they were interested in (drug response). 
(A VAE is an unsupervised neural network that learns a series of representations from data.)
The authors used the learned attributes to encode a low-dimensional representation of held-out AML data with phenotype labels of interest, and used this low-dimensional representation as input to a classifier that predicted _in vitro_ drug response.

Representation learning tends to be data-intensive; many samples are required.
Though there were over 6500 AML samples from many different studies used as part of the training set in Dincer et al. [@doi:10.1101/278739], we expect that in other rare diseases considerably fewer samples will be available or may be from different tissues in systemic diseases.
The study by Dincer and colleagues highlights another challenge: samples collected as part of multiple studies may not be associated with the deep phenotypic information that would maximize their scientific value.
In the next section, we will introduce methods or approaches that may be more broadly useful in rare diseases; representation learning underlies many of them.

#### Transfer, multitask, and few-shot learning

We focus on a series of approaches that are centered on the following concept: to realize the potential of machine learning for biological discovery in rare diseases, we often cannot study an individual rare disease alone as samples are limited.
Instead, we can build on prior knowledge and large volumes of data that do not directly assay our disease of interest, but are similar enough to be valuable for discovery.
We can leverage shared features, whether they are normal developmental processes that are aberrant in disease or an imaging anomaly present in rare and common diseases, for advancing our understanding.
Methods that leverage shared features include transfer learning, multitask learning, and few-shot learning approaches. 

##### Transfer learning

Transfer learning is an approach where a model trained for one task or domain (source domain) is applied to another, typically related task or domain (target domain).
Transfer learning can be supervised (one or both of the source and target domains have labels), or unsupervised (both domains are unlabeled).
Though there are multiple types of transfer learning, we will focus on feature-representation-transfer [@doi:10.1109/TKDE.2009.191] here. 
Feature-representation-transfer approaches learn representations from the source domain and apply them to a target domain [@doi:10.1109/TKDE.2009.191].
This concept is embodied in Dincer et al., where features are learned from unlabeled AML data and then used to encode a low-dimensional representation of AML data with _in vitro_ drug response labels [@doi:10.1101/278739].
The authors then used this low-dimensional representation as input to predict drug response labels–a supervised example.

In an unsupervised case, Taroni et al. trained a Pathway-Level Information ExtractoR (PLIER) [@doi:10.1038/s41592-019-0456-1] on a large generic collection of human transcriptomic data (recount2 [@doi:10.1038/nbt.3838]) and used the latent variables learned by the model to describe transcriptomic data from the unseen rare diseases antineutrophil cytoplasmic antibody (ANCA)-associated vasculitis (AAV) and medulloblastoma in an approach termed MultiPLIER [@doi:10.1016/j.cels.2019.04.003].
(Here "unseen" refers to the fact that these diseases were not in the training set.)
PLIER is a matrix factorization approach that takes prior knowledge in the form of gene sets or pathways and gene expression data as input; some latent variables learned by the model will align with input gene sets  [@doi:10.1038/s41592-019-0456-1].
We demonstrated that training on larger collections of randomly selected samples produced models that captured a larger proportion of input gene sets and better distinguished closely related signals, which suggests that larger training sets produced models that are more suitable for biological discovery [@doi:10.1016/j.cels.2019.04.003].

Though models trained on generic compendia had appealing properties, that alone does not guarantee suitability for describing rare diseases.
We must examine the relevance of learned features to the disease under study.
In Taroni et al., we found that the expression of latent variables that could be matched between the MultiPLIER model and a dataset-specific model were well-correlated, particularly when latent variables were associated with input gene sets [@doi:10.1016/j.cels.2019.04.003].
Despite the absence of AAV from the training set, MultiPLIER was able to learn a latent variable where the genes with the highest contributions encode antigens that the antineutrophil cytoplasmic antibodies (ANCA) form against in AAV and with higher expression in more severe disease [@doi:10.1002/art.27398].
The utility of this approach stems from the fact that biological processes are often _shared_ between conditions–the same ANCA antigen genes are components of neutrophilic granule development that is likely captured or assayed in the collection of transcriptomic data used for training.
MultiPLIER has additional attributes that make it practical for studying rare diseases: latent variables that are not associated with input gene sets may capture technical noise separately from biological signal and we can use one model to describe multiple datasets instead of reconciling output from multiple models (see _05.heterogeneity.md_).

Taken together, DeepProfile [@doi:10.1101/278739] and MultiPLIER [@doi:10.1016/j.cels.2019.04.003] suggest transfer learning can be beneficial for studying rare diseases. 
In the natural images field, researchers have demonstrated that the transferability of features depends on relatedness of tasks [@arxiv:1411.1792].
The limits of transfer learning for and the concept of relatedness in high-dimensional biomedical data assaying rare diseases are open research questions.
In the authors' opinion, selecting an appropriate model for a given task and evaluations that are well-aligned with a research goal are crucial for applying these approaches in rare diseases.


### Techniques and procedures must be implemented to manage model complexity without sacrificing the value of machine learning
Inherent challenges posed by low sample numbers in rare diseases are further aggravated by disease heterogeneity, poorly defined disease phenotypes, and often a lack of control (i.e. normal) data. 
Machine learning approaches must be carefully designed to address these challenges. 
We discuss how to implement methodological solutions like bootstrapping sample data, regularization methods for deep learning, and hyper-ensemble techniques to minimize misinterpretation of the data. 

#### Bootstrapping

Bootstrap (resampling) computation is a powerful statistical technique that can be used to estimate population values from datasets of limited sample size by resampling the data to generate an estimated distribution of the population statistic and minimize estimation error [@doi:10.1080/01621459.1997.10474007].
Bootstrap based techniques are used in conjunction with various learning methods to find the most informative models given a specific dataset (e.g. bootstrap aggregating or bagging used in random forests [@doi:10.1023/A:1010933404324; @doi:10.1198/0003130043277], bootstrap in neural networks [@doi:10/c8xpqz], or regression models [@doi:10.1016/j.neucom.2004.11.017; @doi:10.1002/sim.4780111607]).
In addition to model selection, bootstrap can be used to enhance information content of rare disease datasets and generate confidence intervals for the model predictions [@doi:10.3390/genes11020226].
In this study, bootstrapping the training sample without replacement simulated generation of separate datasets that helped expose the learning models (in this case random forests) to the incomplete nature of the data.
Such bootstrapping of the training data in addition to that included in the model (bagging) helped generate a distribution (and confidence intervals) of the importance scores of the predictive features selected by the model.

#### Regularization

A common strategy for handling the paucity of data in rare disease is to aggregate data from multiple studies or time points to produce a more comprehensive dataset. 
Given a dataset with strong preexisting study-specific technical differences between groups of samples, machine learning methods may model dataset-specific features instead of true biology, leading to high prediction accuracy for training data but poor performance in new test data (an "overfit" model) [@doi:10.1073/pnas.1900654116].
Minimization of overfitting can be accomplished by cross-validation (to reduce variance in predictions) and regularization (to reduce low bias in models) methodologies. 
Regularization makes models less reliant on training data by adding a small penalty (determined by cross-validation), and can not only minimize overfitting but can additionally help in predicting outcomes using a limited number of samples. 

ML models can be regularized using 3 main methods, each with their particular strengths and weaknesses. 
Ridge regression aims to minimize the magnitude of the features, but cannot completely remove unimportant features and thus may not be ideal for reducing the feature space. 
Another method, LASSO or Least Absolute Shrinkage and Selection Operator regression, works well for selecting few important features since it can minimize the magnitude of some features more than the others[@doi:10.1038/nmeth.4014]. 
Elastic-net regression is a combination of LASSO and ridge regression[@doi:10.1111/j.1467-9868.2005.00503.x], and helps to select most useful features, especially in presence of large number of correlated features. 

While regression based regularization has not been used extensively in rare disease, examples of combinations of above strategies implemented in rare variant discovery and immune cell signature discovery can provide an insight into their possible use in rare disease.
In rare variant discovery, adaptive ridge regression was utilized to combine rare variants into a single score to increase the signal of rare variants[@doi:10.1371/journal.pone.0044173], while LASSO was implemented along with group penalties to identify rare variants/ low frequency predictors [@doi:10.1038/nrg2867; @doi:10.1093/bioinformatics/btq448]. 
Hybrid approaches of LASSO including boosting the signal of rare variants by capturing linear combinations of variants by gene or chromosome location in 5% of subjects [@doi:10.1002/gepi.21746; @doi:10.1186/1753-6561-5-S9-S100; @doi:10.1016/j.ajhg.2008.06.024; @doi:10.1186/1753-6561-5-S9-S113; @doi:10.1186/1753-6561-5-S9-S100], integration with the probabilistic logistic bayesian approach [@doi:10.4137/CIN.S17290], and combining feature selection methods with a generalized pooling strategy [@doi:10.1371/journal.pone.0041694] have also been tested in rare variant discovery.
Another interesting approach which incorporated prior knowledge into the regularization (called sparse-group LASSO) worked well to select the driver genes in a pathway of interest where only few genes in a pathway were true predictors of a phenotype [@doi:10.1080/10618600.2012.681250]. 

In immune cell signature discovery, elastic-net regression (a combination of LASSO and ridge regression) has been used to reduce the feature space and was found to outperform the other regression approaches [@doi:10.1016/j.compbiomed.2015.10.008; @doi:10.1186/1471-2105-14-198; @doi:10.1111/j.1467-9868.2005.00503.x]. 
A variation of elastic-net, where a two-step regularized logistic regression was used to pre-select an optimal number of genes before implementing elastic-net regularization for gene selection, identified immune cell signatures in an RNA-seq dataset where the number of cells sampled were far fewer than number of genes profiled [@doi: 10.1186/s12859-019-2994-z].  
Thus robust regularizations methods like LASSO or elastic-net have been methods of choice where the the profiled feature space have outnumbered the number of samples or patients by a magnitude and should be explored while working with rare disease datasets.

#### Hyperensemble


### Managing disparities in data generation is required for robust rare disease analyses

Rare disease data from can suffer from artifacts introduced by batch, assay platform, specimen quality or other non-biological phenomena. 
The consequences of these artifacts are amplified in rare diseases which often have few samples and heterogeneous phenotypes.
Furthermore, datasets are often pieced together from multiple small studies where biological characteristics are confounded by technical variables. 
Collaboration with data generators or domain experts may result in unexpected insight into potential sources of variation. 
The authors experienced this when studying neurofibromatosis type 1 (NF1). 
The NF1 datasets were comprised of samples obtained with different surgical techniques, resulting in biological differences that were a consequence of sample collection, rather than ...
Consequently, careful assessment of and accounting for confounding factors is critical to identifying biologically meaningful features within a dataset. 

Assessment of confounding factors and heterogeneity is perhaps most easily performed using unsupervised learning approaches. 
K-means clustering or hierarchical clustering can be used to characterize the structure present in genomic or imaging data. [@doi:10.1186/1471-2105-9-497;@doi:10.1109/JBHI.2013.2276766]. 
Similarly, dimensionality reduction methods can be used to visualize heterogeneity and confounders, including multidimensional scaling, principal components analysis, t-distributed stochastic neighbor embedding (t-SNE), and uniform manifold approximation and projection (UMAP), among others. [@doi:10.1007/978-3-540-33037-0_14; @doi:10.1098/rsta.2015.0202; @https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf; @arXiv:1802.03426]
All of these methods can be used to identify batch effects and other structure in the data, though some (like t-SNE and UMAP) require parameters that can affect the output and it's interpretation [@doi:10.23915/distill.00002;@arXiv:1802.03426]. 
Therefore, obtaining a clear interpretation from these methods requires understanding the underlying approach and parameters.  
Another important consideration is discussed by Way, et. al. [@doi:10.1186/s13059-020-02021-3]: a single dimensionality reduction method alone may not be sufficient to reveal all of the technical or biological heterogeneity; testing multiple methods may result in a more comprehensive portrait of the data.
Dimensionality reduction techniques are not restricted to 'omic' data - they can also be used in rare disease applications to characterize the structure and heterogeneity of imaging data [@doi:10.1016/j.media.2020.101660], mass cytometry data [@doi:10.1038/ncomms14825], and others.

Once the nature of the non-biological heterogeneity has been established, different techniques can be used to correct the differences. 
Common approaches include reprocessing the raw data using a single analysis pipeline if the data are obtained from different sources, application of batch correction methods [@doi:10.1093/biostatistics/kxj037; @doi:10.1093/nar/gku864], and normalization of raw values[@doi:10.1186/gb-2010-11-3-r25].
It is also important to be realistic when working with rare disease data. 
For various reasons including ethics, funding, and limited biospecimens, experimental design and the resulting data will often be less-than-ideal. 
In these cases, it may be prudent to take a step back, re-evaluate the data, and identify methods that can operate within the constraints of the data. 


### Conclusions
>We will conclude by discussing the potential of the above-mentioned approaches in rare diseases and other biomedical areas where data is scarce.


### Outlook


## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>
